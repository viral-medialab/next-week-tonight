11:22:20,689 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:22:21,736 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:22,553 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:22:22,558 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:22:22,558 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:22:22,559 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:22:22,560 graphrag.index.input.factory INFO loading input from root_dir=input
11:22:22,560 graphrag.index.input.factory INFO using file storage for input
11:22:22,560 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:22:22,562 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:22:22,570 graphrag.index.input.text INFO Found 9 files, loading 9
11:22:22,570 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:22:22,576 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:22:22,607 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:22:22,609 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:22:22,623 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:22:25,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:30,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:35,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:38,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:39,145 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:40,272 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:40,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:42,113 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:42,728 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:46,218 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:47,649 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:48,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:51,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:51,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:52,251 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:52,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:53,581 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:59,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:03,617 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:04,48 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:08,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:09,249 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:12,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:12,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,647 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,157 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,330 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:24,811 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:37,481 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:40,900 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:41,711 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:42,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:42,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:43,41 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:43,346 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,270 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:45,52 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:45,84 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:45,86 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:45,91 root INFO Starting preprocessing of transition probabilities on graph with 62 nodes and 81 edges
11:23:45,91 root INFO Starting at time 1744817025.091522
11:23:45,91 root INFO Beginning preprocessing of transition probabilities for 62 vertices
11:23:45,91 root INFO Completed 1 / 62 vertices
11:23:45,91 root INFO Completed 7 / 62 vertices
11:23:45,91 root INFO Completed 13 / 62 vertices
11:23:45,91 root INFO Completed 19 / 62 vertices
11:23:45,91 root INFO Completed 25 / 62 vertices
11:23:45,91 root INFO Completed 31 / 62 vertices
11:23:45,91 root INFO Completed 37 / 62 vertices
11:23:45,91 root INFO Completed 43 / 62 vertices
11:23:45,91 root INFO Completed 49 / 62 vertices
11:23:45,92 root INFO Completed 55 / 62 vertices
11:23:45,92 root INFO Completed 61 / 62 vertices
11:23:45,92 root INFO Completed preprocessing of transition probabilities for vertices
11:23:45,92 root INFO Beginning preprocessing of transition probabilities for 81 edges
11:23:45,92 root INFO Completed 1 / 81 edges
11:23:45,92 root INFO Completed 9 / 81 edges
11:23:45,92 root INFO Completed 17 / 81 edges
11:23:45,93 root INFO Completed 25 / 81 edges
11:23:45,93 root INFO Completed 33 / 81 edges
11:23:45,94 root INFO Completed 41 / 81 edges
11:23:45,94 root INFO Completed 49 / 81 edges
11:23:45,94 root INFO Completed 57 / 81 edges
11:23:45,94 root INFO Completed 65 / 81 edges
11:23:45,94 root INFO Completed 73 / 81 edges
11:23:45,95 root INFO Completed 81 / 81 edges
11:23:45,95 root INFO Completed preprocessing of transition probabilities for edges
11:23:45,95 root INFO Simulating walks on graph at time 1744817025.095087
11:23:45,95 root INFO Walk iteration: 1/10
11:23:45,98 root INFO Walk iteration: 2/10
11:23:45,101 root INFO Walk iteration: 3/10
11:23:45,103 root INFO Walk iteration: 4/10
11:23:45,106 root INFO Walk iteration: 5/10
11:23:45,108 root INFO Walk iteration: 6/10
11:23:45,111 root INFO Walk iteration: 7/10
11:23:45,114 root INFO Walk iteration: 8/10
11:23:45,116 root INFO Walk iteration: 9/10
11:23:45,118 root INFO Walk iteration: 10/10
11:23:45,121 root INFO Learning embeddings at time 1744817025.121253
11:23:45,121 gensim.models.word2vec INFO collecting all words and their counts
11:23:45,121 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:23:45,122 gensim.models.word2vec INFO collected 62 word types from a corpus of 11200 raw words and 620 sentences
11:23:45,122 gensim.models.word2vec INFO Creating a fresh vocabulary
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 62 unique words (100.00% of original 62, drops 0)', 'datetime': '2025-04-16T11:23:45.122709', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 11200 word corpus (100.00% of original 11200, drops 0)', 'datetime': '2025-04-16T11:23:45.122745', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,122 gensim.models.word2vec INFO deleting the raw counts dictionary of 62 items
11:23:45,122 gensim.models.word2vec INFO sample=0.001 downsamples 62 most-common words
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3126.1365729291606 word corpus (27.9%% of prior 11200)', 'datetime': '2025-04-16T11:23:45.122963', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,123 gensim.models.word2vec INFO estimated required memory for 62 words and 1536 dimensions: 792856 bytes
11:23:45,123 gensim.models.word2vec INFO resetting layer weights
11:23:45,123 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:23:45.123581', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:23:45,123 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 62 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:23:45.123617', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:23:45,143 gensim.models.word2vec INFO EPOCH 0: training on 11200 raw words (3160 effective words) took 0.0s, 166779 effective words/s
11:23:45,161 gensim.models.word2vec INFO EPOCH 1: training on 11200 raw words (3098 effective words) took 0.0s, 179365 effective words/s
11:23:45,179 gensim.models.word2vec INFO EPOCH 2: training on 11200 raw words (3126 effective words) took 0.0s, 180223 effective words/s
11:23:45,179 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 33600 raw words (9384 effective words) took 0.1s, 168364 effective words/s', 'datetime': '2025-04-16T11:23:45.179368', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:23:45,179 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=62, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:23:45.179395', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:23:45,179 root INFO Completed. Ending time is 1744817025.179429 Elapsed time is -0.08790707588195801
11:23:48,887 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,889 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,917 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:23:48,918 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,919 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,935 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,937 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,938 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:23:48,943 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 36
11:23:48,977 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 62
11:24:12,24 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:17,959 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:29,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:31,7 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:32,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:50,727 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:51,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:52,675 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:55,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:55,926 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:56,710 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:56,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:02,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:08,337 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:11,689 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:14,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:14,727 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:25:14,730 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:25:14,732 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:25:14,734 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:25:14,735 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:25:14,739 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:25:14,739 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:25:14,764 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:25:15,612 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:15,930 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:25:15,933 graphrag.index.operations.embed_text.strategies.openai INFO embedding 65 inputs via 65 snippets using 5 batches. max_batch_size=16, max_tokens=8191
11:25:16,431 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,434 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,574 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,770 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,981 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:25:16,990 graphrag.index.operations.embed_text.strategies.openai INFO embedding 16 inputs via 16 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:25:17,454 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:17,642 graphrag.cli.index INFO All workflows completed successfully.
11:41:29,515 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:41:41,570 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:44:27,259 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:44:28,462 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:28,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:44:28,980 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:44:28,981 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:44:28,982 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:44:28,983 graphrag.index.input.factory INFO loading input from root_dir=input
11:44:28,983 graphrag.index.input.factory INFO using file storage for input
11:44:28,983 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:44:28,984 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:44:28,993 graphrag.index.input.text INFO Found 9 files, loading 9
11:44:28,997 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:44:29,4 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:44:29,35 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:44:29,36 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:44:29,49 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:44:31,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:31,621 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:31,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:32,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,173 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,177 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:34,500 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:34,501 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:38,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:58,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:08,400 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:15,568 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:24,63 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:25,703 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:25,758 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:25,760 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:25,764 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
11:45:25,764 root INFO Starting at time 1744818325.764467
11:45:25,764 root INFO Beginning preprocessing of transition probabilities for 39 vertices
11:45:25,764 root INFO Completed 1 / 39 vertices
11:45:25,764 root INFO Completed 4 / 39 vertices
11:45:25,764 root INFO Completed 7 / 39 vertices
11:45:25,764 root INFO Completed 10 / 39 vertices
11:45:25,764 root INFO Completed 13 / 39 vertices
11:45:25,764 root INFO Completed 16 / 39 vertices
11:45:25,764 root INFO Completed 19 / 39 vertices
11:45:25,764 root INFO Completed 22 / 39 vertices
11:45:25,764 root INFO Completed 25 / 39 vertices
11:45:25,764 root INFO Completed 28 / 39 vertices
11:45:25,764 root INFO Completed 31 / 39 vertices
11:45:25,764 root INFO Completed 34 / 39 vertices
11:45:25,764 root INFO Completed 37 / 39 vertices
11:45:25,764 root INFO Completed preprocessing of transition probabilities for vertices
11:45:25,764 root INFO Beginning preprocessing of transition probabilities for 46 edges
11:45:25,764 root INFO Completed 1 / 46 edges
11:45:25,765 root INFO Completed 5 / 46 edges
11:45:25,765 root INFO Completed 9 / 46 edges
11:45:25,765 root INFO Completed 13 / 46 edges
11:45:25,765 root INFO Completed 17 / 46 edges
11:45:25,765 root INFO Completed 21 / 46 edges
11:45:25,765 root INFO Completed 25 / 46 edges
11:45:25,765 root INFO Completed 29 / 46 edges
11:45:25,765 root INFO Completed 33 / 46 edges
11:45:25,766 root INFO Completed 37 / 46 edges
11:45:25,766 root INFO Completed 41 / 46 edges
11:45:25,766 root INFO Completed 45 / 46 edges
11:45:25,766 root INFO Completed preprocessing of transition probabilities for edges
11:45:25,766 root INFO Simulating walks on graph at time 1744818325.766187
11:45:25,766 root INFO Walk iteration: 1/10
11:45:25,767 root INFO Walk iteration: 2/10
11:45:25,769 root INFO Walk iteration: 3/10
11:45:25,770 root INFO Walk iteration: 4/10
11:45:25,771 root INFO Walk iteration: 5/10
11:45:25,773 root INFO Walk iteration: 6/10
11:45:25,774 root INFO Walk iteration: 7/10
11:45:25,776 root INFO Walk iteration: 8/10
11:45:25,777 root INFO Walk iteration: 9/10
11:45:25,778 root INFO Walk iteration: 10/10
11:45:25,780 root INFO Learning embeddings at time 1744818325.7802858
11:45:25,780 gensim.models.word2vec INFO collecting all words and their counts
11:45:25,780 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:45:25,781 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
11:45:25,781 gensim.models.word2vec INFO Creating a fresh vocabulary
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T11:45:25.781201', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T11:45:25.781234', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
11:45:25,781 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T11:45:25.781390', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
11:45:25,781 gensim.models.word2vec INFO resetting layer weights
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:45:25.781826', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:45:25.781856', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:45:25,791 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 162105 effective words/s
11:45:25,801 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 172084 effective words/s
11:45:25,810 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 169905 effective words/s
11:45:25,810 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 156614 effective words/s', 'datetime': '2025-04-16T11:45:25.810624', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:45:25,810 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:45:25.810654', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:45:25,810 root INFO Completed. Ending time is 1744818325.810685 Elapsed time is -0.046217918395996094
11:45:29,574 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,576 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,596 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:45:29,597 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,599 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,615 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,616 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,618 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:45:29,623 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
11:45:45,468 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:55,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:00,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:03,697 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:05,847 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:08,509 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:08,537 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:46:08,540 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:46:08,542 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:46:08,544 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:46:08,546 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:46:08,550 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:46:08,550 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:46:08,774 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:46:08,788 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:46:08,791 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:46:09,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:09,560 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:46:09,566 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
11:46:10,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,906 graphrag.cli.index INFO All workflows completed successfully.
11:51:01,572 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:51:02,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:51:02,916 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:51:02,922 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:51:02,924 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:51:02,925 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:51:02,925 graphrag.index.input.factory INFO loading input from root_dir=input
11:51:02,925 graphrag.index.input.factory INFO using file storage for input
11:51:02,926 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:51:02,927 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:51:02,935 graphrag.index.input.text INFO Found 9 files, loading 9
11:51:02,937 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:51:02,943 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:02,974 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:02,976 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:02,989 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:03,62 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:03,64 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:03,67 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
11:51:03,67 root INFO Starting at time 1744818663.067168
11:51:03,67 root INFO Beginning preprocessing of transition probabilities for 39 vertices
11:51:03,67 root INFO Completed 1 / 39 vertices
11:51:03,67 root INFO Completed 4 / 39 vertices
11:51:03,67 root INFO Completed 7 / 39 vertices
11:51:03,67 root INFO Completed 10 / 39 vertices
11:51:03,67 root INFO Completed 13 / 39 vertices
11:51:03,67 root INFO Completed 16 / 39 vertices
11:51:03,67 root INFO Completed 19 / 39 vertices
11:51:03,67 root INFO Completed 22 / 39 vertices
11:51:03,67 root INFO Completed 25 / 39 vertices
11:51:03,67 root INFO Completed 28 / 39 vertices
11:51:03,67 root INFO Completed 31 / 39 vertices
11:51:03,67 root INFO Completed 34 / 39 vertices
11:51:03,67 root INFO Completed 37 / 39 vertices
11:51:03,67 root INFO Completed preprocessing of transition probabilities for vertices
11:51:03,67 root INFO Beginning preprocessing of transition probabilities for 46 edges
11:51:03,67 root INFO Completed 1 / 46 edges
11:51:03,67 root INFO Completed 5 / 46 edges
11:51:03,67 root INFO Completed 9 / 46 edges
11:51:03,67 root INFO Completed 13 / 46 edges
11:51:03,67 root INFO Completed 17 / 46 edges
11:51:03,68 root INFO Completed 21 / 46 edges
11:51:03,68 root INFO Completed 25 / 46 edges
11:51:03,68 root INFO Completed 29 / 46 edges
11:51:03,68 root INFO Completed 33 / 46 edges
11:51:03,68 root INFO Completed 37 / 46 edges
11:51:03,68 root INFO Completed 41 / 46 edges
11:51:03,68 root INFO Completed 45 / 46 edges
11:51:03,68 root INFO Completed preprocessing of transition probabilities for edges
11:51:03,68 root INFO Simulating walks on graph at time 1744818663.068479
11:51:03,68 root INFO Walk iteration: 1/10
11:51:03,69 root INFO Walk iteration: 2/10
11:51:03,70 root INFO Walk iteration: 3/10
11:51:03,72 root INFO Walk iteration: 4/10
11:51:03,73 root INFO Walk iteration: 5/10
11:51:03,74 root INFO Walk iteration: 6/10
11:51:03,75 root INFO Walk iteration: 7/10
11:51:03,76 root INFO Walk iteration: 8/10
11:51:03,77 root INFO Walk iteration: 9/10
11:51:03,78 root INFO Walk iteration: 10/10
11:51:03,80 root INFO Learning embeddings at time 1744818663.080079
11:51:03,80 gensim.models.word2vec INFO collecting all words and their counts
11:51:03,80 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:51:03,80 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
11:51:03,80 gensim.models.word2vec INFO Creating a fresh vocabulary
11:51:03,80 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T11:51:03.080901', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,80 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T11:51:03.080932', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,81 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
11:51:03,81 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T11:51:03.081070', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,81 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
11:51:03,81 gensim.models.word2vec INFO resetting layer weights
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:51:03.081465', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:51:03.081492', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:51:03,90 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 169659 effective words/s
11:51:03,106 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 135531 effective words/s
11:51:03,115 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 175435 effective words/s
11:51:03,115 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 131113 effective words/s', 'datetime': '2025-04-16T11:51:03.115846', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:51:03,115 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:51:03.115885', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:51:03,115 root INFO Completed. Ending time is 1744818663.115919 Elapsed time is -0.048751115798950195
11:51:06,724 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,726 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,746 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:06,747 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,749 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,765 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,766 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,768 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:51:06,772 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
11:51:42,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:51:42,518 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:42,521 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:42,524 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:42,526 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:42,528 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:51:42,532 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:51:42,532 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:51:42,744 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
11:51:42,765 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:51:42,768 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:51:43,154 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:51:43,182 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:51:43,194 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:51:43,252 graphrag.cli.index INFO All workflows completed successfully.
13:01:31,445 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:01:32,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:01:33,332 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:01:33,336 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:01:33,337 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:01:33,338 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
13:01:33,338 graphrag.index.input.factory INFO loading input from root_dir=input
13:01:33,338 graphrag.index.input.factory INFO using file storage for input
13:01:33,339 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
13:01:33,341 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
13:01:33,350 graphrag.index.input.text INFO Found 9 files, loading 9
13:01:33,351 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:01:33,358 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:33,387 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:33,388 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:33,401 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:33,474 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:33,476 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:33,479 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
13:01:33,479 root INFO Starting at time 1744822893.479897
13:01:33,479 root INFO Beginning preprocessing of transition probabilities for 39 vertices
13:01:33,479 root INFO Completed 1 / 39 vertices
13:01:33,479 root INFO Completed 4 / 39 vertices
13:01:33,480 root INFO Completed 7 / 39 vertices
13:01:33,480 root INFO Completed 10 / 39 vertices
13:01:33,480 root INFO Completed 13 / 39 vertices
13:01:33,480 root INFO Completed 16 / 39 vertices
13:01:33,480 root INFO Completed 19 / 39 vertices
13:01:33,480 root INFO Completed 22 / 39 vertices
13:01:33,480 root INFO Completed 25 / 39 vertices
13:01:33,480 root INFO Completed 28 / 39 vertices
13:01:33,480 root INFO Completed 31 / 39 vertices
13:01:33,480 root INFO Completed 34 / 39 vertices
13:01:33,480 root INFO Completed 37 / 39 vertices
13:01:33,480 root INFO Completed preprocessing of transition probabilities for vertices
13:01:33,480 root INFO Beginning preprocessing of transition probabilities for 46 edges
13:01:33,480 root INFO Completed 1 / 46 edges
13:01:33,480 root INFO Completed 5 / 46 edges
13:01:33,480 root INFO Completed 9 / 46 edges
13:01:33,480 root INFO Completed 13 / 46 edges
13:01:33,480 root INFO Completed 17 / 46 edges
13:01:33,480 root INFO Completed 21 / 46 edges
13:01:33,480 root INFO Completed 25 / 46 edges
13:01:33,481 root INFO Completed 29 / 46 edges
13:01:33,481 root INFO Completed 33 / 46 edges
13:01:33,481 root INFO Completed 37 / 46 edges
13:01:33,481 root INFO Completed 41 / 46 edges
13:01:33,481 root INFO Completed 45 / 46 edges
13:01:33,481 root INFO Completed preprocessing of transition probabilities for edges
13:01:33,481 root INFO Simulating walks on graph at time 1744822893.481245
13:01:33,481 root INFO Walk iteration: 1/10
13:01:33,482 root INFO Walk iteration: 2/10
13:01:33,483 root INFO Walk iteration: 3/10
13:01:33,485 root INFO Walk iteration: 4/10
13:01:33,486 root INFO Walk iteration: 5/10
13:01:33,487 root INFO Walk iteration: 6/10
13:01:33,488 root INFO Walk iteration: 7/10
13:01:33,489 root INFO Walk iteration: 8/10
13:01:33,491 root INFO Walk iteration: 9/10
13:01:33,492 root INFO Walk iteration: 10/10
13:01:33,493 root INFO Learning embeddings at time 1744822893.493786
13:01:33,494 gensim.models.word2vec INFO collecting all words and their counts
13:01:33,494 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:01:33,494 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
13:01:33,494 gensim.models.word2vec INFO Creating a fresh vocabulary
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T13:01:33.494795', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T13:01:33.494830', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,494 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
13:01:33,494 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T13:01:33.494994', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,495 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
13:01:33,495 gensim.models.word2vec INFO resetting layer weights
13:01:33,495 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T13:01:33.495465', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:01:33,495 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T13:01:33.495502', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:01:33,505 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 168077 effective words/s
13:01:33,515 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 166029 effective words/s
13:01:33,524 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 177786 effective words/s
13:01:33,524 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 156743 effective words/s', 'datetime': '2025-04-16T13:01:33.524245', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:01:33,524 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T13:01:33.524279', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:01:33,524 root INFO Completed. Ending time is 1744822893.524309 Elapsed time is -0.04441189765930176
13:01:37,200 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,202 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,222 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:37,223 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,225 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,243 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,244 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,246 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:01:37,251 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
13:01:37,313 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:37,315 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,316 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:37,318 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,319 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:01:37,322 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:01:37,322 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:01:37,541 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
13:01:37,566 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:01:37,570 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:01:37,576 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:01:37,583 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:01:37,633 graphrag.cli.index INFO All workflows completed successfully.
13:41:47,75 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:41:47,994 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:41:48,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:41:48,549 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:41:48,551 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:41:48,552 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
13:41:48,552 graphrag.index.input.factory INFO loading input from root_dir=input
13:41:48,553 graphrag.index.input.factory INFO using file storage for input
13:41:48,553 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
13:41:48,555 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
13:41:48,564 graphrag.index.input.text INFO Found 9 files, loading 9
13:41:48,565 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:41:48,571 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:48,601 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:48,603 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:48,616 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:48,688 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:48,690 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:48,693 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
13:41:48,693 root INFO Starting at time 1744825308.693502
13:41:48,693 root INFO Beginning preprocessing of transition probabilities for 39 vertices
13:41:48,693 root INFO Completed 1 / 39 vertices
13:41:48,693 root INFO Completed 4 / 39 vertices
13:41:48,693 root INFO Completed 7 / 39 vertices
13:41:48,693 root INFO Completed 10 / 39 vertices
13:41:48,693 root INFO Completed 13 / 39 vertices
13:41:48,693 root INFO Completed 16 / 39 vertices
13:41:48,693 root INFO Completed 19 / 39 vertices
13:41:48,693 root INFO Completed 22 / 39 vertices
13:41:48,693 root INFO Completed 25 / 39 vertices
13:41:48,693 root INFO Completed 28 / 39 vertices
13:41:48,693 root INFO Completed 31 / 39 vertices
13:41:48,693 root INFO Completed 34 / 39 vertices
13:41:48,693 root INFO Completed 37 / 39 vertices
13:41:48,693 root INFO Completed preprocessing of transition probabilities for vertices
13:41:48,693 root INFO Beginning preprocessing of transition probabilities for 46 edges
13:41:48,693 root INFO Completed 1 / 46 edges
13:41:48,693 root INFO Completed 5 / 46 edges
13:41:48,694 root INFO Completed 9 / 46 edges
13:41:48,694 root INFO Completed 13 / 46 edges
13:41:48,694 root INFO Completed 17 / 46 edges
13:41:48,694 root INFO Completed 21 / 46 edges
13:41:48,694 root INFO Completed 25 / 46 edges
13:41:48,694 root INFO Completed 29 / 46 edges
13:41:48,694 root INFO Completed 33 / 46 edges
13:41:48,694 root INFO Completed 37 / 46 edges
13:41:48,694 root INFO Completed 41 / 46 edges
13:41:48,694 root INFO Completed 45 / 46 edges
13:41:48,694 root INFO Completed preprocessing of transition probabilities for edges
13:41:48,694 root INFO Simulating walks on graph at time 1744825308.69485
13:41:48,694 root INFO Walk iteration: 1/10
13:41:48,696 root INFO Walk iteration: 2/10
13:41:48,697 root INFO Walk iteration: 3/10
13:41:48,698 root INFO Walk iteration: 4/10
13:41:48,699 root INFO Walk iteration: 5/10
13:41:48,700 root INFO Walk iteration: 6/10
13:41:48,701 root INFO Walk iteration: 7/10
13:41:48,703 root INFO Walk iteration: 8/10
13:41:48,704 root INFO Walk iteration: 9/10
13:41:48,705 root INFO Walk iteration: 10/10
13:41:48,706 root INFO Learning embeddings at time 1744825308.706572
13:41:48,706 gensim.models.word2vec INFO collecting all words and their counts
13:41:48,706 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:41:48,707 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
13:41:48,707 gensim.models.word2vec INFO Creating a fresh vocabulary
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T13:41:48.707443', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T13:41:48.707474', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
13:41:48,707 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T13:41:48.707621', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
13:41:48,707 gensim.models.word2vec INFO resetting layer weights
13:41:48,708 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T13:41:48.708008', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:41:48,708 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T13:41:48.708035', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:41:48,717 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 178760 effective words/s
13:41:48,726 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 180281 effective words/s
13:41:48,735 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 178310 effective words/s
13:41:48,735 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 166187 effective words/s', 'datetime': '2025-04-16T13:41:48.735139', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:41:48,735 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T13:41:48.735171', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:41:48,735 root INFO Completed. Ending time is 1744825308.7352011 Elapsed time is -0.04169917106628418
13:41:52,566 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,568 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,588 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:52,589 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,590 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,606 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,608 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,609 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:41:52,615 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
13:41:52,676 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:52,677 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,679 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:52,680 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,682 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:41:52,684 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:41:52,684 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:41:52,909 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:41:52,923 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:41:52,925 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
13:41:52,945 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:41:52,948 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:41:52,993 graphrag.cli.index INFO All workflows completed successfully.
14:00:29,438 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:00:30,385 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:31,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:00:31,17 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:00:31,18 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:00:31,18 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:00:31,19 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:00:31,19 graphrag.index.input.factory INFO using file storage for input
14:00:31,19 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:00:31,20 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:00:31,28 graphrag.index.input.text INFO Found 9 files, loading 9
14:00:31,29 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:00:31,36 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:00:31,68 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:00:31,70 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:00:31,84 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:00:32,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:38,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:41,934 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:43,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:44,211 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:53,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:54,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:59,183 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:59,496 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:00,184 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:01,760 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:03,675 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:07,350 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:11,549 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:12,681 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:13,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:17,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:19,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:26,573 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:29,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:33,60 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:33,789 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:35,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:40,146 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:40,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:40,176 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:40,181 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 44 edges
14:01:40,181 root INFO Starting at time 1744826500.1812239
14:01:40,181 root INFO Beginning preprocessing of transition probabilities for 39 vertices
14:01:40,181 root INFO Completed 1 / 39 vertices
14:01:40,181 root INFO Completed 4 / 39 vertices
14:01:40,181 root INFO Completed 7 / 39 vertices
14:01:40,181 root INFO Completed 10 / 39 vertices
14:01:40,181 root INFO Completed 13 / 39 vertices
14:01:40,181 root INFO Completed 16 / 39 vertices
14:01:40,181 root INFO Completed 19 / 39 vertices
14:01:40,181 root INFO Completed 22 / 39 vertices
14:01:40,181 root INFO Completed 25 / 39 vertices
14:01:40,181 root INFO Completed 28 / 39 vertices
14:01:40,181 root INFO Completed 31 / 39 vertices
14:01:40,181 root INFO Completed 34 / 39 vertices
14:01:40,181 root INFO Completed 37 / 39 vertices
14:01:40,181 root INFO Completed preprocessing of transition probabilities for vertices
14:01:40,181 root INFO Beginning preprocessing of transition probabilities for 44 edges
14:01:40,181 root INFO Completed 1 / 44 edges
14:01:40,181 root INFO Completed 5 / 44 edges
14:01:40,182 root INFO Completed 9 / 44 edges
14:01:40,182 root INFO Completed 13 / 44 edges
14:01:40,182 root INFO Completed 17 / 44 edges
14:01:40,182 root INFO Completed 21 / 44 edges
14:01:40,182 root INFO Completed 25 / 44 edges
14:01:40,182 root INFO Completed 29 / 44 edges
14:01:40,182 root INFO Completed 33 / 44 edges
14:01:40,182 root INFO Completed 37 / 44 edges
14:01:40,183 root INFO Completed 41 / 44 edges
14:01:40,183 root INFO Completed preprocessing of transition probabilities for edges
14:01:40,183 root INFO Simulating walks on graph at time 1744826500.183128
14:01:40,183 root INFO Walk iteration: 1/10
14:01:40,184 root INFO Walk iteration: 2/10
14:01:40,186 root INFO Walk iteration: 3/10
14:01:40,187 root INFO Walk iteration: 4/10
14:01:40,189 root INFO Walk iteration: 5/10
14:01:40,190 root INFO Walk iteration: 6/10
14:01:40,192 root INFO Walk iteration: 7/10
14:01:40,193 root INFO Walk iteration: 8/10
14:01:40,194 root INFO Walk iteration: 9/10
14:01:40,196 root INFO Walk iteration: 10/10
14:01:40,197 root INFO Learning embeddings at time 1744826500.197429
14:01:40,197 gensim.models.word2vec INFO collecting all words and their counts
14:01:40,197 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:01:40,198 gensim.models.word2vec INFO collected 39 word types from a corpus of 6600 raw words and 390 sentences
14:01:40,198 gensim.models.word2vec INFO Creating a fresh vocabulary
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T14:01:40.198429', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6600 word corpus (100.00% of original 6600, drops 0)', 'datetime': '2025-04-16T14:01:40.198468', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
14:01:40,198 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1409.778285885143 word corpus (21.4%% of prior 6600)', 'datetime': '2025-04-16T14:01:40.198644', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
14:01:40,198 gensim.models.word2vec INFO resetting layer weights
14:01:40,199 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:01:40.199179', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:01:40,199 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:01:40.199238', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:01:40,209 gensim.models.word2vec INFO EPOCH 0: training on 6600 raw words (1428 effective words) took 0.0s, 157081 effective words/s
14:01:40,218 gensim.models.word2vec INFO EPOCH 1: training on 6600 raw words (1398 effective words) took 0.0s, 166176 effective words/s
14:01:40,226 gensim.models.word2vec INFO EPOCH 2: training on 6600 raw words (1372 effective words) took 0.0s, 173791 effective words/s
14:01:40,226 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 19800 raw words (4198 effective words) took 0.0s, 153732 effective words/s', 'datetime': '2025-04-16T14:01:40.226573', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:01:40,226 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:01:40.226604', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:01:40,226 root INFO Completed. Ending time is 1744826500.226635 Elapsed time is -0.045411109924316406
14:01:44,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,98 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,118 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:01:44,120 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,121 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,137 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,138 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,140 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:01:44,145 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
14:02:10,128 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:11,220 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:11,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:13,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:26,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:31,171 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:11,808 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:03:12,897 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:13,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:03:13,416 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:03:13,417 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:03:13,418 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:03:13,418 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:03:13,418 graphrag.index.input.factory INFO using file storage for input
14:03:13,419 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:03:13,419 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:03:13,425 graphrag.index.input.text INFO Found 9 files, loading 9
14:03:13,426 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:03:13,431 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:13,456 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:13,458 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:13,470 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:13,531 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:13,533 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:13,536 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:03:13,536 root INFO Starting at time 1744826593.536353
14:03:13,536 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:03:13,536 root INFO Completed 1 / 24 vertices
14:03:13,536 root INFO Completed 3 / 24 vertices
14:03:13,536 root INFO Completed 5 / 24 vertices
14:03:13,536 root INFO Completed 7 / 24 vertices
14:03:13,536 root INFO Completed 9 / 24 vertices
14:03:13,536 root INFO Completed 11 / 24 vertices
14:03:13,536 root INFO Completed 13 / 24 vertices
14:03:13,536 root INFO Completed 15 / 24 vertices
14:03:13,536 root INFO Completed 17 / 24 vertices
14:03:13,536 root INFO Completed 19 / 24 vertices
14:03:13,536 root INFO Completed 21 / 24 vertices
14:03:13,536 root INFO Completed 23 / 24 vertices
14:03:13,536 root INFO Completed preprocessing of transition probabilities for vertices
14:03:13,536 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:03:13,536 root INFO Completed 1 / 25 edges
14:03:13,536 root INFO Completed 3 / 25 edges
14:03:13,536 root INFO Completed 5 / 25 edges
14:03:13,536 root INFO Completed 7 / 25 edges
14:03:13,536 root INFO Completed 9 / 25 edges
14:03:13,536 root INFO Completed 11 / 25 edges
14:03:13,536 root INFO Completed 13 / 25 edges
14:03:13,536 root INFO Completed 15 / 25 edges
14:03:13,536 root INFO Completed 17 / 25 edges
14:03:13,537 root INFO Completed 19 / 25 edges
14:03:13,537 root INFO Completed 21 / 25 edges
14:03:13,537 root INFO Completed 23 / 25 edges
14:03:13,537 root INFO Completed 25 / 25 edges
14:03:13,537 root INFO Completed preprocessing of transition probabilities for edges
14:03:13,537 root INFO Simulating walks on graph at time 1744826593.5371299
14:03:13,537 root INFO Walk iteration: 1/10
14:03:13,537 root INFO Walk iteration: 2/10
14:03:13,538 root INFO Walk iteration: 3/10
14:03:13,538 root INFO Walk iteration: 4/10
14:03:13,539 root INFO Walk iteration: 5/10
14:03:13,540 root INFO Walk iteration: 6/10
14:03:13,540 root INFO Walk iteration: 7/10
14:03:13,541 root INFO Walk iteration: 8/10
14:03:13,541 root INFO Walk iteration: 9/10
14:03:13,542 root INFO Walk iteration: 10/10
14:03:13,542 root INFO Learning embeddings at time 1744826593.5429351
14:03:13,543 gensim.models.word2vec INFO collecting all words and their counts
14:03:13,543 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:03:13,543 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:03:13,543 gensim.models.word2vec INFO Creating a fresh vocabulary
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:03:13.543516', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:03:13.543546', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:03:13,543 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:03:13.543651', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:03:13,543 gensim.models.word2vec INFO resetting layer weights
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:03:13.543942', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:03:13.543968', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:03:13,547 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199358 effective words/s
14:03:13,551 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 235317 effective words/s
14:03:13,554 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 231815 effective words/s
14:03:13,554 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170367 effective words/s', 'datetime': '2025-04-16T14:03:13.554911', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:03:13,554 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:03:13.554940', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:03:13,554 root INFO Completed. Ending time is 1744826593.554966 Elapsed time is -0.01861286163330078
14:03:17,242 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,244 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,264 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:17,265 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,267 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,282 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,283 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,284 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:03:17,289 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:03:41,508 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:47,305 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:53,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:55,697 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:04:01,739 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:04:01,764 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:04:01,767 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:04:01,769 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:04:01,771 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:04:01,773 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:04:01,776 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:04:01,776 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:04:02,7 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:04:02,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,863 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,864 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,865 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:03,73 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:04:03,81 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:04:03,787 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:03,926 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:04:03,933 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:04:04,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:04,468 graphrag.cli.index INFO All workflows completed successfully.
14:08:15,375 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:08:16,209 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:08:19,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:08:19,362 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:08:19,363 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:08:19,364 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:08:19,364 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:08:19,364 graphrag.index.input.factory INFO using file storage for input
14:08:19,364 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:08:19,365 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:08:19,373 graphrag.index.input.text INFO Found 9 files, loading 9
14:08:19,374 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:08:19,379 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:19,410 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:19,412 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:19,425 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:19,496 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:19,499 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:19,503 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:08:19,503 root INFO Starting at time 1744826899.503965
14:08:19,504 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:08:19,504 root INFO Completed 1 / 24 vertices
14:08:19,504 root INFO Completed 3 / 24 vertices
14:08:19,504 root INFO Completed 5 / 24 vertices
14:08:19,504 root INFO Completed 7 / 24 vertices
14:08:19,504 root INFO Completed 9 / 24 vertices
14:08:19,504 root INFO Completed 11 / 24 vertices
14:08:19,504 root INFO Completed 13 / 24 vertices
14:08:19,504 root INFO Completed 15 / 24 vertices
14:08:19,504 root INFO Completed 17 / 24 vertices
14:08:19,504 root INFO Completed 19 / 24 vertices
14:08:19,504 root INFO Completed 21 / 24 vertices
14:08:19,504 root INFO Completed 23 / 24 vertices
14:08:19,504 root INFO Completed preprocessing of transition probabilities for vertices
14:08:19,504 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:08:19,504 root INFO Completed 1 / 25 edges
14:08:19,504 root INFO Completed 3 / 25 edges
14:08:19,504 root INFO Completed 5 / 25 edges
14:08:19,504 root INFO Completed 7 / 25 edges
14:08:19,504 root INFO Completed 9 / 25 edges
14:08:19,504 root INFO Completed 11 / 25 edges
14:08:19,504 root INFO Completed 13 / 25 edges
14:08:19,504 root INFO Completed 15 / 25 edges
14:08:19,504 root INFO Completed 17 / 25 edges
14:08:19,504 root INFO Completed 19 / 25 edges
14:08:19,504 root INFO Completed 21 / 25 edges
14:08:19,504 root INFO Completed 23 / 25 edges
14:08:19,504 root INFO Completed 25 / 25 edges
14:08:19,504 root INFO Completed preprocessing of transition probabilities for edges
14:08:19,504 root INFO Simulating walks on graph at time 1744826899.504867
14:08:19,505 root INFO Walk iteration: 1/10
14:08:19,505 root INFO Walk iteration: 2/10
14:08:19,506 root INFO Walk iteration: 3/10
14:08:19,506 root INFO Walk iteration: 4/10
14:08:19,507 root INFO Walk iteration: 5/10
14:08:19,508 root INFO Walk iteration: 6/10
14:08:19,508 root INFO Walk iteration: 7/10
14:08:19,509 root INFO Walk iteration: 8/10
14:08:19,510 root INFO Walk iteration: 9/10
14:08:19,510 root INFO Walk iteration: 10/10
14:08:19,511 root INFO Learning embeddings at time 1744826899.511583
14:08:19,511 gensim.models.word2vec INFO collecting all words and their counts
14:08:19,512 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:08:19,512 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:08:19,512 gensim.models.word2vec INFO Creating a fresh vocabulary
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:08:19.512306', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:08:19.512342', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:08:19,512 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:08:19.512455', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:08:19,512 gensim.models.word2vec INFO resetting layer weights
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:08:19.512786', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:08:19.512819', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:08:19,517 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 176572 effective words/s
14:08:19,520 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 204596 effective words/s
14:08:19,524 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 195843 effective words/s
14:08:19,524 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 163705 effective words/s', 'datetime': '2025-04-16T14:08:19.524211', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:08:19,524 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:08:19.524244', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:08:19,524 root INFO Completed. Ending time is 1744826899.52427 Elapsed time is -0.020305156707763672
14:08:23,359 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,361 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,381 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:23,383 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,384 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,399 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,401 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,402 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:08:23,407 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:08:23,454 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:23,456 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,457 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:23,459 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,460 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:08:23,463 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:08:23,463 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:08:23,680 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:08:23,690 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:08:23,693 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:08:23,716 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:08:23,720 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:08:23,771 graphrag.cli.index INFO All workflows completed successfully.
14:12:22,793 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:12:23,509 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:12:23,745 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:12:23,748 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:12:23,749 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:12:23,749 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:12:23,749 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:12:23,749 graphrag.index.input.factory INFO using file storage for input
14:12:23,750 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:12:23,750 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:12:23,756 graphrag.index.input.text INFO Found 9 files, loading 9
14:12:23,757 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:12:23,762 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:23,790 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:23,792 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:23,805 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:23,865 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:23,867 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:23,870 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:12:23,870 root INFO Starting at time 1744827143.870765
14:12:23,870 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:12:23,870 root INFO Completed 1 / 24 vertices
14:12:23,870 root INFO Completed 3 / 24 vertices
14:12:23,870 root INFO Completed 5 / 24 vertices
14:12:23,870 root INFO Completed 7 / 24 vertices
14:12:23,870 root INFO Completed 9 / 24 vertices
14:12:23,870 root INFO Completed 11 / 24 vertices
14:12:23,870 root INFO Completed 13 / 24 vertices
14:12:23,870 root INFO Completed 15 / 24 vertices
14:12:23,870 root INFO Completed 17 / 24 vertices
14:12:23,871 root INFO Completed 19 / 24 vertices
14:12:23,871 root INFO Completed 21 / 24 vertices
14:12:23,871 root INFO Completed 23 / 24 vertices
14:12:23,871 root INFO Completed preprocessing of transition probabilities for vertices
14:12:23,871 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:12:23,871 root INFO Completed 1 / 25 edges
14:12:23,871 root INFO Completed 3 / 25 edges
14:12:23,871 root INFO Completed 5 / 25 edges
14:12:23,871 root INFO Completed 7 / 25 edges
14:12:23,871 root INFO Completed 9 / 25 edges
14:12:23,871 root INFO Completed 11 / 25 edges
14:12:23,871 root INFO Completed 13 / 25 edges
14:12:23,871 root INFO Completed 15 / 25 edges
14:12:23,871 root INFO Completed 17 / 25 edges
14:12:23,871 root INFO Completed 19 / 25 edges
14:12:23,871 root INFO Completed 21 / 25 edges
14:12:23,871 root INFO Completed 23 / 25 edges
14:12:23,871 root INFO Completed 25 / 25 edges
14:12:23,871 root INFO Completed preprocessing of transition probabilities for edges
14:12:23,871 root INFO Simulating walks on graph at time 1744827143.871603
14:12:23,871 root INFO Walk iteration: 1/10
14:12:23,872 root INFO Walk iteration: 2/10
14:12:23,872 root INFO Walk iteration: 3/10
14:12:23,873 root INFO Walk iteration: 4/10
14:12:23,874 root INFO Walk iteration: 5/10
14:12:23,874 root INFO Walk iteration: 6/10
14:12:23,875 root INFO Walk iteration: 7/10
14:12:23,875 root INFO Walk iteration: 8/10
14:12:23,876 root INFO Walk iteration: 9/10
14:12:23,876 root INFO Walk iteration: 10/10
14:12:23,877 root INFO Learning embeddings at time 1744827143.877565
14:12:23,877 gensim.models.word2vec INFO collecting all words and their counts
14:12:23,877 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:12:23,878 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:12:23,878 gensim.models.word2vec INFO Creating a fresh vocabulary
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:12:23.878167', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:12:23.878197', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:12:23,878 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:12:23.878305', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:12:23,878 gensim.models.word2vec INFO resetting layer weights
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:12:23.878599', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:12:23.878626', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:12:23,882 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199620 effective words/s
14:12:23,885 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 205771 effective words/s
14:12:23,889 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 234235 effective words/s
14:12:23,889 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172138 effective words/s', 'datetime': '2025-04-16T14:12:23.889455', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:12:23,889 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:12:23.889483', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:12:23,889 root INFO Completed. Ending time is 1744827143.889507 Elapsed time is -0.018742084503173828
14:12:27,493 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,495 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,515 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:27,516 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,517 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,532 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,534 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,535 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:12:27,541 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:12:27,586 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:27,588 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,589 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:27,590 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,592 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:12:27,594 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:12:27,594 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:12:27,806 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:12:27,831 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:12:27,838 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:12:27,846 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:12:27,849 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:12:27,899 graphrag.cli.index INFO All workflows completed successfully.
13:24:21,157 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:24:22,165 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:24:22,756 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:24:22,762 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:24:22,763 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:24:22,765 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
13:24:22,765 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
13:24:22,765 graphrag.index.input.factory INFO using file storage for input
13:24:22,766 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
13:24:22,767 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
13:24:22,776 graphrag.index.input.text INFO Found 9 files, loading 9
13:24:22,777 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:24:22,784 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:22,813 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:22,815 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:22,827 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:22,890 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:22,892 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:22,895 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
13:24:22,895 root INFO Starting at time 1744910662.8956742
13:24:22,895 root INFO Beginning preprocessing of transition probabilities for 24 vertices
13:24:22,895 root INFO Completed 1 / 24 vertices
13:24:22,895 root INFO Completed 3 / 24 vertices
13:24:22,895 root INFO Completed 5 / 24 vertices
13:24:22,895 root INFO Completed 7 / 24 vertices
13:24:22,895 root INFO Completed 9 / 24 vertices
13:24:22,895 root INFO Completed 11 / 24 vertices
13:24:22,895 root INFO Completed 13 / 24 vertices
13:24:22,895 root INFO Completed 15 / 24 vertices
13:24:22,895 root INFO Completed 17 / 24 vertices
13:24:22,895 root INFO Completed 19 / 24 vertices
13:24:22,895 root INFO Completed 21 / 24 vertices
13:24:22,895 root INFO Completed 23 / 24 vertices
13:24:22,895 root INFO Completed preprocessing of transition probabilities for vertices
13:24:22,895 root INFO Beginning preprocessing of transition probabilities for 25 edges
13:24:22,896 root INFO Completed 1 / 25 edges
13:24:22,896 root INFO Completed 3 / 25 edges
13:24:22,896 root INFO Completed 5 / 25 edges
13:24:22,896 root INFO Completed 7 / 25 edges
13:24:22,896 root INFO Completed 9 / 25 edges
13:24:22,896 root INFO Completed 11 / 25 edges
13:24:22,896 root INFO Completed 13 / 25 edges
13:24:22,896 root INFO Completed 15 / 25 edges
13:24:22,896 root INFO Completed 17 / 25 edges
13:24:22,896 root INFO Completed 19 / 25 edges
13:24:22,896 root INFO Completed 21 / 25 edges
13:24:22,896 root INFO Completed 23 / 25 edges
13:24:22,896 root INFO Completed 25 / 25 edges
13:24:22,896 root INFO Completed preprocessing of transition probabilities for edges
13:24:22,896 root INFO Simulating walks on graph at time 1744910662.896491
13:24:22,896 root INFO Walk iteration: 1/10
13:24:22,897 root INFO Walk iteration: 2/10
13:24:22,897 root INFO Walk iteration: 3/10
13:24:22,898 root INFO Walk iteration: 4/10
13:24:22,898 root INFO Walk iteration: 5/10
13:24:22,899 root INFO Walk iteration: 6/10
13:24:22,900 root INFO Walk iteration: 7/10
13:24:22,900 root INFO Walk iteration: 8/10
13:24:22,901 root INFO Walk iteration: 9/10
13:24:22,901 root INFO Walk iteration: 10/10
13:24:22,902 root INFO Learning embeddings at time 1744910662.902466
13:24:22,902 gensim.models.word2vec INFO collecting all words and their counts
13:24:22,902 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:24:22,902 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
13:24:22,902 gensim.models.word2vec INFO Creating a fresh vocabulary
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T13:24:22.903060', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T13:24:22.903089', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
13:24:22,903 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T13:24:22.903198', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
13:24:22,903 gensim.models.word2vec INFO resetting layer weights
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T13:24:22.903484', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T13:24:22.903510', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:24:22,907 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 186997 effective words/s
13:24:22,910 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 205540 effective words/s
13:24:22,914 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205797 effective words/s
13:24:22,914 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170164 effective words/s', 'datetime': '2025-04-17T13:24:22.914464', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:24:22,914 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T13:24:22.914492', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:24:22,914 root INFO Completed. Ending time is 1744910662.9145138 Elapsed time is -0.018839597702026367
13:24:26,536 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,539 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,558 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:26,560 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,561 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,576 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,578 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,579 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:24:26,584 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
13:24:26,630 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:26,631 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,633 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:26,634 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,636 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:24:26,638 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:24:26,638 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:24:26,861 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:24:26,872 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:24:26,874 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
13:24:26,897 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:24:26,903 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:24:26,954 graphrag.cli.index INFO All workflows completed successfully.
14:02:27,768 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:02:28,700 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:29,429 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:02:29,434 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:02:29,436 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:02:29,437 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
14:02:29,437 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:02:29,437 graphrag.index.input.factory INFO using file storage for input
14:02:29,438 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:02:29,439 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:02:29,447 graphrag.index.input.text INFO Found 9 files, loading 9
14:02:29,448 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:02:29,455 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:02:29,485 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:02:29,487 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:02:29,500 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:02:29,563 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:02:29,565 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:02:29,568 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:02:29,568 root INFO Starting at time 1744912949.568873
14:02:29,568 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:02:29,568 root INFO Completed 1 / 24 vertices
14:02:29,568 root INFO Completed 3 / 24 vertices
14:02:29,568 root INFO Completed 5 / 24 vertices
14:02:29,569 root INFO Completed 7 / 24 vertices
14:02:29,569 root INFO Completed 9 / 24 vertices
14:02:29,569 root INFO Completed 11 / 24 vertices
14:02:29,569 root INFO Completed 13 / 24 vertices
14:02:29,569 root INFO Completed 15 / 24 vertices
14:02:29,569 root INFO Completed 17 / 24 vertices
14:02:29,569 root INFO Completed 19 / 24 vertices
14:02:29,569 root INFO Completed 21 / 24 vertices
14:02:29,569 root INFO Completed 23 / 24 vertices
14:02:29,569 root INFO Completed preprocessing of transition probabilities for vertices
14:02:29,569 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:02:29,569 root INFO Completed 1 / 25 edges
14:02:29,569 root INFO Completed 3 / 25 edges
14:02:29,569 root INFO Completed 5 / 25 edges
14:02:29,569 root INFO Completed 7 / 25 edges
14:02:29,569 root INFO Completed 9 / 25 edges
14:02:29,569 root INFO Completed 11 / 25 edges
14:02:29,569 root INFO Completed 13 / 25 edges
14:02:29,569 root INFO Completed 15 / 25 edges
14:02:29,569 root INFO Completed 17 / 25 edges
14:02:29,569 root INFO Completed 19 / 25 edges
14:02:29,569 root INFO Completed 21 / 25 edges
14:02:29,569 root INFO Completed 23 / 25 edges
14:02:29,569 root INFO Completed 25 / 25 edges
14:02:29,569 root INFO Completed preprocessing of transition probabilities for edges
14:02:29,569 root INFO Simulating walks on graph at time 1744912949.569695
14:02:29,569 root INFO Walk iteration: 1/10
14:02:29,570 root INFO Walk iteration: 2/10
14:02:29,570 root INFO Walk iteration: 3/10
14:02:29,571 root INFO Walk iteration: 4/10
14:02:29,572 root INFO Walk iteration: 5/10
14:02:29,572 root INFO Walk iteration: 6/10
14:02:29,573 root INFO Walk iteration: 7/10
14:02:29,573 root INFO Walk iteration: 8/10
14:02:29,574 root INFO Walk iteration: 9/10
14:02:29,575 root INFO Walk iteration: 10/10
14:02:29,575 root INFO Learning embeddings at time 1744912949.575618
14:02:29,575 gensim.models.word2vec INFO collecting all words and their counts
14:02:29,575 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:02:29,576 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:02:29,576 gensim.models.word2vec INFO Creating a fresh vocabulary
14:02:29,576 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T14:02:29.576206', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:02:29,576 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T14:02:29.576237', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:02:29,576 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:02:29,576 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:02:29,576 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T14:02:29.576347', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:02:29,576 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:02:29,576 gensim.models.word2vec INFO resetting layer weights
14:02:29,576 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T14:02:29.576636', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:02:29,576 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T14:02:29.576665', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:02:29,580 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 188438 effective words/s
14:02:29,584 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 202237 effective words/s
14:02:29,587 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205018 effective words/s
14:02:29,587 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 169849 effective words/s', 'datetime': '2025-04-17T14:02:29.587641', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:02:29,587 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T14:02:29.587668', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:02:29,587 root INFO Completed. Ending time is 1744912949.5876942 Elapsed time is -0.018821239471435547
14:02:33,236 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:02:33,238 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:02:33,258 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:02:33,259 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:02:33,261 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:02:33,276 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:02:33,277 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:02:33,278 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:02:33,284 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:02:33,330 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:02:33,331 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:02:33,332 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:02:33,334 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:02:33,335 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:02:33,338 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:02:33,338 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:02:33,557 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:02:33,584 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:02:33,590 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:02:33,595 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:02:33,601 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:02:33,655 graphrag.cli.index INFO All workflows completed successfully.
14:31:20,861 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:31:22,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:31:22,725 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:31:22,731 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:31:22,732 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:31:22,734 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
14:31:22,735 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
14:31:22,735 graphrag.index.input.factory INFO using file storage for input
14:31:22,736 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
14:31:22,737 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:31:22,746 graphrag.index.input.text INFO Found 9 files, loading 9
14:31:22,747 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:31:22,754 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:31:22,785 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:31:22,787 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:31:22,800 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:31:22,860 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:31:22,862 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:31:22,865 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:31:22,865 root INFO Starting at time 1744914682.865705
14:31:22,865 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:31:22,865 root INFO Completed 1 / 24 vertices
14:31:22,865 root INFO Completed 3 / 24 vertices
14:31:22,865 root INFO Completed 5 / 24 vertices
14:31:22,865 root INFO Completed 7 / 24 vertices
14:31:22,865 root INFO Completed 9 / 24 vertices
14:31:22,865 root INFO Completed 11 / 24 vertices
14:31:22,865 root INFO Completed 13 / 24 vertices
14:31:22,865 root INFO Completed 15 / 24 vertices
14:31:22,865 root INFO Completed 17 / 24 vertices
14:31:22,865 root INFO Completed 19 / 24 vertices
14:31:22,865 root INFO Completed 21 / 24 vertices
14:31:22,865 root INFO Completed 23 / 24 vertices
14:31:22,865 root INFO Completed preprocessing of transition probabilities for vertices
14:31:22,866 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:31:22,866 root INFO Completed 1 / 25 edges
14:31:22,866 root INFO Completed 3 / 25 edges
14:31:22,866 root INFO Completed 5 / 25 edges
14:31:22,866 root INFO Completed 7 / 25 edges
14:31:22,866 root INFO Completed 9 / 25 edges
14:31:22,866 root INFO Completed 11 / 25 edges
14:31:22,866 root INFO Completed 13 / 25 edges
14:31:22,866 root INFO Completed 15 / 25 edges
14:31:22,866 root INFO Completed 17 / 25 edges
14:31:22,866 root INFO Completed 19 / 25 edges
14:31:22,866 root INFO Completed 21 / 25 edges
14:31:22,866 root INFO Completed 23 / 25 edges
14:31:22,866 root INFO Completed 25 / 25 edges
14:31:22,866 root INFO Completed preprocessing of transition probabilities for edges
14:31:22,866 root INFO Simulating walks on graph at time 1744914682.866515
14:31:22,866 root INFO Walk iteration: 1/10
14:31:22,867 root INFO Walk iteration: 2/10
14:31:22,867 root INFO Walk iteration: 3/10
14:31:22,868 root INFO Walk iteration: 4/10
14:31:22,869 root INFO Walk iteration: 5/10
14:31:22,869 root INFO Walk iteration: 6/10
14:31:22,870 root INFO Walk iteration: 7/10
14:31:22,870 root INFO Walk iteration: 8/10
14:31:22,871 root INFO Walk iteration: 9/10
14:31:22,871 root INFO Walk iteration: 10/10
14:31:22,872 root INFO Learning embeddings at time 1744914682.8725362
14:31:22,872 gensim.models.word2vec INFO collecting all words and their counts
14:31:22,872 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:31:22,873 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:31:22,873 gensim.models.word2vec INFO Creating a fresh vocabulary
14:31:22,873 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T14:31:22.873127', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:31:22,873 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T14:31:22.873158', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:31:22,873 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:31:22,873 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:31:22,873 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T14:31:22.873267', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:31:22,873 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:31:22,873 gensim.models.word2vec INFO resetting layer weights
14:31:22,873 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T14:31:22.873557', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:31:22,873 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T14:31:22.873584', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:31:22,877 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 198306 effective words/s
14:31:22,880 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 206370 effective words/s
14:31:22,884 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 201483 effective words/s
14:31:22,884 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 169079 effective words/s', 'datetime': '2025-04-17T14:31:22.884611', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:31:22,884 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T14:31:22.884637', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:31:22,884 root INFO Completed. Ending time is 1744914682.884662 Elapsed time is -0.018956899642944336
14:31:26,447 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:31:26,450 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:31:26,469 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:31:26,470 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:31:26,472 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:31:26,487 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:31:26,488 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:31:26,490 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:31:26,495 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:31:26,541 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:31:26,543 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:31:26,544 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:31:26,546 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:31:26,547 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:31:26,550 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:31:26,550 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:31:26,774 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:31:26,785 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:31:26,788 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:31:26,810 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:31:26,817 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:31:26,867 graphrag.cli.index INFO All workflows completed successfully.
14:43:28,696 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:43:29,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:43:29,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:43:29,935 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:43:29,937 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:43:29,938 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
14:43:29,939 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:43:29,939 graphrag.index.input.factory INFO using file storage for input
14:43:29,940 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:43:29,941 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:43:29,951 graphrag.index.input.text INFO Found 9 files, loading 9
14:43:29,952 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:43:29,959 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:43:29,988 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:43:29,990 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:43:30,2 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:43:30,62 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:43:30,64 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:43:30,67 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:43:30,67 root INFO Starting at time 1744915410.0675561
14:43:30,67 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:43:30,67 root INFO Completed 1 / 24 vertices
14:43:30,67 root INFO Completed 3 / 24 vertices
14:43:30,67 root INFO Completed 5 / 24 vertices
14:43:30,67 root INFO Completed 7 / 24 vertices
14:43:30,67 root INFO Completed 9 / 24 vertices
14:43:30,67 root INFO Completed 11 / 24 vertices
14:43:30,67 root INFO Completed 13 / 24 vertices
14:43:30,67 root INFO Completed 15 / 24 vertices
14:43:30,67 root INFO Completed 17 / 24 vertices
14:43:30,67 root INFO Completed 19 / 24 vertices
14:43:30,67 root INFO Completed 21 / 24 vertices
14:43:30,67 root INFO Completed 23 / 24 vertices
14:43:30,67 root INFO Completed preprocessing of transition probabilities for vertices
14:43:30,67 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:43:30,67 root INFO Completed 1 / 25 edges
14:43:30,67 root INFO Completed 3 / 25 edges
14:43:30,67 root INFO Completed 5 / 25 edges
14:43:30,68 root INFO Completed 7 / 25 edges
14:43:30,68 root INFO Completed 9 / 25 edges
14:43:30,68 root INFO Completed 11 / 25 edges
14:43:30,68 root INFO Completed 13 / 25 edges
14:43:30,68 root INFO Completed 15 / 25 edges
14:43:30,68 root INFO Completed 17 / 25 edges
14:43:30,68 root INFO Completed 19 / 25 edges
14:43:30,68 root INFO Completed 21 / 25 edges
14:43:30,68 root INFO Completed 23 / 25 edges
14:43:30,68 root INFO Completed 25 / 25 edges
14:43:30,68 root INFO Completed preprocessing of transition probabilities for edges
14:43:30,68 root INFO Simulating walks on graph at time 1744915410.0683782
14:43:30,68 root INFO Walk iteration: 1/10
14:43:30,69 root INFO Walk iteration: 2/10
14:43:30,69 root INFO Walk iteration: 3/10
14:43:30,70 root INFO Walk iteration: 4/10
14:43:30,70 root INFO Walk iteration: 5/10
14:43:30,71 root INFO Walk iteration: 6/10
14:43:30,72 root INFO Walk iteration: 7/10
14:43:30,72 root INFO Walk iteration: 8/10
14:43:30,73 root INFO Walk iteration: 9/10
14:43:30,73 root INFO Walk iteration: 10/10
14:43:30,74 root INFO Learning embeddings at time 1744915410.074412
14:43:30,74 gensim.models.word2vec INFO collecting all words and their counts
14:43:30,74 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:43:30,74 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:43:30,74 gensim.models.word2vec INFO Creating a fresh vocabulary
14:43:30,75 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T14:43:30.074997', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:43:30,75 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T14:43:30.075026', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:43:30,75 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:43:30,75 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:43:30,75 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T14:43:30.075133', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:43:30,75 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:43:30,75 gensim.models.word2vec INFO resetting layer weights
14:43:30,75 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T14:43:30.075429', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:43:30,75 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T14:43:30.075455', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:43:30,79 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 196706 effective words/s
14:43:30,82 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209915 effective words/s
14:43:30,86 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 233707 effective words/s
14:43:30,86 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170588 effective words/s', 'datetime': '2025-04-17T14:43:30.086382', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:43:30,86 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T14:43:30.086410', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:43:30,86 root INFO Completed. Ending time is 1744915410.086433 Elapsed time is -0.01887679100036621
14:43:33,687 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:43:33,689 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:43:33,709 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:43:33,710 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:43:33,711 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:43:33,727 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:43:33,728 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:43:33,729 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:43:33,735 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:43:33,781 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:43:33,782 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:43:33,783 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:43:33,785 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:43:33,786 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:43:33,789 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:43:33,789 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:43:34,11 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:43:34,21 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:43:34,27 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:43:34,35 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:43:34,38 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:43:34,102 graphrag.cli.index INFO All workflows completed successfully.
14:47:17,836 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:47:18,833 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:47:19,653 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:47:19,658 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:47:19,659 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:47:19,661 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
14:47:19,661 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:47:19,661 graphrag.index.input.factory INFO using file storage for input
14:47:19,662 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:47:19,663 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:47:19,672 graphrag.index.input.text INFO Found 9 files, loading 9
14:47:19,673 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:47:19,680 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:47:19,710 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:47:19,712 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:47:19,725 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:47:19,785 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:47:19,786 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:47:19,789 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:47:19,789 root INFO Starting at time 1744915639.78998
14:47:19,790 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:47:19,790 root INFO Completed 1 / 24 vertices
14:47:19,790 root INFO Completed 3 / 24 vertices
14:47:19,790 root INFO Completed 5 / 24 vertices
14:47:19,790 root INFO Completed 7 / 24 vertices
14:47:19,790 root INFO Completed 9 / 24 vertices
14:47:19,790 root INFO Completed 11 / 24 vertices
14:47:19,790 root INFO Completed 13 / 24 vertices
14:47:19,790 root INFO Completed 15 / 24 vertices
14:47:19,790 root INFO Completed 17 / 24 vertices
14:47:19,790 root INFO Completed 19 / 24 vertices
14:47:19,790 root INFO Completed 21 / 24 vertices
14:47:19,790 root INFO Completed 23 / 24 vertices
14:47:19,790 root INFO Completed preprocessing of transition probabilities for vertices
14:47:19,790 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:47:19,790 root INFO Completed 1 / 25 edges
14:47:19,790 root INFO Completed 3 / 25 edges
14:47:19,790 root INFO Completed 5 / 25 edges
14:47:19,790 root INFO Completed 7 / 25 edges
14:47:19,790 root INFO Completed 9 / 25 edges
14:47:19,790 root INFO Completed 11 / 25 edges
14:47:19,790 root INFO Completed 13 / 25 edges
14:47:19,790 root INFO Completed 15 / 25 edges
14:47:19,790 root INFO Completed 17 / 25 edges
14:47:19,790 root INFO Completed 19 / 25 edges
14:47:19,790 root INFO Completed 21 / 25 edges
14:47:19,790 root INFO Completed 23 / 25 edges
14:47:19,790 root INFO Completed 25 / 25 edges
14:47:19,790 root INFO Completed preprocessing of transition probabilities for edges
14:47:19,790 root INFO Simulating walks on graph at time 1744915639.790796
14:47:19,790 root INFO Walk iteration: 1/10
14:47:19,791 root INFO Walk iteration: 2/10
14:47:19,792 root INFO Walk iteration: 3/10
14:47:19,792 root INFO Walk iteration: 4/10
14:47:19,793 root INFO Walk iteration: 5/10
14:47:19,793 root INFO Walk iteration: 6/10
14:47:19,794 root INFO Walk iteration: 7/10
14:47:19,795 root INFO Walk iteration: 8/10
14:47:19,795 root INFO Walk iteration: 9/10
14:47:19,796 root INFO Walk iteration: 10/10
14:47:19,796 root INFO Learning embeddings at time 1744915639.796715
14:47:19,797 gensim.models.word2vec INFO collecting all words and their counts
14:47:19,797 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:47:19,797 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:47:19,797 gensim.models.word2vec INFO Creating a fresh vocabulary
14:47:19,797 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T14:47:19.797300', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:47:19,797 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T14:47:19.797330', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:47:19,797 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:47:19,797 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:47:19,797 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T14:47:19.797441', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:47:19,797 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:47:19,797 gensim.models.word2vec INFO resetting layer weights
14:47:19,797 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T14:47:19.797736', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:47:19,797 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T14:47:19.797763', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:47:19,801 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 195376 effective words/s
14:47:19,805 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 237725 effective words/s
14:47:19,808 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204933 effective words/s
14:47:19,808 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 171551 effective words/s', 'datetime': '2025-04-17T14:47:19.808651', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:47:19,808 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T14:47:19.808680', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:47:19,808 root INFO Completed. Ending time is 1744915639.808706 Elapsed time is -0.018726110458374023
14:47:23,520 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:47:23,522 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:47:23,542 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:47:23,543 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:47:23,545 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:47:23,560 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:47:23,561 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:47:23,563 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:47:23,568 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:47:23,614 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:47:23,615 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:47:23,616 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:47:23,618 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:47:23,619 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:47:23,622 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:47:23,622 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:47:23,835 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:47:23,842 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:47:23,848 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:47:23,856 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:47:23,858 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:47:23,924 graphrag.cli.index INFO All workflows completed successfully.
15:03:15,401 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
15:03:16,349 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:17,272 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:03:17,293 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:03:17,295 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Trump_tarrifs_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Trump_tarrifs_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
15:03:17,296 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Trump_tarrifs_output
15:03:17,297 graphrag.index.input.factory INFO loading input from root_dir=Trump_tarrifs_input
15:03:17,297 graphrag.index.input.factory INFO using file storage for input
15:03:17,298 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Trump_tarrifs_input for files matching .*\.txt$
15:03:17,299 graphrag.index.input.text INFO found text files from Trump_tarrifs_input, found [('trump_tarrifs_4828.txt', {}), ('trump_tarrifs_2690.txt', {}), ('trump_tarrifs_9473.txt', {}), ('trump_tarrifs_4812.txt', {}), ('trump_tarrifs_436.txt', {}), ('trump_tarrifs_7999.txt', {}), ('trump_tarrifs_perplexity_response.txt', {})]
15:03:17,306 graphrag.index.input.text INFO Found 7 files, loading 7
15:03:17,307 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 7
15:03:17,315 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:03:17,341 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:03:17,343 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:03:17,356 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:03:22,243 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:26,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:27,550 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:29,652 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:31,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:32,34 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:32,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:32,525 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:33,577 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:35,860 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:36,672 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:36,817 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:37,970 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:44,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:03:44,527 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:03:44,528 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:03:44,532 root INFO Starting preprocessing of transition probabilities on graph with 8 nodes and 9 edges
15:03:44,532 root INFO Starting at time 1744916624.532036
15:03:44,532 root INFO Beginning preprocessing of transition probabilities for 8 vertices
15:03:44,532 root INFO Completed 1 / 8 vertices
15:03:44,532 root INFO Completed 2 / 8 vertices
15:03:44,532 root INFO Completed 3 / 8 vertices
15:03:44,532 root INFO Completed 4 / 8 vertices
15:03:44,532 root INFO Completed 5 / 8 vertices
15:03:44,532 root INFO Completed 6 / 8 vertices
15:03:44,532 root INFO Completed 7 / 8 vertices
15:03:44,532 root INFO Completed 8 / 8 vertices
15:03:44,532 root INFO Completed preprocessing of transition probabilities for vertices
15:03:44,532 root INFO Beginning preprocessing of transition probabilities for 9 edges
15:03:44,532 root INFO Completed 1 / 9 edges
15:03:44,532 root INFO Completed 2 / 9 edges
15:03:44,532 root INFO Completed 3 / 9 edges
15:03:44,532 root INFO Completed 4 / 9 edges
15:03:44,532 root INFO Completed 5 / 9 edges
15:03:44,532 root INFO Completed 6 / 9 edges
15:03:44,532 root INFO Completed 7 / 9 edges
15:03:44,532 root INFO Completed 8 / 9 edges
15:03:44,532 root INFO Completed 9 / 9 edges
15:03:44,532 root INFO Completed preprocessing of transition probabilities for edges
15:03:44,532 root INFO Simulating walks on graph at time 1744916624.532507
15:03:44,532 root INFO Walk iteration: 1/10
15:03:44,532 root INFO Walk iteration: 2/10
15:03:44,533 root INFO Walk iteration: 3/10
15:03:44,533 root INFO Walk iteration: 4/10
15:03:44,533 root INFO Walk iteration: 5/10
15:03:44,534 root INFO Walk iteration: 6/10
15:03:44,534 root INFO Walk iteration: 7/10
15:03:44,534 root INFO Walk iteration: 8/10
15:03:44,534 root INFO Walk iteration: 9/10
15:03:44,535 root INFO Walk iteration: 10/10
15:03:44,535 root INFO Learning embeddings at time 1744916624.5353532
15:03:44,535 gensim.models.word2vec INFO collecting all words and their counts
15:03:44,535 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
15:03:44,535 gensim.models.word2vec INFO collected 8 word types from a corpus of 1600 raw words and 80 sentences
15:03:44,535 gensim.models.word2vec INFO Creating a fresh vocabulary
15:03:44,535 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 8 unique words (100.00% of original 8, drops 0)', 'datetime': '2025-04-17T15:03:44.535790', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:03:44,535 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 1600 word corpus (100.00% of original 1600, drops 0)', 'datetime': '2025-04-17T15:03:44.535824', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:03:44,535 gensim.models.word2vec INFO deleting the raw counts dictionary of 8 items
15:03:44,535 gensim.models.word2vec INFO sample=0.001 downsamples 8 most-common words
15:03:44,535 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 146.7424655976301 word corpus (9.2%% of prior 1600)', 'datetime': '2025-04-17T15:03:44.535912', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:03:44,535 gensim.models.word2vec INFO estimated required memory for 8 words and 1536 dimensions: 102304 bytes
15:03:44,536 gensim.models.word2vec INFO resetting layer weights
15:03:44,536 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T15:03:44.536116', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
15:03:44,536 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 8 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T15:03:44.536150', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
15:03:44,537 gensim.models.word2vec INFO EPOCH 0: training on 1600 raw words (138 effective words) took 0.0s, 152507 effective words/s
15:03:44,538 gensim.models.word2vec INFO EPOCH 1: training on 1600 raw words (152 effective words) took 0.0s, 212130 effective words/s
15:03:44,539 gensim.models.word2vec INFO EPOCH 2: training on 1600 raw words (139 effective words) took 0.0s, 207605 effective words/s
15:03:44,539 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 4800 raw words (429 effective words) took 0.0s, 118392 effective words/s', 'datetime': '2025-04-17T15:03:44.539795', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
15:03:44,539 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=8, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T15:03:44.539830', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
15:03:44,539 root INFO Completed. Ending time is 1744916624.539854 Elapsed time is -0.007817983627319336
15:03:48,208 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:03:48,210 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:03:48,230 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:03:48,231 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:03:48,233 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:03:48,248 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:03:48,250 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:03:48,251 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:03:48,257 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 8
15:04:08,744 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:04:12,225 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:04:12,251 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:04:12,255 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:04:12,257 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:04:12,259 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:04:12,261 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
15:04:12,265 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
15:04:12,265 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
15:04:12,488 graphrag.index.operations.embed_text.strategies.openai INFO embedding 41 inputs via 41 snippets using 3 batches. max_batch_size=16, max_tokens=8191
15:04:13,292 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:04:13,342 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:04:13,966 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:04:14,162 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
15:04:14,164 graphrag.index.operations.embed_text.strategies.openai INFO embedding 2 inputs via 2 snippets using 1 batches. max_batch_size=16, max_tokens=8191
15:04:14,783 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:04:14,842 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
15:04:14,850 graphrag.index.operations.embed_text.strategies.openai INFO embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, max_tokens=8191
15:04:15,353 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:04:15,450 graphrag.cli.index INFO All workflows completed successfully.
15:16:59,636 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
15:17:00,442 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
15:17:01,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
15:17:01,354 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:17:01,355 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
15:17:01,356 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
15:17:01,356 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
15:17:01,356 graphrag.index.input.factory INFO using file storage for input
15:17:01,356 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
15:17:01,357 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
15:17:01,363 graphrag.index.input.text INFO Found 9 files, loading 9
15:17:01,364 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
15:17:01,371 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:17:01,400 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:17:01,402 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:17:01,415 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:17:01,476 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:17:01,478 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:17:01,481 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
15:17:01,481 root INFO Starting at time 1744917421.4816499
15:17:01,481 root INFO Beginning preprocessing of transition probabilities for 24 vertices
15:17:01,481 root INFO Completed 1 / 24 vertices
15:17:01,481 root INFO Completed 3 / 24 vertices
15:17:01,481 root INFO Completed 5 / 24 vertices
15:17:01,481 root INFO Completed 7 / 24 vertices
15:17:01,481 root INFO Completed 9 / 24 vertices
15:17:01,481 root INFO Completed 11 / 24 vertices
15:17:01,481 root INFO Completed 13 / 24 vertices
15:17:01,481 root INFO Completed 15 / 24 vertices
15:17:01,481 root INFO Completed 17 / 24 vertices
15:17:01,481 root INFO Completed 19 / 24 vertices
15:17:01,481 root INFO Completed 21 / 24 vertices
15:17:01,481 root INFO Completed 23 / 24 vertices
15:17:01,481 root INFO Completed preprocessing of transition probabilities for vertices
15:17:01,481 root INFO Beginning preprocessing of transition probabilities for 25 edges
15:17:01,481 root INFO Completed 1 / 25 edges
15:17:01,482 root INFO Completed 3 / 25 edges
15:17:01,482 root INFO Completed 5 / 25 edges
15:17:01,482 root INFO Completed 7 / 25 edges
15:17:01,482 root INFO Completed 9 / 25 edges
15:17:01,482 root INFO Completed 11 / 25 edges
15:17:01,482 root INFO Completed 13 / 25 edges
15:17:01,482 root INFO Completed 15 / 25 edges
15:17:01,482 root INFO Completed 17 / 25 edges
15:17:01,482 root INFO Completed 19 / 25 edges
15:17:01,482 root INFO Completed 21 / 25 edges
15:17:01,482 root INFO Completed 23 / 25 edges
15:17:01,482 root INFO Completed 25 / 25 edges
15:17:01,482 root INFO Completed preprocessing of transition probabilities for edges
15:17:01,482 root INFO Simulating walks on graph at time 1744917421.482482
15:17:01,482 root INFO Walk iteration: 1/10
15:17:01,483 root INFO Walk iteration: 2/10
15:17:01,483 root INFO Walk iteration: 3/10
15:17:01,484 root INFO Walk iteration: 4/10
15:17:01,485 root INFO Walk iteration: 5/10
15:17:01,485 root INFO Walk iteration: 6/10
15:17:01,486 root INFO Walk iteration: 7/10
15:17:01,486 root INFO Walk iteration: 8/10
15:17:01,487 root INFO Walk iteration: 9/10
15:17:01,487 root INFO Walk iteration: 10/10
15:17:01,488 root INFO Learning embeddings at time 1744917421.4885519
15:17:01,488 gensim.models.word2vec INFO collecting all words and their counts
15:17:01,488 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
15:17:01,489 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
15:17:01,489 gensim.models.word2vec INFO Creating a fresh vocabulary
15:17:01,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T15:17:01.489148', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:17:01,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T15:17:01.489179', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:17:01,489 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
15:17:01,489 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
15:17:01,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T15:17:01.489292', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
15:17:01,489 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
15:17:01,489 gensim.models.word2vec INFO resetting layer weights
15:17:01,489 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T15:17:01.489584', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
15:17:01,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T15:17:01.489611', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
15:17:01,493 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199358 effective words/s
15:17:01,496 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 211286 effective words/s
15:17:01,500 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 208206 effective words/s
15:17:01,500 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173723 effective words/s', 'datetime': '2025-04-17T15:17:01.500356', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
15:17:01,500 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T15:17:01.500383', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
15:17:01,500 root INFO Completed. Ending time is 1744917421.500406 Elapsed time is -0.01875615119934082
15:17:05,98 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:17:05,100 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:17:05,119 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:17:05,120 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:17:05,122 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:17:05,137 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:17:05,138 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:17:05,139 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:17:05,145 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
15:17:05,190 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:17:05,192 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:17:05,193 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:17:05,194 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:17:05,196 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
15:17:05,198 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
15:17:05,198 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
15:17:05,420 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
15:17:05,448 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
15:17:05,451 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
15:17:05,456 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
15:17:05,462 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
15:17:05,512 graphrag.cli.index INFO All workflows completed successfully.
23:10:45,523 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:10:51,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:10:52,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:10:52,756 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:10:52,758 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:10:52,759 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
23:10:52,759 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
23:10:52,760 graphrag.index.input.factory INFO using file storage for input
23:10:52,760 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
23:10:52,761 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:10:52,769 graphrag.index.input.text INFO Found 9 files, loading 9
23:10:52,772 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:10:52,794 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:10:52,836 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:10:52,838 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:10:52,849 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:10:52,908 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:10:52,910 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:10:52,913 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:10:52,913 root INFO Starting at time 1745291452.913214
23:10:52,913 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:10:52,913 root INFO Completed 1 / 24 vertices
23:10:52,913 root INFO Completed 3 / 24 vertices
23:10:52,913 root INFO Completed 5 / 24 vertices
23:10:52,913 root INFO Completed 7 / 24 vertices
23:10:52,913 root INFO Completed 9 / 24 vertices
23:10:52,913 root INFO Completed 11 / 24 vertices
23:10:52,913 root INFO Completed 13 / 24 vertices
23:10:52,913 root INFO Completed 15 / 24 vertices
23:10:52,913 root INFO Completed 17 / 24 vertices
23:10:52,913 root INFO Completed 19 / 24 vertices
23:10:52,913 root INFO Completed 21 / 24 vertices
23:10:52,913 root INFO Completed 23 / 24 vertices
23:10:52,913 root INFO Completed preprocessing of transition probabilities for vertices
23:10:52,913 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:10:52,913 root INFO Completed 1 / 25 edges
23:10:52,913 root INFO Completed 3 / 25 edges
23:10:52,913 root INFO Completed 5 / 25 edges
23:10:52,913 root INFO Completed 7 / 25 edges
23:10:52,913 root INFO Completed 9 / 25 edges
23:10:52,913 root INFO Completed 11 / 25 edges
23:10:52,913 root INFO Completed 13 / 25 edges
23:10:52,913 root INFO Completed 15 / 25 edges
23:10:52,913 root INFO Completed 17 / 25 edges
23:10:52,913 root INFO Completed 19 / 25 edges
23:10:52,913 root INFO Completed 21 / 25 edges
23:10:52,913 root INFO Completed 23 / 25 edges
23:10:52,913 root INFO Completed 25 / 25 edges
23:10:52,913 root INFO Completed preprocessing of transition probabilities for edges
23:10:52,913 root INFO Simulating walks on graph at time 1745291452.9139972
23:10:52,914 root INFO Walk iteration: 1/10
23:10:52,915 root INFO Walk iteration: 2/10
23:10:52,916 root INFO Walk iteration: 3/10
23:10:52,916 root INFO Walk iteration: 4/10
23:10:52,917 root INFO Walk iteration: 5/10
23:10:52,918 root INFO Walk iteration: 6/10
23:10:52,918 root INFO Walk iteration: 7/10
23:10:52,919 root INFO Walk iteration: 8/10
23:10:52,919 root INFO Walk iteration: 9/10
23:10:52,920 root INFO Walk iteration: 10/10
23:10:52,921 root INFO Learning embeddings at time 1745291452.921052
23:10:52,921 gensim.models.word2vec INFO collecting all words and their counts
23:10:52,921 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:10:52,921 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:10:52,921 gensim.models.word2vec INFO Creating a fresh vocabulary
23:10:52,921 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:10:52.921648', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:10:52,921 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:10:52.921678', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:10:52,921 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:10:52,921 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:10:52,921 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:10:52.921786', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:10:52,921 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:10:52,921 gensim.models.word2vec INFO resetting layer weights
23:10:52,922 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:10:52.922271', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:10:52,922 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:10:52.922298', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:10:52,926 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 160763 effective words/s
23:10:52,930 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 201656 effective words/s
23:10:52,933 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205267 effective words/s
23:10:52,933 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 161866 effective words/s', 'datetime': '2025-04-21T23:10:52.933814', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:10:52,933 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:10:52.933839', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:10:52,933 root INFO Completed. Ending time is 1745291452.933862 Elapsed time is -0.02064800262451172
23:10:56,593 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:10:56,595 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:10:56,615 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:10:56,616 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:10:56,618 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:10:56,633 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:10:56,635 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:10:56,636 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:10:56,642 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:10:56,689 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:10:56,690 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:10:56,692 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:10:56,693 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:10:56,695 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:10:56,698 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:10:56,698 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:10:56,934 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:10:56,962 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:10:56,964 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:10:56,986 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:10:56,993 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:10:57,42 graphrag.cli.index INFO All workflows completed successfully.
23:24:51,905 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:24:53,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:24:54,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:24:54,317 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:24:54,318 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:24:54,318 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:24:54,318 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:24:54,318 graphrag.index.input.factory INFO using file storage for input
23:24:54,319 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:24:54,319 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:24:54,324 graphrag.index.input.text INFO Found 9 files, loading 9
23:24:54,325 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:24:54,330 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:24:54,356 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:24:54,358 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:24:54,370 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:24:54,429 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:24:54,431 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:24:54,434 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:24:54,434 root INFO Starting at time 1745292294.434772
23:24:54,434 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:24:54,434 root INFO Completed 1 / 24 vertices
23:24:54,434 root INFO Completed 3 / 24 vertices
23:24:54,434 root INFO Completed 5 / 24 vertices
23:24:54,434 root INFO Completed 7 / 24 vertices
23:24:54,434 root INFO Completed 9 / 24 vertices
23:24:54,434 root INFO Completed 11 / 24 vertices
23:24:54,434 root INFO Completed 13 / 24 vertices
23:24:54,434 root INFO Completed 15 / 24 vertices
23:24:54,434 root INFO Completed 17 / 24 vertices
23:24:54,435 root INFO Completed 19 / 24 vertices
23:24:54,435 root INFO Completed 21 / 24 vertices
23:24:54,435 root INFO Completed 23 / 24 vertices
23:24:54,435 root INFO Completed preprocessing of transition probabilities for vertices
23:24:54,435 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:24:54,435 root INFO Completed 1 / 25 edges
23:24:54,435 root INFO Completed 3 / 25 edges
23:24:54,435 root INFO Completed 5 / 25 edges
23:24:54,435 root INFO Completed 7 / 25 edges
23:24:54,435 root INFO Completed 9 / 25 edges
23:24:54,435 root INFO Completed 11 / 25 edges
23:24:54,435 root INFO Completed 13 / 25 edges
23:24:54,435 root INFO Completed 15 / 25 edges
23:24:54,435 root INFO Completed 17 / 25 edges
23:24:54,435 root INFO Completed 19 / 25 edges
23:24:54,435 root INFO Completed 21 / 25 edges
23:24:54,435 root INFO Completed 23 / 25 edges
23:24:54,435 root INFO Completed 25 / 25 edges
23:24:54,435 root INFO Completed preprocessing of transition probabilities for edges
23:24:54,435 root INFO Simulating walks on graph at time 1745292294.4355872
23:24:54,435 root INFO Walk iteration: 1/10
23:24:54,436 root INFO Walk iteration: 2/10
23:24:54,436 root INFO Walk iteration: 3/10
23:24:54,437 root INFO Walk iteration: 4/10
23:24:54,438 root INFO Walk iteration: 5/10
23:24:54,438 root INFO Walk iteration: 6/10
23:24:54,439 root INFO Walk iteration: 7/10
23:24:54,439 root INFO Walk iteration: 8/10
23:24:54,440 root INFO Walk iteration: 9/10
23:24:54,441 root INFO Walk iteration: 10/10
23:24:54,441 root INFO Learning embeddings at time 1745292294.4416618
23:24:54,441 gensim.models.word2vec INFO collecting all words and their counts
23:24:54,442 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:24:54,442 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:24:54,442 gensim.models.word2vec INFO Creating a fresh vocabulary
23:24:54,442 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:24:54.442269', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:24:54,442 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:24:54.442300', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:24:54,442 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:24:54,442 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:24:54,442 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:24:54.442413', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:24:54,442 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:24:54,442 gensim.models.word2vec INFO resetting layer weights
23:24:54,442 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:24:54.442718', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:24:54,442 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:24:54.442746', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:24:54,446 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 189231 effective words/s
23:24:54,450 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 206829 effective words/s
23:24:54,453 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205361 effective words/s
23:24:54,453 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172539 effective words/s', 'datetime': '2025-04-21T23:24:54.453551', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:24:54,453 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:24:54.453576', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:24:54,453 root INFO Completed. Ending time is 1745292294.4536 Elapsed time is -0.01882791519165039
23:24:58,44 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:24:58,46 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:24:58,66 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:24:58,67 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:24:58,69 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:24:58,84 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:24:58,86 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:24:58,87 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:24:58,92 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:24:58,138 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:24:58,139 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:24:58,141 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:24:58,142 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:24:58,144 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:24:58,146 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:24:58,146 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:24:58,359 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:24:58,367 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:24:58,370 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:24:58,392 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:24:58,398 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:24:58,448 graphrag.cli.index INFO All workflows completed successfully.
23:32:58,978 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:32:59,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:33:00,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:33:00,16 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:33:00,17 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:33:00,18 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
23:33:00,18 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
23:33:00,18 graphrag.index.input.factory INFO using file storage for input
23:33:00,18 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
23:33:00,19 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:33:00,22 graphrag.index.input.text INFO Found 9 files, loading 9
23:33:00,23 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:33:00,27 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:00,49 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:00,51 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:00,62 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:00,121 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:00,123 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:00,126 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:33:00,126 root INFO Starting at time 1745292780.126485
23:33:00,126 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:33:00,126 root INFO Completed 1 / 24 vertices
23:33:00,126 root INFO Completed 3 / 24 vertices
23:33:00,126 root INFO Completed 5 / 24 vertices
23:33:00,126 root INFO Completed 7 / 24 vertices
23:33:00,126 root INFO Completed 9 / 24 vertices
23:33:00,126 root INFO Completed 11 / 24 vertices
23:33:00,126 root INFO Completed 13 / 24 vertices
23:33:00,126 root INFO Completed 15 / 24 vertices
23:33:00,126 root INFO Completed 17 / 24 vertices
23:33:00,126 root INFO Completed 19 / 24 vertices
23:33:00,126 root INFO Completed 21 / 24 vertices
23:33:00,126 root INFO Completed 23 / 24 vertices
23:33:00,126 root INFO Completed preprocessing of transition probabilities for vertices
23:33:00,126 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:33:00,126 root INFO Completed 1 / 25 edges
23:33:00,126 root INFO Completed 3 / 25 edges
23:33:00,126 root INFO Completed 5 / 25 edges
23:33:00,126 root INFO Completed 7 / 25 edges
23:33:00,126 root INFO Completed 9 / 25 edges
23:33:00,127 root INFO Completed 11 / 25 edges
23:33:00,127 root INFO Completed 13 / 25 edges
23:33:00,127 root INFO Completed 15 / 25 edges
23:33:00,127 root INFO Completed 17 / 25 edges
23:33:00,127 root INFO Completed 19 / 25 edges
23:33:00,127 root INFO Completed 21 / 25 edges
23:33:00,127 root INFO Completed 23 / 25 edges
23:33:00,127 root INFO Completed 25 / 25 edges
23:33:00,127 root INFO Completed preprocessing of transition probabilities for edges
23:33:00,127 root INFO Simulating walks on graph at time 1745292780.1272929
23:33:00,127 root INFO Walk iteration: 1/10
23:33:00,128 root INFO Walk iteration: 2/10
23:33:00,128 root INFO Walk iteration: 3/10
23:33:00,129 root INFO Walk iteration: 4/10
23:33:00,129 root INFO Walk iteration: 5/10
23:33:00,130 root INFO Walk iteration: 6/10
23:33:00,130 root INFO Walk iteration: 7/10
23:33:00,131 root INFO Walk iteration: 8/10
23:33:00,132 root INFO Walk iteration: 9/10
23:33:00,132 root INFO Walk iteration: 10/10
23:33:00,133 root INFO Learning embeddings at time 1745292780.133296
23:33:00,133 gensim.models.word2vec INFO collecting all words and their counts
23:33:00,133 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:33:00,133 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:33:00,133 gensim.models.word2vec INFO Creating a fresh vocabulary
23:33:00,133 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:33:00.133916', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:00,133 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:33:00.133948', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:00,134 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:33:00,134 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:33:00,134 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:33:00.134062', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:00,134 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:33:00,134 gensim.models.word2vec INFO resetting layer weights
23:33:00,134 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:33:00.134369', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:33:00,134 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:33:00.134397', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:33:00,138 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 194602 effective words/s
23:33:00,141 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 234318 effective words/s
23:33:00,145 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204416 effective words/s
23:33:00,145 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 169507 effective words/s', 'datetime': '2025-04-21T23:33:00.145397', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:33:00,145 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:33:00.145426', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:33:00,145 root INFO Completed. Ending time is 1745292780.145451 Elapsed time is -0.018965959548950195
23:33:03,743 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:03,745 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:03,765 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:03,766 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:03,767 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:03,783 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:03,784 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:03,785 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:33:03,791 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:33:03,836 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:03,838 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:03,839 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:03,840 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:03,842 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:33:03,844 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:33:03,845 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:33:04,82 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:33:04,119 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:33:04,121 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:33:04,143 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:33:04,146 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:33:04,194 graphrag.cli.index INFO All workflows completed successfully.
23:33:47,867 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:33:48,640 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:33:49,180 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:33:49,182 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:33:49,183 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:33:49,184 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:33:49,184 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:33:49,184 graphrag.index.input.factory INFO using file storage for input
23:33:49,184 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:33:49,185 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:33:49,189 graphrag.index.input.text INFO Found 9 files, loading 9
23:33:49,189 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:33:49,193 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:49,216 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:49,218 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:49,229 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:49,288 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:49,290 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:49,293 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:33:49,293 root INFO Starting at time 1745292829.293931
23:33:49,293 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:33:49,293 root INFO Completed 1 / 24 vertices
23:33:49,294 root INFO Completed 3 / 24 vertices
23:33:49,294 root INFO Completed 5 / 24 vertices
23:33:49,294 root INFO Completed 7 / 24 vertices
23:33:49,294 root INFO Completed 9 / 24 vertices
23:33:49,294 root INFO Completed 11 / 24 vertices
23:33:49,294 root INFO Completed 13 / 24 vertices
23:33:49,294 root INFO Completed 15 / 24 vertices
23:33:49,294 root INFO Completed 17 / 24 vertices
23:33:49,294 root INFO Completed 19 / 24 vertices
23:33:49,294 root INFO Completed 21 / 24 vertices
23:33:49,294 root INFO Completed 23 / 24 vertices
23:33:49,294 root INFO Completed preprocessing of transition probabilities for vertices
23:33:49,294 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:33:49,294 root INFO Completed 1 / 25 edges
23:33:49,294 root INFO Completed 3 / 25 edges
23:33:49,294 root INFO Completed 5 / 25 edges
23:33:49,294 root INFO Completed 7 / 25 edges
23:33:49,294 root INFO Completed 9 / 25 edges
23:33:49,294 root INFO Completed 11 / 25 edges
23:33:49,294 root INFO Completed 13 / 25 edges
23:33:49,294 root INFO Completed 15 / 25 edges
23:33:49,294 root INFO Completed 17 / 25 edges
23:33:49,294 root INFO Completed 19 / 25 edges
23:33:49,294 root INFO Completed 21 / 25 edges
23:33:49,294 root INFO Completed 23 / 25 edges
23:33:49,294 root INFO Completed 25 / 25 edges
23:33:49,294 root INFO Completed preprocessing of transition probabilities for edges
23:33:49,294 root INFO Simulating walks on graph at time 1745292829.2947378
23:33:49,294 root INFO Walk iteration: 1/10
23:33:49,295 root INFO Walk iteration: 2/10
23:33:49,296 root INFO Walk iteration: 3/10
23:33:49,296 root INFO Walk iteration: 4/10
23:33:49,297 root INFO Walk iteration: 5/10
23:33:49,297 root INFO Walk iteration: 6/10
23:33:49,298 root INFO Walk iteration: 7/10
23:33:49,298 root INFO Walk iteration: 8/10
23:33:49,299 root INFO Walk iteration: 9/10
23:33:49,300 root INFO Walk iteration: 10/10
23:33:49,300 root INFO Learning embeddings at time 1745292829.300769
23:33:49,301 gensim.models.word2vec INFO collecting all words and their counts
23:33:49,301 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:33:49,301 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:33:49,301 gensim.models.word2vec INFO Creating a fresh vocabulary
23:33:49,301 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:33:49.301377', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:49,301 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:33:49.301408', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:49,301 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:33:49,301 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:33:49,301 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:33:49.301518', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:33:49,301 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:33:49,301 gensim.models.word2vec INFO resetting layer weights
23:33:49,301 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:33:49.301805', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:33:49,301 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:33:49.301832', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:33:49,305 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 191131 effective words/s
23:33:49,309 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 206808 effective words/s
23:33:49,312 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 202156 effective words/s
23:33:49,312 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 167799 effective words/s', 'datetime': '2025-04-21T23:33:49.312942', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:33:49,312 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:33:49.312976', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:33:49,313 root INFO Completed. Ending time is 1745292829.3130019 Elapsed time is -0.019070863723754883
23:33:53,108 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:53,110 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:53,130 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:53,131 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:53,133 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:53,148 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:53,149 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:53,150 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:33:53,155 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:33:53,202 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:33:53,203 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:33:53,205 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:33:53,206 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:33:53,208 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:33:53,211 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:33:53,211 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:33:53,423 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:33:53,449 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:33:53,455 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:33:53,464 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:33:53,467 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:33:53,516 graphrag.cli.index INFO All workflows completed successfully.
23:38:14,901 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:38:15,528 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:38:16,417 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:38:16,422 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:38:16,424 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:38:16,426 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:38:16,426 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:38:16,427 graphrag.index.input.factory INFO using file storage for input
23:38:16,427 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:38:16,428 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:38:16,436 graphrag.index.input.text INFO Found 9 files, loading 9
23:38:16,437 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:38:16,443 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:38:16,474 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:38:16,475 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:38:16,488 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:38:16,547 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:38:16,549 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:38:16,552 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:38:16,552 root INFO Starting at time 1745293096.552108
23:38:16,552 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:38:16,552 root INFO Completed 1 / 24 vertices
23:38:16,552 root INFO Completed 3 / 24 vertices
23:38:16,552 root INFO Completed 5 / 24 vertices
23:38:16,552 root INFO Completed 7 / 24 vertices
23:38:16,552 root INFO Completed 9 / 24 vertices
23:38:16,552 root INFO Completed 11 / 24 vertices
23:38:16,552 root INFO Completed 13 / 24 vertices
23:38:16,552 root INFO Completed 15 / 24 vertices
23:38:16,552 root INFO Completed 17 / 24 vertices
23:38:16,552 root INFO Completed 19 / 24 vertices
23:38:16,552 root INFO Completed 21 / 24 vertices
23:38:16,552 root INFO Completed 23 / 24 vertices
23:38:16,552 root INFO Completed preprocessing of transition probabilities for vertices
23:38:16,552 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:38:16,552 root INFO Completed 1 / 25 edges
23:38:16,552 root INFO Completed 3 / 25 edges
23:38:16,552 root INFO Completed 5 / 25 edges
23:38:16,552 root INFO Completed 7 / 25 edges
23:38:16,552 root INFO Completed 9 / 25 edges
23:38:16,552 root INFO Completed 11 / 25 edges
23:38:16,552 root INFO Completed 13 / 25 edges
23:38:16,552 root INFO Completed 15 / 25 edges
23:38:16,552 root INFO Completed 17 / 25 edges
23:38:16,552 root INFO Completed 19 / 25 edges
23:38:16,552 root INFO Completed 21 / 25 edges
23:38:16,552 root INFO Completed 23 / 25 edges
23:38:16,552 root INFO Completed 25 / 25 edges
23:38:16,552 root INFO Completed preprocessing of transition probabilities for edges
23:38:16,552 root INFO Simulating walks on graph at time 1745293096.552937
23:38:16,553 root INFO Walk iteration: 1/10
23:38:16,553 root INFO Walk iteration: 2/10
23:38:16,554 root INFO Walk iteration: 3/10
23:38:16,554 root INFO Walk iteration: 4/10
23:38:16,555 root INFO Walk iteration: 5/10
23:38:16,556 root INFO Walk iteration: 6/10
23:38:16,556 root INFO Walk iteration: 7/10
23:38:16,557 root INFO Walk iteration: 8/10
23:38:16,557 root INFO Walk iteration: 9/10
23:38:16,558 root INFO Walk iteration: 10/10
23:38:16,558 root INFO Learning embeddings at time 1745293096.558888
23:38:16,559 gensim.models.word2vec INFO collecting all words and their counts
23:38:16,559 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:38:16,559 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:38:16,559 gensim.models.word2vec INFO Creating a fresh vocabulary
23:38:16,559 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:38:16.559489', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:38:16,559 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:38:16.559519', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:38:16,559 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:38:16,559 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:38:16,559 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:38:16.559628', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:38:16,559 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:38:16,559 gensim.models.word2vec INFO resetting layer weights
23:38:16,559 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:38:16.559922', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:38:16,559 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:38:16.559954', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:38:16,563 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 205348 effective words/s
23:38:16,567 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 214453 effective words/s
23:38:16,570 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 209477 effective words/s
23:38:16,570 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 174974 effective words/s', 'datetime': '2025-04-21T23:38:16.570610', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:38:16,570 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:38:16.570641', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:38:16,570 root INFO Completed. Ending time is 1745293096.570667 Elapsed time is -0.018558979034423828
23:38:20,196 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:38:20,198 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:38:20,217 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:38:20,218 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:38:20,220 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:38:20,235 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:38:20,236 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:38:20,238 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:38:20,242 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:38:20,287 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:38:20,288 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:38:20,290 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:38:20,291 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:38:20,293 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:38:20,295 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:38:20,295 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:38:20,506 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:38:20,529 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:38:20,535 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:38:20,543 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:38:20,545 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:38:20,593 graphrag.cli.index INFO All workflows completed successfully.
23:42:38,850 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:42:39,725 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:42:41,347 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:42:41,352 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:42:41,354 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:42:41,355 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:42:41,355 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:42:41,355 graphrag.index.input.factory INFO using file storage for input
23:42:41,356 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:42:41,358 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:42:41,364 graphrag.index.input.text INFO Found 9 files, loading 9
23:42:41,365 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:42:41,372 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:42:41,402 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:42:41,404 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:42:41,416 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:42:41,476 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:42:41,478 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:42:41,481 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:42:41,481 root INFO Starting at time 1745293361.48149
23:42:41,481 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:42:41,481 root INFO Completed 1 / 24 vertices
23:42:41,481 root INFO Completed 3 / 24 vertices
23:42:41,481 root INFO Completed 5 / 24 vertices
23:42:41,481 root INFO Completed 7 / 24 vertices
23:42:41,481 root INFO Completed 9 / 24 vertices
23:42:41,481 root INFO Completed 11 / 24 vertices
23:42:41,481 root INFO Completed 13 / 24 vertices
23:42:41,481 root INFO Completed 15 / 24 vertices
23:42:41,481 root INFO Completed 17 / 24 vertices
23:42:41,481 root INFO Completed 19 / 24 vertices
23:42:41,481 root INFO Completed 21 / 24 vertices
23:42:41,481 root INFO Completed 23 / 24 vertices
23:42:41,481 root INFO Completed preprocessing of transition probabilities for vertices
23:42:41,481 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:42:41,481 root INFO Completed 1 / 25 edges
23:42:41,481 root INFO Completed 3 / 25 edges
23:42:41,481 root INFO Completed 5 / 25 edges
23:42:41,481 root INFO Completed 7 / 25 edges
23:42:41,482 root INFO Completed 9 / 25 edges
23:42:41,482 root INFO Completed 11 / 25 edges
23:42:41,482 root INFO Completed 13 / 25 edges
23:42:41,482 root INFO Completed 15 / 25 edges
23:42:41,482 root INFO Completed 17 / 25 edges
23:42:41,482 root INFO Completed 19 / 25 edges
23:42:41,482 root INFO Completed 21 / 25 edges
23:42:41,482 root INFO Completed 23 / 25 edges
23:42:41,482 root INFO Completed 25 / 25 edges
23:42:41,482 root INFO Completed preprocessing of transition probabilities for edges
23:42:41,482 root INFO Simulating walks on graph at time 1745293361.48235
23:42:41,482 root INFO Walk iteration: 1/10
23:42:41,483 root INFO Walk iteration: 2/10
23:42:41,483 root INFO Walk iteration: 3/10
23:42:41,484 root INFO Walk iteration: 4/10
23:42:41,484 root INFO Walk iteration: 5/10
23:42:41,485 root INFO Walk iteration: 6/10
23:42:41,486 root INFO Walk iteration: 7/10
23:42:41,486 root INFO Walk iteration: 8/10
23:42:41,487 root INFO Walk iteration: 9/10
23:42:41,487 root INFO Walk iteration: 10/10
23:42:41,488 root INFO Learning embeddings at time 1745293361.488518
23:42:41,488 gensim.models.word2vec INFO collecting all words and their counts
23:42:41,488 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:42:41,489 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:42:41,489 gensim.models.word2vec INFO Creating a fresh vocabulary
23:42:41,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:42:41.489115', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:42:41,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:42:41.489147', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:42:41,489 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:42:41,489 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:42:41,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:42:41.489256', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:42:41,489 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:42:41,489 gensim.models.word2vec INFO resetting layer weights
23:42:41,489 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:42:41.489543', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:42:41,489 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:42:41.489571', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:42:41,493 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 198607 effective words/s
23:42:41,496 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 204591 effective words/s
23:42:41,500 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 227887 effective words/s
23:42:41,500 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 169845 effective words/s', 'datetime': '2025-04-21T23:42:41.500548', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:42:41,500 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:42:41.500579', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:42:41,500 root INFO Completed. Ending time is 1745293361.500607 Elapsed time is -0.019117116928100586
23:42:45,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:42:45,98 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:42:45,118 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:42:45,119 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:42:45,120 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:42:45,135 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:42:45,137 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:42:45,138 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:42:45,144 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:42:45,189 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:42:45,191 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:42:45,192 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:42:45,194 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:42:45,195 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:42:45,198 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:42:45,198 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:42:45,410 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:42:45,434 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:42:45,440 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:42:45,448 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:42:45,451 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:42:45,499 graphrag.cli.index INFO All workflows completed successfully.
23:47:15,855 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:47:16,479 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:47:16,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:47:16,866 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:47:16,868 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:47:16,869 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:47:16,870 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:47:16,870 graphrag.index.input.factory INFO using file storage for input
23:47:16,871 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:47:16,871 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:47:16,878 graphrag.index.input.text INFO Found 9 files, loading 9
23:47:16,880 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:47:16,888 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:47:16,918 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:47:16,920 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:47:16,933 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:47:16,993 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:47:16,995 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:47:16,998 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:47:16,998 root INFO Starting at time 1745293636.9983912
23:47:16,998 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:47:16,998 root INFO Completed 1 / 24 vertices
23:47:16,998 root INFO Completed 3 / 24 vertices
23:47:16,998 root INFO Completed 5 / 24 vertices
23:47:16,998 root INFO Completed 7 / 24 vertices
23:47:16,998 root INFO Completed 9 / 24 vertices
23:47:16,998 root INFO Completed 11 / 24 vertices
23:47:16,998 root INFO Completed 13 / 24 vertices
23:47:16,998 root INFO Completed 15 / 24 vertices
23:47:16,998 root INFO Completed 17 / 24 vertices
23:47:16,998 root INFO Completed 19 / 24 vertices
23:47:16,998 root INFO Completed 21 / 24 vertices
23:47:16,998 root INFO Completed 23 / 24 vertices
23:47:16,998 root INFO Completed preprocessing of transition probabilities for vertices
23:47:16,998 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:47:16,998 root INFO Completed 1 / 25 edges
23:47:16,998 root INFO Completed 3 / 25 edges
23:47:16,998 root INFO Completed 5 / 25 edges
23:47:16,998 root INFO Completed 7 / 25 edges
23:47:16,998 root INFO Completed 9 / 25 edges
23:47:16,998 root INFO Completed 11 / 25 edges
23:47:16,998 root INFO Completed 13 / 25 edges
23:47:16,999 root INFO Completed 15 / 25 edges
23:47:16,999 root INFO Completed 17 / 25 edges
23:47:16,999 root INFO Completed 19 / 25 edges
23:47:16,999 root INFO Completed 21 / 25 edges
23:47:16,999 root INFO Completed 23 / 25 edges
23:47:16,999 root INFO Completed 25 / 25 edges
23:47:16,999 root INFO Completed preprocessing of transition probabilities for edges
23:47:16,999 root INFO Simulating walks on graph at time 1745293636.999205
23:47:16,999 root INFO Walk iteration: 1/10
23:47:16,999 root INFO Walk iteration: 2/10
23:47:17,0 root INFO Walk iteration: 3/10
23:47:17,1 root INFO Walk iteration: 4/10
23:47:17,1 root INFO Walk iteration: 5/10
23:47:17,2 root INFO Walk iteration: 6/10
23:47:17,2 root INFO Walk iteration: 7/10
23:47:17,3 root INFO Walk iteration: 8/10
23:47:17,4 root INFO Walk iteration: 9/10
23:47:17,4 root INFO Walk iteration: 10/10
23:47:17,5 root INFO Learning embeddings at time 1745293637.0052118
23:47:17,5 gensim.models.word2vec INFO collecting all words and their counts
23:47:17,5 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:47:17,5 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:47:17,5 gensim.models.word2vec INFO Creating a fresh vocabulary
23:47:17,5 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:47:17.005854', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:47:17,5 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:47:17.005887', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:47:17,5 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:47:17,5 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:47:17,6 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:47:17.006001', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:47:17,6 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:47:17,6 gensim.models.word2vec INFO resetting layer weights
23:47:17,6 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:47:17.006310', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:47:17,6 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:47:17.006338', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:47:17,10 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 196494 effective words/s
23:47:17,13 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209017 effective words/s
23:47:17,17 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 206465 effective words/s
23:47:17,17 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172266 effective words/s', 'datetime': '2025-04-21T23:47:17.017161', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:47:17,17 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:47:17.017186', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:47:17,17 root INFO Completed. Ending time is 1745293637.017208 Elapsed time is -0.01881694793701172
23:47:20,607 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:47:20,610 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:47:20,630 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:47:20,631 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:47:20,633 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:47:20,648 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:47:20,649 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:47:20,651 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:47:20,656 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:47:20,701 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:47:20,702 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:47:20,704 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:47:20,705 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:47:20,706 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:47:20,709 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:47:20,709 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:47:20,925 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:47:20,935 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:47:20,938 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:47:20,943 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:47:20,946 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:47:21,11 graphrag.cli.index INFO All workflows completed successfully.
23:50:22,653 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:50:23,613 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:50:24,386 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:50:24,393 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:50:24,394 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:50:24,396 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:50:24,396 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:50:24,396 graphrag.index.input.factory INFO using file storage for input
23:50:24,397 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:50:24,398 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:50:24,405 graphrag.index.input.text INFO Found 9 files, loading 9
23:50:24,406 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:50:24,413 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:50:24,443 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:50:24,445 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:50:24,458 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:50:24,520 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:50:24,522 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:50:24,525 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:50:24,525 root INFO Starting at time 1745293824.525837
23:50:24,525 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:50:24,525 root INFO Completed 1 / 24 vertices
23:50:24,525 root INFO Completed 3 / 24 vertices
23:50:24,525 root INFO Completed 5 / 24 vertices
23:50:24,525 root INFO Completed 7 / 24 vertices
23:50:24,525 root INFO Completed 9 / 24 vertices
23:50:24,525 root INFO Completed 11 / 24 vertices
23:50:24,526 root INFO Completed 13 / 24 vertices
23:50:24,526 root INFO Completed 15 / 24 vertices
23:50:24,526 root INFO Completed 17 / 24 vertices
23:50:24,526 root INFO Completed 19 / 24 vertices
23:50:24,526 root INFO Completed 21 / 24 vertices
23:50:24,526 root INFO Completed 23 / 24 vertices
23:50:24,526 root INFO Completed preprocessing of transition probabilities for vertices
23:50:24,526 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:50:24,526 root INFO Completed 1 / 25 edges
23:50:24,526 root INFO Completed 3 / 25 edges
23:50:24,526 root INFO Completed 5 / 25 edges
23:50:24,526 root INFO Completed 7 / 25 edges
23:50:24,526 root INFO Completed 9 / 25 edges
23:50:24,526 root INFO Completed 11 / 25 edges
23:50:24,526 root INFO Completed 13 / 25 edges
23:50:24,526 root INFO Completed 15 / 25 edges
23:50:24,526 root INFO Completed 17 / 25 edges
23:50:24,526 root INFO Completed 19 / 25 edges
23:50:24,526 root INFO Completed 21 / 25 edges
23:50:24,526 root INFO Completed 23 / 25 edges
23:50:24,526 root INFO Completed 25 / 25 edges
23:50:24,526 root INFO Completed preprocessing of transition probabilities for edges
23:50:24,526 root INFO Simulating walks on graph at time 1745293824.526654
23:50:24,526 root INFO Walk iteration: 1/10
23:50:24,527 root INFO Walk iteration: 2/10
23:50:24,527 root INFO Walk iteration: 3/10
23:50:24,528 root INFO Walk iteration: 4/10
23:50:24,529 root INFO Walk iteration: 5/10
23:50:24,529 root INFO Walk iteration: 6/10
23:50:24,530 root INFO Walk iteration: 7/10
23:50:24,530 root INFO Walk iteration: 8/10
23:50:24,531 root INFO Walk iteration: 9/10
23:50:24,532 root INFO Walk iteration: 10/10
23:50:24,532 root INFO Learning embeddings at time 1745293824.532733
23:50:24,533 gensim.models.word2vec INFO collecting all words and their counts
23:50:24,533 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:50:24,533 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:50:24,533 gensim.models.word2vec INFO Creating a fresh vocabulary
23:50:24,533 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:50:24.533364', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:50:24,533 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:50:24.533396', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:50:24,533 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:50:24,533 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:50:24,533 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:50:24.533508', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:50:24,533 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:50:24,533 gensim.models.word2vec INFO resetting layer weights
23:50:24,533 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:50:24.533796', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:50:24,533 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:50:24.533823', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:50:24,537 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 204986 effective words/s
23:50:24,540 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 212116 effective words/s
23:50:24,544 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 238219 effective words/s
23:50:24,544 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 175462 effective words/s', 'datetime': '2025-04-21T23:50:24.544448', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:50:24,544 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:50:24.544474', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:50:24,544 root INFO Completed. Ending time is 1745293824.544498 Elapsed time is -0.018661022186279297
23:50:28,136 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:50:28,138 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:50:28,157 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:50:28,159 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:50:28,160 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:50:28,175 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:50:28,177 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:50:28,178 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:50:28,183 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:50:28,229 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:50:28,231 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:50:28,232 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:50:28,233 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:50:28,235 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:50:28,237 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:50:28,237 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:50:28,449 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:50:28,474 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:50:28,477 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:50:28,482 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:50:28,488 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:50:28,538 graphrag.cli.index INFO All workflows completed successfully.
23:52:17,946 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:52:18,768 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:52:19,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:52:19,177 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:52:19,177 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:52:19,178 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:52:19,178 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:52:19,178 graphrag.index.input.factory INFO using file storage for input
23:52:19,178 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:52:19,178 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:52:19,181 graphrag.index.input.text INFO Found 9 files, loading 9
23:52:19,182 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:52:19,186 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:19,207 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:19,208 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:19,219 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:19,279 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:19,280 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:19,284 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:52:19,284 root INFO Starting at time 1745293939.284197
23:52:19,284 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:52:19,284 root INFO Completed 1 / 24 vertices
23:52:19,284 root INFO Completed 3 / 24 vertices
23:52:19,284 root INFO Completed 5 / 24 vertices
23:52:19,284 root INFO Completed 7 / 24 vertices
23:52:19,284 root INFO Completed 9 / 24 vertices
23:52:19,284 root INFO Completed 11 / 24 vertices
23:52:19,284 root INFO Completed 13 / 24 vertices
23:52:19,284 root INFO Completed 15 / 24 vertices
23:52:19,284 root INFO Completed 17 / 24 vertices
23:52:19,284 root INFO Completed 19 / 24 vertices
23:52:19,284 root INFO Completed 21 / 24 vertices
23:52:19,284 root INFO Completed 23 / 24 vertices
23:52:19,284 root INFO Completed preprocessing of transition probabilities for vertices
23:52:19,284 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:52:19,284 root INFO Completed 1 / 25 edges
23:52:19,284 root INFO Completed 3 / 25 edges
23:52:19,284 root INFO Completed 5 / 25 edges
23:52:19,284 root INFO Completed 7 / 25 edges
23:52:19,284 root INFO Completed 9 / 25 edges
23:52:19,284 root INFO Completed 11 / 25 edges
23:52:19,284 root INFO Completed 13 / 25 edges
23:52:19,284 root INFO Completed 15 / 25 edges
23:52:19,284 root INFO Completed 17 / 25 edges
23:52:19,284 root INFO Completed 19 / 25 edges
23:52:19,284 root INFO Completed 21 / 25 edges
23:52:19,284 root INFO Completed 23 / 25 edges
23:52:19,284 root INFO Completed 25 / 25 edges
23:52:19,284 root INFO Completed preprocessing of transition probabilities for edges
23:52:19,285 root INFO Simulating walks on graph at time 1745293939.285003
23:52:19,285 root INFO Walk iteration: 1/10
23:52:19,285 root INFO Walk iteration: 2/10
23:52:19,286 root INFO Walk iteration: 3/10
23:52:19,286 root INFO Walk iteration: 4/10
23:52:19,287 root INFO Walk iteration: 5/10
23:52:19,288 root INFO Walk iteration: 6/10
23:52:19,288 root INFO Walk iteration: 7/10
23:52:19,289 root INFO Walk iteration: 8/10
23:52:19,290 root INFO Walk iteration: 9/10
23:52:19,290 root INFO Walk iteration: 10/10
23:52:19,291 root INFO Learning embeddings at time 1745293939.2911968
23:52:19,291 gensim.models.word2vec INFO collecting all words and their counts
23:52:19,291 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:52:19,291 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:52:19,291 gensim.models.word2vec INFO Creating a fresh vocabulary
23:52:19,291 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:52:19.291814', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:19,291 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:52:19.291846', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:19,291 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:52:19,291 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:52:19,291 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:52:19.291958', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:19,292 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:52:19,292 gensim.models.word2vec INFO resetting layer weights
23:52:19,292 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:52:19.292250', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:52:19,292 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:52:19.292278', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:52:19,295 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 202973 effective words/s
23:52:19,299 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 237325 effective words/s
23:52:19,303 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 206114 effective words/s
23:52:19,303 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173034 effective words/s', 'datetime': '2025-04-21T23:52:19.303052', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:52:19,303 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:52:19.303079', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:52:19,303 root INFO Completed. Ending time is 1745293939.303103 Elapsed time is -0.0189058780670166
23:52:23,54 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:23,56 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:23,76 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:23,77 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:23,79 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:23,94 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:23,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:23,97 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:52:23,102 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:52:23,148 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:23,150 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:23,151 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:23,153 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:23,154 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:52:23,157 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:52:23,157 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:52:23,374 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:52:23,384 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:52:23,386 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:52:23,408 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:52:23,411 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:52:23,461 graphrag.cli.index INFO All workflows completed successfully.
23:52:47,767 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:52:48,362 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:52:48,976 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:52:48,980 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:52:48,981 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:52:48,982 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:52:48,983 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:52:48,983 graphrag.index.input.factory INFO using file storage for input
23:52:48,983 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:52:48,984 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:52:48,990 graphrag.index.input.text INFO Found 9 files, loading 9
23:52:48,992 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:52:48,998 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:49,27 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:49,28 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:49,41 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:49,100 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:49,101 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:49,104 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:52:49,104 root INFO Starting at time 1745293969.104655
23:52:49,104 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:52:49,104 root INFO Completed 1 / 24 vertices
23:52:49,104 root INFO Completed 3 / 24 vertices
23:52:49,104 root INFO Completed 5 / 24 vertices
23:52:49,104 root INFO Completed 7 / 24 vertices
23:52:49,104 root INFO Completed 9 / 24 vertices
23:52:49,104 root INFO Completed 11 / 24 vertices
23:52:49,104 root INFO Completed 13 / 24 vertices
23:52:49,104 root INFO Completed 15 / 24 vertices
23:52:49,104 root INFO Completed 17 / 24 vertices
23:52:49,104 root INFO Completed 19 / 24 vertices
23:52:49,104 root INFO Completed 21 / 24 vertices
23:52:49,104 root INFO Completed 23 / 24 vertices
23:52:49,104 root INFO Completed preprocessing of transition probabilities for vertices
23:52:49,104 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:52:49,104 root INFO Completed 1 / 25 edges
23:52:49,105 root INFO Completed 3 / 25 edges
23:52:49,105 root INFO Completed 5 / 25 edges
23:52:49,105 root INFO Completed 7 / 25 edges
23:52:49,105 root INFO Completed 9 / 25 edges
23:52:49,105 root INFO Completed 11 / 25 edges
23:52:49,105 root INFO Completed 13 / 25 edges
23:52:49,105 root INFO Completed 15 / 25 edges
23:52:49,105 root INFO Completed 17 / 25 edges
23:52:49,105 root INFO Completed 19 / 25 edges
23:52:49,105 root INFO Completed 21 / 25 edges
23:52:49,105 root INFO Completed 23 / 25 edges
23:52:49,105 root INFO Completed 25 / 25 edges
23:52:49,105 root INFO Completed preprocessing of transition probabilities for edges
23:52:49,105 root INFO Simulating walks on graph at time 1745293969.105474
23:52:49,105 root INFO Walk iteration: 1/10
23:52:49,106 root INFO Walk iteration: 2/10
23:52:49,106 root INFO Walk iteration: 3/10
23:52:49,107 root INFO Walk iteration: 4/10
23:52:49,107 root INFO Walk iteration: 5/10
23:52:49,108 root INFO Walk iteration: 6/10
23:52:49,109 root INFO Walk iteration: 7/10
23:52:49,109 root INFO Walk iteration: 8/10
23:52:49,110 root INFO Walk iteration: 9/10
23:52:49,110 root INFO Walk iteration: 10/10
23:52:49,111 root INFO Learning embeddings at time 1745293969.111407
23:52:49,111 gensim.models.word2vec INFO collecting all words and their counts
23:52:49,111 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:52:49,111 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:52:49,111 gensim.models.word2vec INFO Creating a fresh vocabulary
23:52:49,112 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:52:49.112005', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:49,112 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:52:49.112035', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:49,112 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:52:49,112 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:52:49,112 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:52:49.112144', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:52:49,112 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:52:49,112 gensim.models.word2vec INFO resetting layer weights
23:52:49,112 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:52:49.112493', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:52:49,112 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:52:49.112519', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:52:49,116 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199597 effective words/s
23:52:49,119 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 210246 effective words/s
23:52:49,123 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204667 effective words/s
23:52:49,123 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 171901 effective words/s', 'datetime': '2025-04-21T23:52:49.123364', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:52:49,123 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:52:49.123393', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:52:49,123 root INFO Completed. Ending time is 1745293969.123418 Elapsed time is -0.018763065338134766
23:52:52,706 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:52,708 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:52,727 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:52,729 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:52,730 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:52,745 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:52,746 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:52,748 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:52:52,752 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:52:52,797 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:52:52,799 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:52:52,800 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:52:52,802 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:52:52,803 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:52:52,806 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:52:52,806 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:52:53,16 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:52:53,40 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:52:53,46 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:52:53,54 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:52:53,57 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:52:53,104 graphrag.cli.index INFO All workflows completed successfully.
23:56:50,386 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:56:58,477 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:56:59,145 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:56:59,150 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:56:59,151 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:56:59,152 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
23:56:59,152 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
23:56:59,152 graphrag.index.input.factory INFO using file storage for input
23:56:59,153 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
23:56:59,155 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:56:59,161 graphrag.index.input.text INFO Found 9 files, loading 9
23:56:59,162 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:56:59,168 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:56:59,197 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:56:59,199 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:56:59,211 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:56:59,270 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:56:59,272 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:56:59,274 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:56:59,274 root INFO Starting at time 1745294219.274753
23:56:59,274 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:56:59,274 root INFO Completed 1 / 24 vertices
23:56:59,274 root INFO Completed 3 / 24 vertices
23:56:59,274 root INFO Completed 5 / 24 vertices
23:56:59,274 root INFO Completed 7 / 24 vertices
23:56:59,274 root INFO Completed 9 / 24 vertices
23:56:59,274 root INFO Completed 11 / 24 vertices
23:56:59,274 root INFO Completed 13 / 24 vertices
23:56:59,274 root INFO Completed 15 / 24 vertices
23:56:59,274 root INFO Completed 17 / 24 vertices
23:56:59,274 root INFO Completed 19 / 24 vertices
23:56:59,275 root INFO Completed 21 / 24 vertices
23:56:59,275 root INFO Completed 23 / 24 vertices
23:56:59,275 root INFO Completed preprocessing of transition probabilities for vertices
23:56:59,275 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:56:59,275 root INFO Completed 1 / 25 edges
23:56:59,275 root INFO Completed 3 / 25 edges
23:56:59,275 root INFO Completed 5 / 25 edges
23:56:59,275 root INFO Completed 7 / 25 edges
23:56:59,275 root INFO Completed 9 / 25 edges
23:56:59,275 root INFO Completed 11 / 25 edges
23:56:59,275 root INFO Completed 13 / 25 edges
23:56:59,275 root INFO Completed 15 / 25 edges
23:56:59,275 root INFO Completed 17 / 25 edges
23:56:59,275 root INFO Completed 19 / 25 edges
23:56:59,275 root INFO Completed 21 / 25 edges
23:56:59,275 root INFO Completed 23 / 25 edges
23:56:59,275 root INFO Completed 25 / 25 edges
23:56:59,275 root INFO Completed preprocessing of transition probabilities for edges
23:56:59,275 root INFO Simulating walks on graph at time 1745294219.275575
23:56:59,275 root INFO Walk iteration: 1/10
23:56:59,276 root INFO Walk iteration: 2/10
23:56:59,276 root INFO Walk iteration: 3/10
23:56:59,277 root INFO Walk iteration: 4/10
23:56:59,278 root INFO Walk iteration: 5/10
23:56:59,278 root INFO Walk iteration: 6/10
23:56:59,279 root INFO Walk iteration: 7/10
23:56:59,279 root INFO Walk iteration: 8/10
23:56:59,280 root INFO Walk iteration: 9/10
23:56:59,280 root INFO Walk iteration: 10/10
23:56:59,281 root INFO Learning embeddings at time 1745294219.281434
23:56:59,281 gensim.models.word2vec INFO collecting all words and their counts
23:56:59,281 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:56:59,281 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:56:59,281 gensim.models.word2vec INFO Creating a fresh vocabulary
23:56:59,282 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:56:59.282028', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:56:59,282 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:56:59.282058', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:56:59,282 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:56:59,282 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:56:59,282 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:56:59.282166', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:56:59,282 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:56:59,282 gensim.models.word2vec INFO resetting layer weights
23:56:59,282 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:56:59.282449', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:56:59,282 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:56:59.282476', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:56:59,286 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 205320 effective words/s
23:56:59,289 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 211792 effective words/s
23:56:59,293 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 236348 effective words/s
23:56:59,293 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173819 effective words/s', 'datetime': '2025-04-21T23:56:59.293202', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:56:59,293 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:56:59.293232', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:56:59,293 root INFO Completed. Ending time is 1745294219.293257 Elapsed time is -0.018503904342651367
23:57:02,870 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:02,872 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:02,891 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:02,893 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:02,894 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:02,910 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:02,911 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:02,913 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:57:02,917 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:57:02,962 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:57:02,963 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:02,965 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:02,966 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:02,968 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:57:02,970 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:57:02,970 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:57:03,183 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:57:03,189 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:57:03,193 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:57:03,215 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:57:03,220 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:57:03,270 graphrag.cli.index INFO All workflows completed successfully.
23:57:32,724 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:57:33,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:57:33,494 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:57:33,496 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:57:33,497 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:57:33,498 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
23:57:33,498 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
23:57:33,498 graphrag.index.input.factory INFO using file storage for input
23:57:33,498 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
23:57:33,499 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:57:33,504 graphrag.index.input.text INFO Found 9 files, loading 9
23:57:33,505 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:57:33,509 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:57:33,536 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:57:33,537 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:33,550 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:33,618 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:33,619 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:33,622 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:57:33,622 root INFO Starting at time 1745294253.622781
23:57:33,622 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:57:33,622 root INFO Completed 1 / 24 vertices
23:57:33,622 root INFO Completed 3 / 24 vertices
23:57:33,622 root INFO Completed 5 / 24 vertices
23:57:33,622 root INFO Completed 7 / 24 vertices
23:57:33,622 root INFO Completed 9 / 24 vertices
23:57:33,622 root INFO Completed 11 / 24 vertices
23:57:33,622 root INFO Completed 13 / 24 vertices
23:57:33,623 root INFO Completed 15 / 24 vertices
23:57:33,623 root INFO Completed 17 / 24 vertices
23:57:33,623 root INFO Completed 19 / 24 vertices
23:57:33,623 root INFO Completed 21 / 24 vertices
23:57:33,623 root INFO Completed 23 / 24 vertices
23:57:33,623 root INFO Completed preprocessing of transition probabilities for vertices
23:57:33,623 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:57:33,623 root INFO Completed 1 / 25 edges
23:57:33,623 root INFO Completed 3 / 25 edges
23:57:33,623 root INFO Completed 5 / 25 edges
23:57:33,623 root INFO Completed 7 / 25 edges
23:57:33,623 root INFO Completed 9 / 25 edges
23:57:33,623 root INFO Completed 11 / 25 edges
23:57:33,623 root INFO Completed 13 / 25 edges
23:57:33,623 root INFO Completed 15 / 25 edges
23:57:33,623 root INFO Completed 17 / 25 edges
23:57:33,623 root INFO Completed 19 / 25 edges
23:57:33,623 root INFO Completed 21 / 25 edges
23:57:33,623 root INFO Completed 23 / 25 edges
23:57:33,623 root INFO Completed 25 / 25 edges
23:57:33,623 root INFO Completed preprocessing of transition probabilities for edges
23:57:33,623 root INFO Simulating walks on graph at time 1745294253.6236632
23:57:33,623 root INFO Walk iteration: 1/10
23:57:33,624 root INFO Walk iteration: 2/10
23:57:33,624 root INFO Walk iteration: 3/10
23:57:33,625 root INFO Walk iteration: 4/10
23:57:33,626 root INFO Walk iteration: 5/10
23:57:33,626 root INFO Walk iteration: 6/10
23:57:33,627 root INFO Walk iteration: 7/10
23:57:33,628 root INFO Walk iteration: 8/10
23:57:33,628 root INFO Walk iteration: 9/10
23:57:33,629 root INFO Walk iteration: 10/10
23:57:33,629 root INFO Learning embeddings at time 1745294253.6298292
23:57:33,630 gensim.models.word2vec INFO collecting all words and their counts
23:57:33,630 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:57:33,630 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:57:33,630 gensim.models.word2vec INFO Creating a fresh vocabulary
23:57:33,630 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:57:33.630524', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:57:33,630 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:57:33.630556', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:57:33,630 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:57:33,630 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:57:33,630 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:57:33.630679', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:57:33,630 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:57:33,630 gensim.models.word2vec INFO resetting layer weights
23:57:33,630 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:57:33.630972', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:57:33,631 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:57:33.631001', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:57:33,634 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 200081 effective words/s
23:57:33,638 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209309 effective words/s
23:57:33,641 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205296 effective words/s
23:57:33,641 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 171775 effective words/s', 'datetime': '2025-04-21T23:57:33.641859', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:57:33,641 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:57:33.641889', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:57:33,641 root INFO Completed. Ending time is 1745294253.6419148 Elapsed time is -0.019133806228637695
23:57:37,239 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:37,241 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:37,261 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:37,262 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:37,264 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:37,279 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:37,280 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:37,282 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:57:37,286 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:57:37,331 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:57:37,332 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:57:37,334 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:57:37,335 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:57:37,337 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:57:37,340 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:57:37,340 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:57:37,552 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:57:37,559 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:57:37,565 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:57:37,573 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:57:37,575 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:57:37,642 graphrag.cli.index INFO All workflows completed successfully.
23:59:05,963 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
23:59:06,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
23:59:07,72 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
23:59:07,77 graphrag.cli.index INFO Starting pipeline run. dry_run=False
23:59:07,78 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
23:59:07,79 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
23:59:07,79 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
23:59:07,79 graphrag.index.input.factory INFO using file storage for input
23:59:07,79 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
23:59:07,80 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
23:59:07,86 graphrag.index.input.text INFO Found 9 files, loading 9
23:59:07,87 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
23:59:07,93 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:59:07,121 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:59:07,123 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:59:07,135 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:59:07,195 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:59:07,196 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:59:07,199 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
23:59:07,199 root INFO Starting at time 1745294347.199289
23:59:07,199 root INFO Beginning preprocessing of transition probabilities for 24 vertices
23:59:07,199 root INFO Completed 1 / 24 vertices
23:59:07,199 root INFO Completed 3 / 24 vertices
23:59:07,199 root INFO Completed 5 / 24 vertices
23:59:07,199 root INFO Completed 7 / 24 vertices
23:59:07,199 root INFO Completed 9 / 24 vertices
23:59:07,199 root INFO Completed 11 / 24 vertices
23:59:07,199 root INFO Completed 13 / 24 vertices
23:59:07,199 root INFO Completed 15 / 24 vertices
23:59:07,199 root INFO Completed 17 / 24 vertices
23:59:07,199 root INFO Completed 19 / 24 vertices
23:59:07,199 root INFO Completed 21 / 24 vertices
23:59:07,199 root INFO Completed 23 / 24 vertices
23:59:07,199 root INFO Completed preprocessing of transition probabilities for vertices
23:59:07,199 root INFO Beginning preprocessing of transition probabilities for 25 edges
23:59:07,199 root INFO Completed 1 / 25 edges
23:59:07,199 root INFO Completed 3 / 25 edges
23:59:07,199 root INFO Completed 5 / 25 edges
23:59:07,199 root INFO Completed 7 / 25 edges
23:59:07,199 root INFO Completed 9 / 25 edges
23:59:07,199 root INFO Completed 11 / 25 edges
23:59:07,199 root INFO Completed 13 / 25 edges
23:59:07,199 root INFO Completed 15 / 25 edges
23:59:07,199 root INFO Completed 17 / 25 edges
23:59:07,199 root INFO Completed 19 / 25 edges
23:59:07,200 root INFO Completed 21 / 25 edges
23:59:07,200 root INFO Completed 23 / 25 edges
23:59:07,200 root INFO Completed 25 / 25 edges
23:59:07,200 root INFO Completed preprocessing of transition probabilities for edges
23:59:07,200 root INFO Simulating walks on graph at time 1745294347.200109
23:59:07,200 root INFO Walk iteration: 1/10
23:59:07,200 root INFO Walk iteration: 2/10
23:59:07,201 root INFO Walk iteration: 3/10
23:59:07,201 root INFO Walk iteration: 4/10
23:59:07,202 root INFO Walk iteration: 5/10
23:59:07,203 root INFO Walk iteration: 6/10
23:59:07,203 root INFO Walk iteration: 7/10
23:59:07,204 root INFO Walk iteration: 8/10
23:59:07,204 root INFO Walk iteration: 9/10
23:59:07,205 root INFO Walk iteration: 10/10
23:59:07,206 root INFO Learning embeddings at time 1745294347.206013
23:59:07,206 gensim.models.word2vec INFO collecting all words and their counts
23:59:07,206 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
23:59:07,206 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
23:59:07,206 gensim.models.word2vec INFO Creating a fresh vocabulary
23:59:07,206 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-21T23:59:07.206628', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:59:07,206 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-21T23:59:07.206660', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:59:07,206 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
23:59:07,206 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
23:59:07,206 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-21T23:59:07.206772', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
23:59:07,206 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
23:59:07,206 gensim.models.word2vec INFO resetting layer weights
23:59:07,207 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T23:59:07.207067', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
23:59:07,207 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-21T23:59:07.207095', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:59:07,210 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 195890 effective words/s
23:59:07,214 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209584 effective words/s
23:59:07,217 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204757 effective words/s
23:59:07,218 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170696 effective words/s', 'datetime': '2025-04-21T23:59:07.218017', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
23:59:07,218 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-21T23:59:07.218043', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
23:59:07,218 root INFO Completed. Ending time is 1745294347.218067 Elapsed time is -0.018777847290039062
23:59:10,975 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:59:10,977 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:59:10,997 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:59:10,998 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:59:11,0 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:59:11,15 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:59:11,17 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:59:11,18 graphrag.utils.storage INFO reading table from storage: communities.parquet
23:59:11,23 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
23:59:11,68 graphrag.utils.storage INFO reading table from storage: documents.parquet
23:59:11,69 graphrag.utils.storage INFO reading table from storage: relationships.parquet
23:59:11,71 graphrag.utils.storage INFO reading table from storage: text_units.parquet
23:59:11,72 graphrag.utils.storage INFO reading table from storage: entities.parquet
23:59:11,74 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
23:59:11,77 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
23:59:11,77 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
23:59:11,289 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
23:59:11,313 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
23:59:11,319 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:59:11,327 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
23:59:11,330 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
23:59:11,378 graphrag.cli.index INFO All workflows completed successfully.
00:02:01,281 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:02:02,585 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:02:03,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:02:03,272 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:02:03,273 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:02:03,273 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
00:02:03,274 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
00:02:03,274 graphrag.index.input.factory INFO using file storage for input
00:02:03,274 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
00:02:03,274 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:02:03,279 graphrag.index.input.text INFO Found 9 files, loading 9
00:02:03,280 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:02:03,286 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:02:03,312 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:02:03,313 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:02:03,326 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:02:03,387 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:02:03,389 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:02:03,392 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:02:03,392 root INFO Starting at time 1745294523.392789
00:02:03,392 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:02:03,392 root INFO Completed 1 / 24 vertices
00:02:03,392 root INFO Completed 3 / 24 vertices
00:02:03,392 root INFO Completed 5 / 24 vertices
00:02:03,392 root INFO Completed 7 / 24 vertices
00:02:03,392 root INFO Completed 9 / 24 vertices
00:02:03,392 root INFO Completed 11 / 24 vertices
00:02:03,392 root INFO Completed 13 / 24 vertices
00:02:03,392 root INFO Completed 15 / 24 vertices
00:02:03,393 root INFO Completed 17 / 24 vertices
00:02:03,393 root INFO Completed 19 / 24 vertices
00:02:03,393 root INFO Completed 21 / 24 vertices
00:02:03,393 root INFO Completed 23 / 24 vertices
00:02:03,393 root INFO Completed preprocessing of transition probabilities for vertices
00:02:03,393 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:02:03,393 root INFO Completed 1 / 25 edges
00:02:03,393 root INFO Completed 3 / 25 edges
00:02:03,393 root INFO Completed 5 / 25 edges
00:02:03,393 root INFO Completed 7 / 25 edges
00:02:03,393 root INFO Completed 9 / 25 edges
00:02:03,393 root INFO Completed 11 / 25 edges
00:02:03,393 root INFO Completed 13 / 25 edges
00:02:03,393 root INFO Completed 15 / 25 edges
00:02:03,393 root INFO Completed 17 / 25 edges
00:02:03,393 root INFO Completed 19 / 25 edges
00:02:03,393 root INFO Completed 21 / 25 edges
00:02:03,393 root INFO Completed 23 / 25 edges
00:02:03,393 root INFO Completed 25 / 25 edges
00:02:03,393 root INFO Completed preprocessing of transition probabilities for edges
00:02:03,393 root INFO Simulating walks on graph at time 1745294523.393616
00:02:03,393 root INFO Walk iteration: 1/10
00:02:03,394 root INFO Walk iteration: 2/10
00:02:03,394 root INFO Walk iteration: 3/10
00:02:03,395 root INFO Walk iteration: 4/10
00:02:03,396 root INFO Walk iteration: 5/10
00:02:03,396 root INFO Walk iteration: 6/10
00:02:03,397 root INFO Walk iteration: 7/10
00:02:03,397 root INFO Walk iteration: 8/10
00:02:03,398 root INFO Walk iteration: 9/10
00:02:03,399 root INFO Walk iteration: 10/10
00:02:03,399 root INFO Learning embeddings at time 1745294523.3996449
00:02:03,399 gensim.models.word2vec INFO collecting all words and their counts
00:02:03,399 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:02:03,400 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:02:03,400 gensim.models.word2vec INFO Creating a fresh vocabulary
00:02:03,400 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:02:03.400244', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:02:03,400 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:02:03.400276', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:02:03,400 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:02:03,400 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:02:03,400 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:02:03.400390', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:02:03,400 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:02:03,400 gensim.models.word2vec INFO resetting layer weights
00:02:03,400 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:02:03.400683', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:02:03,400 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:02:03.400711', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:02:03,404 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 204464 effective words/s
00:02:03,407 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 214574 effective words/s
00:02:03,411 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 207226 effective words/s
00:02:03,411 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 176293 effective words/s', 'datetime': '2025-04-22T00:02:03.411288', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:02:03,411 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:02:03.411314', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:02:03,411 root INFO Completed. Ending time is 1745294523.411339 Elapsed time is -0.01855015754699707
00:02:07,49 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:02:07,52 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:02:07,71 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:02:07,73 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:02:07,74 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:02:07,89 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:02:07,90 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:02:07,92 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:02:07,97 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:02:07,143 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:02:07,144 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:02:07,146 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:02:07,147 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:02:07,148 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:02:07,151 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:02:07,151 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:02:07,368 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:02:07,378 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:02:07,380 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:02:07,403 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:02:07,406 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:02:07,454 graphrag.cli.index INFO All workflows completed successfully.
00:33:07,477 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:33:08,484 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:33:09,178 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:33:09,183 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:33:09,184 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:33:09,185 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:33:09,185 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:33:09,185 graphrag.index.input.factory INFO using file storage for input
00:33:09,185 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:33:09,186 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:33:09,192 graphrag.index.input.text INFO Found 9 files, loading 9
00:33:09,193 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:33:09,200 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:33:09,229 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:33:09,231 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:33:09,243 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:33:09,303 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:33:09,305 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:33:09,308 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:33:09,308 root INFO Starting at time 1745296389.308668
00:33:09,308 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:33:09,308 root INFO Completed 1 / 24 vertices
00:33:09,308 root INFO Completed 3 / 24 vertices
00:33:09,308 root INFO Completed 5 / 24 vertices
00:33:09,308 root INFO Completed 7 / 24 vertices
00:33:09,308 root INFO Completed 9 / 24 vertices
00:33:09,308 root INFO Completed 11 / 24 vertices
00:33:09,308 root INFO Completed 13 / 24 vertices
00:33:09,308 root INFO Completed 15 / 24 vertices
00:33:09,308 root INFO Completed 17 / 24 vertices
00:33:09,308 root INFO Completed 19 / 24 vertices
00:33:09,308 root INFO Completed 21 / 24 vertices
00:33:09,308 root INFO Completed 23 / 24 vertices
00:33:09,308 root INFO Completed preprocessing of transition probabilities for vertices
00:33:09,308 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:33:09,308 root INFO Completed 1 / 25 edges
00:33:09,309 root INFO Completed 3 / 25 edges
00:33:09,309 root INFO Completed 5 / 25 edges
00:33:09,309 root INFO Completed 7 / 25 edges
00:33:09,309 root INFO Completed 9 / 25 edges
00:33:09,309 root INFO Completed 11 / 25 edges
00:33:09,309 root INFO Completed 13 / 25 edges
00:33:09,309 root INFO Completed 15 / 25 edges
00:33:09,309 root INFO Completed 17 / 25 edges
00:33:09,309 root INFO Completed 19 / 25 edges
00:33:09,309 root INFO Completed 21 / 25 edges
00:33:09,309 root INFO Completed 23 / 25 edges
00:33:09,309 root INFO Completed 25 / 25 edges
00:33:09,309 root INFO Completed preprocessing of transition probabilities for edges
00:33:09,309 root INFO Simulating walks on graph at time 1745296389.3094752
00:33:09,309 root INFO Walk iteration: 1/10
00:33:09,310 root INFO Walk iteration: 2/10
00:33:09,310 root INFO Walk iteration: 3/10
00:33:09,311 root INFO Walk iteration: 4/10
00:33:09,311 root INFO Walk iteration: 5/10
00:33:09,312 root INFO Walk iteration: 6/10
00:33:09,313 root INFO Walk iteration: 7/10
00:33:09,313 root INFO Walk iteration: 8/10
00:33:09,314 root INFO Walk iteration: 9/10
00:33:09,314 root INFO Walk iteration: 10/10
00:33:09,315 root INFO Learning embeddings at time 1745296389.3154109
00:33:09,315 gensim.models.word2vec INFO collecting all words and their counts
00:33:09,315 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:33:09,315 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:33:09,315 gensim.models.word2vec INFO Creating a fresh vocabulary
00:33:09,316 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:33:09.316007', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:33:09,316 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:33:09.316038', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:33:09,316 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:33:09,316 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:33:09,316 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:33:09.316148', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:33:09,316 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:33:09,316 gensim.models.word2vec INFO resetting layer weights
00:33:09,316 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:33:09.316433', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:33:09,316 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:33:09.316460', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:33:09,320 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 196241 effective words/s
00:33:09,323 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 238302 effective words/s
00:33:09,327 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204019 effective words/s
00:33:09,327 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172073 effective words/s', 'datetime': '2025-04-22T00:33:09.327294', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:33:09,327 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:33:09.327319', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:33:09,327 root INFO Completed. Ending time is 1745296389.3273442 Elapsed time is -0.018676280975341797
00:33:12,921 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:33:12,923 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:33:12,943 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:33:12,944 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:33:12,946 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:33:12,961 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:33:12,962 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:33:12,964 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:33:12,969 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:33:13,14 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:33:13,16 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:33:13,17 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:33:13,18 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:33:13,20 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:33:13,23 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:33:13,23 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:33:13,257 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:33:13,305 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:33:13,308 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:33:13,315 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:33:13,321 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:33:13,372 graphrag.cli.index INFO All workflows completed successfully.
00:36:42,272 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:36:42,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:36:43,813 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:36:43,820 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:36:43,821 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:36:43,822 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:36:43,823 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:36:43,823 graphrag.index.input.factory INFO using file storage for input
00:36:43,824 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:36:43,824 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:36:43,831 graphrag.index.input.text INFO Found 9 files, loading 9
00:36:43,832 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:36:43,839 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:36:43,870 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:36:43,871 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:36:43,884 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:36:43,944 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:36:43,946 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:36:43,949 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:36:43,949 root INFO Starting at time 1745296603.949528
00:36:43,949 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:36:43,949 root INFO Completed 1 / 24 vertices
00:36:43,949 root INFO Completed 3 / 24 vertices
00:36:43,949 root INFO Completed 5 / 24 vertices
00:36:43,949 root INFO Completed 7 / 24 vertices
00:36:43,949 root INFO Completed 9 / 24 vertices
00:36:43,949 root INFO Completed 11 / 24 vertices
00:36:43,949 root INFO Completed 13 / 24 vertices
00:36:43,949 root INFO Completed 15 / 24 vertices
00:36:43,949 root INFO Completed 17 / 24 vertices
00:36:43,949 root INFO Completed 19 / 24 vertices
00:36:43,949 root INFO Completed 21 / 24 vertices
00:36:43,949 root INFO Completed 23 / 24 vertices
00:36:43,949 root INFO Completed preprocessing of transition probabilities for vertices
00:36:43,949 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:36:43,949 root INFO Completed 1 / 25 edges
00:36:43,949 root INFO Completed 3 / 25 edges
00:36:43,949 root INFO Completed 5 / 25 edges
00:36:43,949 root INFO Completed 7 / 25 edges
00:36:43,950 root INFO Completed 9 / 25 edges
00:36:43,950 root INFO Completed 11 / 25 edges
00:36:43,950 root INFO Completed 13 / 25 edges
00:36:43,950 root INFO Completed 15 / 25 edges
00:36:43,950 root INFO Completed 17 / 25 edges
00:36:43,950 root INFO Completed 19 / 25 edges
00:36:43,950 root INFO Completed 21 / 25 edges
00:36:43,950 root INFO Completed 23 / 25 edges
00:36:43,950 root INFO Completed 25 / 25 edges
00:36:43,950 root INFO Completed preprocessing of transition probabilities for edges
00:36:43,950 root INFO Simulating walks on graph at time 1745296603.950391
00:36:43,950 root INFO Walk iteration: 1/10
00:36:43,951 root INFO Walk iteration: 2/10
00:36:43,951 root INFO Walk iteration: 3/10
00:36:43,952 root INFO Walk iteration: 4/10
00:36:43,952 root INFO Walk iteration: 5/10
00:36:43,953 root INFO Walk iteration: 6/10
00:36:43,954 root INFO Walk iteration: 7/10
00:36:43,954 root INFO Walk iteration: 8/10
00:36:43,955 root INFO Walk iteration: 9/10
00:36:43,955 root INFO Walk iteration: 10/10
00:36:43,956 root INFO Learning embeddings at time 1745296603.956575
00:36:43,956 gensim.models.word2vec INFO collecting all words and their counts
00:36:43,956 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:36:43,957 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:36:43,957 gensim.models.word2vec INFO Creating a fresh vocabulary
00:36:43,957 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:36:43.957185', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:36:43,957 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:36:43.957217', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:36:43,957 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:36:43,957 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:36:43,957 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:36:43.957330', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:36:43,957 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:36:43,957 gensim.models.word2vec INFO resetting layer weights
00:36:43,957 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:36:43.957616', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:36:43,957 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:36:43.957643', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:36:43,961 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 187424 effective words/s
00:36:43,964 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 211705 effective words/s
00:36:43,968 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204371 effective words/s
00:36:43,968 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173146 effective words/s', 'datetime': '2025-04-22T00:36:43.968410', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:36:43,968 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:36:43.968436', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:36:43,968 root INFO Completed. Ending time is 1745296603.96846 Elapsed time is -0.018932104110717773
00:36:47,574 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:36:47,576 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:36:47,596 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:36:47,598 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:36:47,600 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:36:47,617 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:36:47,618 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:36:47,620 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:36:47,626 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:36:47,671 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:36:47,673 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:36:47,674 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:36:47,676 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:36:47,677 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:36:47,680 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:36:47,680 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:36:47,916 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:36:47,945 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:36:47,948 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:36:47,970 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:36:47,973 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:36:48,21 graphrag.cli.index INFO All workflows completed successfully.
00:39:51,252 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:39:51,758 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:39:52,576 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:39:52,581 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:39:52,582 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:39:52,583 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:39:52,583 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:39:52,583 graphrag.index.input.factory INFO using file storage for input
00:39:52,583 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:39:52,584 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:39:52,590 graphrag.index.input.text INFO Found 9 files, loading 9
00:39:52,591 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:39:52,597 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:39:52,627 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:39:52,628 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:39:52,641 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:39:52,701 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:39:52,702 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:39:52,705 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:39:52,705 root INFO Starting at time 1745296792.705853
00:39:52,705 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:39:52,705 root INFO Completed 1 / 24 vertices
00:39:52,705 root INFO Completed 3 / 24 vertices
00:39:52,705 root INFO Completed 5 / 24 vertices
00:39:52,705 root INFO Completed 7 / 24 vertices
00:39:52,705 root INFO Completed 9 / 24 vertices
00:39:52,706 root INFO Completed 11 / 24 vertices
00:39:52,706 root INFO Completed 13 / 24 vertices
00:39:52,706 root INFO Completed 15 / 24 vertices
00:39:52,706 root INFO Completed 17 / 24 vertices
00:39:52,706 root INFO Completed 19 / 24 vertices
00:39:52,706 root INFO Completed 21 / 24 vertices
00:39:52,706 root INFO Completed 23 / 24 vertices
00:39:52,706 root INFO Completed preprocessing of transition probabilities for vertices
00:39:52,706 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:39:52,706 root INFO Completed 1 / 25 edges
00:39:52,706 root INFO Completed 3 / 25 edges
00:39:52,706 root INFO Completed 5 / 25 edges
00:39:52,706 root INFO Completed 7 / 25 edges
00:39:52,706 root INFO Completed 9 / 25 edges
00:39:52,706 root INFO Completed 11 / 25 edges
00:39:52,706 root INFO Completed 13 / 25 edges
00:39:52,706 root INFO Completed 15 / 25 edges
00:39:52,706 root INFO Completed 17 / 25 edges
00:39:52,706 root INFO Completed 19 / 25 edges
00:39:52,706 root INFO Completed 21 / 25 edges
00:39:52,706 root INFO Completed 23 / 25 edges
00:39:52,706 root INFO Completed 25 / 25 edges
00:39:52,706 root INFO Completed preprocessing of transition probabilities for edges
00:39:52,706 root INFO Simulating walks on graph at time 1745296792.70665
00:39:52,706 root INFO Walk iteration: 1/10
00:39:52,707 root INFO Walk iteration: 2/10
00:39:52,708 root INFO Walk iteration: 3/10
00:39:52,708 root INFO Walk iteration: 4/10
00:39:52,709 root INFO Walk iteration: 5/10
00:39:52,709 root INFO Walk iteration: 6/10
00:39:52,710 root INFO Walk iteration: 7/10
00:39:52,711 root INFO Walk iteration: 8/10
00:39:52,711 root INFO Walk iteration: 9/10
00:39:52,712 root INFO Walk iteration: 10/10
00:39:52,712 root INFO Learning embeddings at time 1745296792.7129118
00:39:52,713 gensim.models.word2vec INFO collecting all words and their counts
00:39:52,713 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:39:52,713 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:39:52,713 gensim.models.word2vec INFO Creating a fresh vocabulary
00:39:52,713 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:39:52.713518', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:39:52,713 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:39:52.713549', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:39:52,713 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:39:52,713 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:39:52,713 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:39:52.713660', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:39:52,713 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:39:52,713 gensim.models.word2vec INFO resetting layer weights
00:39:52,713 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:39:52.713947', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:39:52,713 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:39:52.713974', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:39:52,717 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 204499 effective words/s
00:39:52,720 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 243563 effective words/s
00:39:52,724 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 210052 effective words/s
00:39:52,724 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 176984 effective words/s', 'datetime': '2025-04-22T00:39:52.724507', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:39:52,724 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:39:52.724532', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:39:52,724 root INFO Completed. Ending time is 1745296792.724555 Elapsed time is -0.018702030181884766
00:39:56,730 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:39:56,732 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:39:56,754 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:39:56,755 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:39:56,757 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:39:56,774 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:39:56,775 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:39:56,777 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:39:56,782 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:39:56,830 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:39:56,832 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:39:56,833 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:39:56,835 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:39:56,836 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:39:56,839 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:39:56,839 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:39:57,55 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:39:57,65 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:39:57,68 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:39:57,91 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:39:57,94 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:39:57,145 graphrag.cli.index INFO All workflows completed successfully.
00:39:59,653 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:40:00,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:40:01,75 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:40:01,79 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:40:01,80 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:40:01,80 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:40:01,80 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:40:01,80 graphrag.index.input.factory INFO using file storage for input
00:40:01,81 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:40:01,81 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:40:01,87 graphrag.index.input.text INFO Found 9 files, loading 9
00:40:01,88 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:40:01,93 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:40:01,120 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:40:01,122 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:40:01,135 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:40:01,194 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:40:01,195 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:40:01,198 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:40:01,198 root INFO Starting at time 1745296801.198216
00:40:01,198 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:40:01,198 root INFO Completed 1 / 24 vertices
00:40:01,198 root INFO Completed 3 / 24 vertices
00:40:01,198 root INFO Completed 5 / 24 vertices
00:40:01,198 root INFO Completed 7 / 24 vertices
00:40:01,198 root INFO Completed 9 / 24 vertices
00:40:01,198 root INFO Completed 11 / 24 vertices
00:40:01,198 root INFO Completed 13 / 24 vertices
00:40:01,198 root INFO Completed 15 / 24 vertices
00:40:01,198 root INFO Completed 17 / 24 vertices
00:40:01,198 root INFO Completed 19 / 24 vertices
00:40:01,198 root INFO Completed 21 / 24 vertices
00:40:01,198 root INFO Completed 23 / 24 vertices
00:40:01,198 root INFO Completed preprocessing of transition probabilities for vertices
00:40:01,198 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:40:01,198 root INFO Completed 1 / 25 edges
00:40:01,198 root INFO Completed 3 / 25 edges
00:40:01,198 root INFO Completed 5 / 25 edges
00:40:01,198 root INFO Completed 7 / 25 edges
00:40:01,198 root INFO Completed 9 / 25 edges
00:40:01,198 root INFO Completed 11 / 25 edges
00:40:01,198 root INFO Completed 13 / 25 edges
00:40:01,198 root INFO Completed 15 / 25 edges
00:40:01,198 root INFO Completed 17 / 25 edges
00:40:01,198 root INFO Completed 19 / 25 edges
00:40:01,198 root INFO Completed 21 / 25 edges
00:40:01,198 root INFO Completed 23 / 25 edges
00:40:01,199 root INFO Completed 25 / 25 edges
00:40:01,199 root INFO Completed preprocessing of transition probabilities for edges
00:40:01,199 root INFO Simulating walks on graph at time 1745296801.199046
00:40:01,199 root INFO Walk iteration: 1/10
00:40:01,199 root INFO Walk iteration: 2/10
00:40:01,200 root INFO Walk iteration: 3/10
00:40:01,200 root INFO Walk iteration: 4/10
00:40:01,201 root INFO Walk iteration: 5/10
00:40:01,202 root INFO Walk iteration: 6/10
00:40:01,202 root INFO Walk iteration: 7/10
00:40:01,203 root INFO Walk iteration: 8/10
00:40:01,203 root INFO Walk iteration: 9/10
00:40:01,204 root INFO Walk iteration: 10/10
00:40:01,205 root INFO Learning embeddings at time 1745296801.2050261
00:40:01,205 gensim.models.word2vec INFO collecting all words and their counts
00:40:01,205 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:40:01,205 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:40:01,205 gensim.models.word2vec INFO Creating a fresh vocabulary
00:40:01,205 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:40:01.205648', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:40:01,205 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:40:01.205679', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:40:01,205 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:40:01,205 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:40:01,205 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:40:01.205791', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:40:01,205 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:40:01,205 gensim.models.word2vec INFO resetting layer weights
00:40:01,206 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:40:01.206077', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:40:01,206 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:40:01.206105', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:40:01,209 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199659 effective words/s
00:40:01,213 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 206752 effective words/s
00:40:01,216 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 202548 effective words/s
00:40:01,217 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170584 effective words/s', 'datetime': '2025-04-22T00:40:01.217036', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:40:01,217 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:40:01.217066', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:40:01,217 root INFO Completed. Ending time is 1745296801.2170932 Elapsed time is -0.018877267837524414
00:40:04,811 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:40:04,813 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:40:04,832 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:40:04,834 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:40:04,835 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:40:04,851 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:40:04,852 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:40:04,854 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:40:04,858 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:40:04,903 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:40:04,905 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:40:04,906 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:40:04,907 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:40:04,909 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:40:04,912 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:40:04,912 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:40:05,126 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:40:05,136 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:40:05,139 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:40:05,160 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:40:05,163 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:40:05,212 graphrag.cli.index INFO All workflows completed successfully.
00:48:22,36 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:48:22,869 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:48:23,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:48:23,258 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:48:23,260 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:48:23,261 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:48:23,261 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:48:23,261 graphrag.index.input.factory INFO using file storage for input
00:48:23,262 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:48:23,263 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:48:23,270 graphrag.index.input.text INFO Found 9 files, loading 9
00:48:23,272 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:48:23,278 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:48:23,308 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:48:23,310 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:48:23,323 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:48:23,382 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:48:23,383 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:48:23,386 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:48:23,386 root INFO Starting at time 1745297303.386352
00:48:23,386 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:48:23,386 root INFO Completed 1 / 24 vertices
00:48:23,386 root INFO Completed 3 / 24 vertices
00:48:23,386 root INFO Completed 5 / 24 vertices
00:48:23,386 root INFO Completed 7 / 24 vertices
00:48:23,386 root INFO Completed 9 / 24 vertices
00:48:23,386 root INFO Completed 11 / 24 vertices
00:48:23,386 root INFO Completed 13 / 24 vertices
00:48:23,386 root INFO Completed 15 / 24 vertices
00:48:23,386 root INFO Completed 17 / 24 vertices
00:48:23,386 root INFO Completed 19 / 24 vertices
00:48:23,386 root INFO Completed 21 / 24 vertices
00:48:23,386 root INFO Completed 23 / 24 vertices
00:48:23,386 root INFO Completed preprocessing of transition probabilities for vertices
00:48:23,386 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:48:23,386 root INFO Completed 1 / 25 edges
00:48:23,386 root INFO Completed 3 / 25 edges
00:48:23,386 root INFO Completed 5 / 25 edges
00:48:23,386 root INFO Completed 7 / 25 edges
00:48:23,386 root INFO Completed 9 / 25 edges
00:48:23,386 root INFO Completed 11 / 25 edges
00:48:23,386 root INFO Completed 13 / 25 edges
00:48:23,386 root INFO Completed 15 / 25 edges
00:48:23,387 root INFO Completed 17 / 25 edges
00:48:23,387 root INFO Completed 19 / 25 edges
00:48:23,387 root INFO Completed 21 / 25 edges
00:48:23,387 root INFO Completed 23 / 25 edges
00:48:23,387 root INFO Completed 25 / 25 edges
00:48:23,387 root INFO Completed preprocessing of transition probabilities for edges
00:48:23,387 root INFO Simulating walks on graph at time 1745297303.3871841
00:48:23,387 root INFO Walk iteration: 1/10
00:48:23,387 root INFO Walk iteration: 2/10
00:48:23,388 root INFO Walk iteration: 3/10
00:48:23,389 root INFO Walk iteration: 4/10
00:48:23,389 root INFO Walk iteration: 5/10
00:48:23,390 root INFO Walk iteration: 6/10
00:48:23,390 root INFO Walk iteration: 7/10
00:48:23,391 root INFO Walk iteration: 8/10
00:48:23,392 root INFO Walk iteration: 9/10
00:48:23,392 root INFO Walk iteration: 10/10
00:48:23,393 root INFO Learning embeddings at time 1745297303.393234
00:48:23,393 gensim.models.word2vec INFO collecting all words and their counts
00:48:23,393 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:48:23,393 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:48:23,393 gensim.models.word2vec INFO Creating a fresh vocabulary
00:48:23,393 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:48:23.393839', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:48:23,393 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:48:23.393870', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:48:23,393 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:48:23,393 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:48:23,393 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:48:23.393983', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:48:23,394 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:48:23,394 gensim.models.word2vec INFO resetting layer weights
00:48:23,394 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:48:23.394270', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:48:23,394 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:48:23.394297', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:48:23,398 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 201125 effective words/s
00:48:23,401 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 208879 effective words/s
00:48:23,405 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205963 effective words/s
00:48:23,405 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172461 effective words/s', 'datetime': '2025-04-22T00:48:23.405108', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:48:23,405 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:48:23.405137', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:48:23,405 root INFO Completed. Ending time is 1745297303.405163 Elapsed time is -0.01881098747253418
00:48:26,980 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:48:26,982 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:48:27,2 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:48:27,3 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:48:27,4 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:48:27,20 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:48:27,21 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:48:27,22 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:48:27,27 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:48:27,72 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:48:27,73 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:48:27,75 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:48:27,76 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:48:27,78 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:48:27,81 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:48:27,81 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:48:27,292 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:48:27,316 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:48:27,322 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:48:27,330 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:48:27,333 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:48:27,382 graphrag.cli.index INFO All workflows completed successfully.
00:55:47,764 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
00:55:48,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
00:55:48,903 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
00:55:48,909 graphrag.cli.index INFO Starting pipeline run. dry_run=False
00:55:48,910 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
00:55:48,912 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
00:55:48,912 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
00:55:48,912 graphrag.index.input.factory INFO using file storage for input
00:55:48,913 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
00:55:48,913 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
00:55:48,921 graphrag.index.input.text INFO Found 9 files, loading 9
00:55:48,922 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
00:55:48,928 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:55:48,958 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:55:48,960 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:55:48,973 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:55:49,35 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:55:49,36 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:55:49,40 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
00:55:49,40 root INFO Starting at time 1745297749.0402591
00:55:49,40 root INFO Beginning preprocessing of transition probabilities for 24 vertices
00:55:49,40 root INFO Completed 1 / 24 vertices
00:55:49,40 root INFO Completed 3 / 24 vertices
00:55:49,40 root INFO Completed 5 / 24 vertices
00:55:49,40 root INFO Completed 7 / 24 vertices
00:55:49,40 root INFO Completed 9 / 24 vertices
00:55:49,40 root INFO Completed 11 / 24 vertices
00:55:49,40 root INFO Completed 13 / 24 vertices
00:55:49,40 root INFO Completed 15 / 24 vertices
00:55:49,40 root INFO Completed 17 / 24 vertices
00:55:49,40 root INFO Completed 19 / 24 vertices
00:55:49,40 root INFO Completed 21 / 24 vertices
00:55:49,40 root INFO Completed 23 / 24 vertices
00:55:49,40 root INFO Completed preprocessing of transition probabilities for vertices
00:55:49,40 root INFO Beginning preprocessing of transition probabilities for 25 edges
00:55:49,40 root INFO Completed 1 / 25 edges
00:55:49,40 root INFO Completed 3 / 25 edges
00:55:49,40 root INFO Completed 5 / 25 edges
00:55:49,40 root INFO Completed 7 / 25 edges
00:55:49,40 root INFO Completed 9 / 25 edges
00:55:49,40 root INFO Completed 11 / 25 edges
00:55:49,40 root INFO Completed 13 / 25 edges
00:55:49,40 root INFO Completed 15 / 25 edges
00:55:49,40 root INFO Completed 17 / 25 edges
00:55:49,40 root INFO Completed 19 / 25 edges
00:55:49,40 root INFO Completed 21 / 25 edges
00:55:49,40 root INFO Completed 23 / 25 edges
00:55:49,41 root INFO Completed 25 / 25 edges
00:55:49,41 root INFO Completed preprocessing of transition probabilities for edges
00:55:49,41 root INFO Simulating walks on graph at time 1745297749.041055
00:55:49,41 root INFO Walk iteration: 1/10
00:55:49,41 root INFO Walk iteration: 2/10
00:55:49,42 root INFO Walk iteration: 3/10
00:55:49,42 root INFO Walk iteration: 4/10
00:55:49,43 root INFO Walk iteration: 5/10
00:55:49,44 root INFO Walk iteration: 6/10
00:55:49,44 root INFO Walk iteration: 7/10
00:55:49,45 root INFO Walk iteration: 8/10
00:55:49,45 root INFO Walk iteration: 9/10
00:55:49,46 root INFO Walk iteration: 10/10
00:55:49,47 root INFO Learning embeddings at time 1745297749.047012
00:55:49,47 gensim.models.word2vec INFO collecting all words and their counts
00:55:49,47 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
00:55:49,47 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
00:55:49,47 gensim.models.word2vec INFO Creating a fresh vocabulary
00:55:49,47 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T00:55:49.047595', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:55:49,47 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T00:55:49.047625', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:55:49,47 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
00:55:49,47 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
00:55:49,47 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T00:55:49.047733', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
00:55:49,47 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
00:55:49,47 gensim.models.word2vec INFO resetting layer weights
00:55:49,48 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T00:55:49.048012', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
00:55:49,48 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T00:55:49.048039', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:55:49,51 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 204975 effective words/s
00:55:49,55 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 215956 effective words/s
00:55:49,58 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 211587 effective words/s
00:55:49,58 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 177290 effective words/s', 'datetime': '2025-04-22T00:55:49.058555', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
00:55:49,58 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T00:55:49.058587', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
00:55:49,58 root INFO Completed. Ending time is 1745297749.058614 Elapsed time is -0.01835489273071289
00:55:52,644 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:55:52,647 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:55:52,666 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:55:52,667 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:55:52,669 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:55:52,684 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:55:52,685 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:55:52,687 graphrag.utils.storage INFO reading table from storage: communities.parquet
00:55:52,692 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
00:55:52,737 graphrag.utils.storage INFO reading table from storage: documents.parquet
00:55:52,739 graphrag.utils.storage INFO reading table from storage: relationships.parquet
00:55:52,740 graphrag.utils.storage INFO reading table from storage: text_units.parquet
00:55:52,742 graphrag.utils.storage INFO reading table from storage: entities.parquet
00:55:52,743 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
00:55:52,746 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
00:55:52,746 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
00:55:52,958 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:55:52,965 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
00:55:52,968 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
00:55:52,990 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
00:55:52,996 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:55:53,47 graphrag.cli.index INFO All workflows completed successfully.
01:00:16,818 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:00:17,811 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:00:18,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:00:18,531 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:00:18,532 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:00:18,533 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:00:18,533 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:00:18,533 graphrag.index.input.factory INFO using file storage for input
01:00:18,533 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:00:18,534 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:00:18,540 graphrag.index.input.text INFO Found 9 files, loading 9
01:00:18,541 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:00:18,547 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:00:18,576 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:00:18,577 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:00:18,590 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:00:18,650 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:00:18,651 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:00:18,654 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:00:18,654 root INFO Starting at time 1745298018.654944
01:00:18,654 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:00:18,654 root INFO Completed 1 / 24 vertices
01:00:18,655 root INFO Completed 3 / 24 vertices
01:00:18,655 root INFO Completed 5 / 24 vertices
01:00:18,655 root INFO Completed 7 / 24 vertices
01:00:18,655 root INFO Completed 9 / 24 vertices
01:00:18,655 root INFO Completed 11 / 24 vertices
01:00:18,655 root INFO Completed 13 / 24 vertices
01:00:18,655 root INFO Completed 15 / 24 vertices
01:00:18,655 root INFO Completed 17 / 24 vertices
01:00:18,655 root INFO Completed 19 / 24 vertices
01:00:18,655 root INFO Completed 21 / 24 vertices
01:00:18,655 root INFO Completed 23 / 24 vertices
01:00:18,655 root INFO Completed preprocessing of transition probabilities for vertices
01:00:18,655 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:00:18,655 root INFO Completed 1 / 25 edges
01:00:18,655 root INFO Completed 3 / 25 edges
01:00:18,655 root INFO Completed 5 / 25 edges
01:00:18,655 root INFO Completed 7 / 25 edges
01:00:18,655 root INFO Completed 9 / 25 edges
01:00:18,655 root INFO Completed 11 / 25 edges
01:00:18,655 root INFO Completed 13 / 25 edges
01:00:18,655 root INFO Completed 15 / 25 edges
01:00:18,655 root INFO Completed 17 / 25 edges
01:00:18,655 root INFO Completed 19 / 25 edges
01:00:18,655 root INFO Completed 21 / 25 edges
01:00:18,655 root INFO Completed 23 / 25 edges
01:00:18,655 root INFO Completed 25 / 25 edges
01:00:18,655 root INFO Completed preprocessing of transition probabilities for edges
01:00:18,655 root INFO Simulating walks on graph at time 1745298018.655841
01:00:18,655 root INFO Walk iteration: 1/10
01:00:18,656 root INFO Walk iteration: 2/10
01:00:18,657 root INFO Walk iteration: 3/10
01:00:18,657 root INFO Walk iteration: 4/10
01:00:18,658 root INFO Walk iteration: 5/10
01:00:18,659 root INFO Walk iteration: 6/10
01:00:18,659 root INFO Walk iteration: 7/10
01:00:18,660 root INFO Walk iteration: 8/10
01:00:18,661 root INFO Walk iteration: 9/10
01:00:18,661 root INFO Walk iteration: 10/10
01:00:18,662 root INFO Learning embeddings at time 1745298018.662302
01:00:18,662 gensim.models.word2vec INFO collecting all words and their counts
01:00:18,662 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:00:18,662 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:00:18,662 gensim.models.word2vec INFO Creating a fresh vocabulary
01:00:18,662 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:00:18.662975', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:00:18,663 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:00:18.663012', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:00:18,663 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:00:18,663 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:00:18,663 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:00:18.663135', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:00:18,663 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:00:18,663 gensim.models.word2vec INFO resetting layer weights
01:00:18,663 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:00:18.663457', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:00:18,663 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:00:18.663488', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:00:18,667 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 188572 effective words/s
01:00:18,671 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 233572 effective words/s
01:00:18,674 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 200652 effective words/s
01:00:18,675 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 161727 effective words/s', 'datetime': '2025-04-22T01:00:18.675020', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:00:18,675 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:00:18.675057', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:00:18,675 root INFO Completed. Ending time is 1745298018.6750872 Elapsed time is -0.02014327049255371
01:00:22,260 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:00:22,262 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:00:22,282 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:00:22,284 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:00:22,285 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:00:22,300 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:00:22,302 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:00:22,304 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:00:22,308 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:00:22,353 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:00:22,355 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:00:22,357 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:00:22,358 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:00:22,360 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:00:22,363 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:00:22,363 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:00:22,574 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:00:22,598 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:00:22,601 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:00:22,606 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:00:22,612 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:00:22,663 graphrag.cli.index INFO All workflows completed successfully.
01:09:15,355 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:09:16,545 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:09:17,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:09:17,199 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:09:17,200 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:09:17,202 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
01:09:17,202 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
01:09:17,202 graphrag.index.input.factory INFO using file storage for input
01:09:17,203 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
01:09:17,204 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:09:17,212 graphrag.index.input.text INFO Found 9 files, loading 9
01:09:17,213 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:09:17,220 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:09:17,251 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:09:17,253 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:09:17,266 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:09:17,326 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:09:17,327 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:09:17,330 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:09:17,330 root INFO Starting at time 1745298557.330282
01:09:17,330 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:09:17,330 root INFO Completed 1 / 24 vertices
01:09:17,330 root INFO Completed 3 / 24 vertices
01:09:17,330 root INFO Completed 5 / 24 vertices
01:09:17,330 root INFO Completed 7 / 24 vertices
01:09:17,330 root INFO Completed 9 / 24 vertices
01:09:17,330 root INFO Completed 11 / 24 vertices
01:09:17,330 root INFO Completed 13 / 24 vertices
01:09:17,330 root INFO Completed 15 / 24 vertices
01:09:17,330 root INFO Completed 17 / 24 vertices
01:09:17,330 root INFO Completed 19 / 24 vertices
01:09:17,330 root INFO Completed 21 / 24 vertices
01:09:17,330 root INFO Completed 23 / 24 vertices
01:09:17,330 root INFO Completed preprocessing of transition probabilities for vertices
01:09:17,330 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:09:17,330 root INFO Completed 1 / 25 edges
01:09:17,330 root INFO Completed 3 / 25 edges
01:09:17,330 root INFO Completed 5 / 25 edges
01:09:17,330 root INFO Completed 7 / 25 edges
01:09:17,330 root INFO Completed 9 / 25 edges
01:09:17,330 root INFO Completed 11 / 25 edges
01:09:17,330 root INFO Completed 13 / 25 edges
01:09:17,330 root INFO Completed 15 / 25 edges
01:09:17,330 root INFO Completed 17 / 25 edges
01:09:17,330 root INFO Completed 19 / 25 edges
01:09:17,331 root INFO Completed 21 / 25 edges
01:09:17,331 root INFO Completed 23 / 25 edges
01:09:17,331 root INFO Completed 25 / 25 edges
01:09:17,331 root INFO Completed preprocessing of transition probabilities for edges
01:09:17,331 root INFO Simulating walks on graph at time 1745298557.331091
01:09:17,331 root INFO Walk iteration: 1/10
01:09:17,331 root INFO Walk iteration: 2/10
01:09:17,332 root INFO Walk iteration: 3/10
01:09:17,332 root INFO Walk iteration: 4/10
01:09:17,333 root INFO Walk iteration: 5/10
01:09:17,334 root INFO Walk iteration: 6/10
01:09:17,334 root INFO Walk iteration: 7/10
01:09:17,335 root INFO Walk iteration: 8/10
01:09:17,336 root INFO Walk iteration: 9/10
01:09:17,336 root INFO Walk iteration: 10/10
01:09:17,337 root INFO Learning embeddings at time 1745298557.337476
01:09:17,337 gensim.models.word2vec INFO collecting all words and their counts
01:09:17,337 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:09:17,338 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:09:17,338 gensim.models.word2vec INFO Creating a fresh vocabulary
01:09:17,338 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:09:17.338085', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:09:17,338 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:09:17.338115', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:09:17,338 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:09:17,338 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:09:17,338 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:09:17.338223', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:09:17,338 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:09:17,338 gensim.models.word2vec INFO resetting layer weights
01:09:17,338 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:09:17.338508', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:09:17,338 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:09:17.338535', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:09:17,342 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 200055 effective words/s
01:09:17,345 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209969 effective words/s
01:09:17,349 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 202739 effective words/s
01:09:17,349 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 171048 effective words/s', 'datetime': '2025-04-22T01:09:17.349435', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:09:17,349 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:09:17.349467', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:09:17,349 root INFO Completed. Ending time is 1745298557.349494 Elapsed time is -0.019212007522583008
01:09:20,940 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:09:20,942 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:09:20,962 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:09:20,963 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:09:20,964 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:09:20,980 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:09:20,981 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:09:20,982 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:09:20,987 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:09:21,32 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:09:21,34 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:09:21,35 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:09:21,37 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:09:21,38 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:09:21,41 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:09:21,41 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:09:21,252 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:09:21,259 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:09:21,262 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:09:21,283 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:09:21,289 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:09:21,340 graphrag.cli.index INFO All workflows completed successfully.
01:13:34,186 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:13:34,939 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:13:35,653 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:13:35,660 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:13:35,662 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:13:35,663 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
01:13:35,663 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
01:13:35,663 graphrag.index.input.factory INFO using file storage for input
01:13:35,665 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
01:13:35,666 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:13:35,673 graphrag.index.input.text INFO Found 9 files, loading 9
01:13:35,674 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:13:35,680 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:13:35,710 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:13:35,711 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:13:35,724 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:13:35,784 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:13:35,786 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:13:35,788 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:13:35,788 root INFO Starting at time 1745298815.788725
01:13:35,788 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:13:35,788 root INFO Completed 1 / 24 vertices
01:13:35,788 root INFO Completed 3 / 24 vertices
01:13:35,788 root INFO Completed 5 / 24 vertices
01:13:35,788 root INFO Completed 7 / 24 vertices
01:13:35,788 root INFO Completed 9 / 24 vertices
01:13:35,788 root INFO Completed 11 / 24 vertices
01:13:35,788 root INFO Completed 13 / 24 vertices
01:13:35,788 root INFO Completed 15 / 24 vertices
01:13:35,788 root INFO Completed 17 / 24 vertices
01:13:35,788 root INFO Completed 19 / 24 vertices
01:13:35,788 root INFO Completed 21 / 24 vertices
01:13:35,788 root INFO Completed 23 / 24 vertices
01:13:35,789 root INFO Completed preprocessing of transition probabilities for vertices
01:13:35,789 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:13:35,789 root INFO Completed 1 / 25 edges
01:13:35,789 root INFO Completed 3 / 25 edges
01:13:35,789 root INFO Completed 5 / 25 edges
01:13:35,789 root INFO Completed 7 / 25 edges
01:13:35,789 root INFO Completed 9 / 25 edges
01:13:35,789 root INFO Completed 11 / 25 edges
01:13:35,789 root INFO Completed 13 / 25 edges
01:13:35,789 root INFO Completed 15 / 25 edges
01:13:35,789 root INFO Completed 17 / 25 edges
01:13:35,789 root INFO Completed 19 / 25 edges
01:13:35,789 root INFO Completed 21 / 25 edges
01:13:35,789 root INFO Completed 23 / 25 edges
01:13:35,789 root INFO Completed 25 / 25 edges
01:13:35,789 root INFO Completed preprocessing of transition probabilities for edges
01:13:35,789 root INFO Simulating walks on graph at time 1745298815.789556
01:13:35,789 root INFO Walk iteration: 1/10
01:13:35,790 root INFO Walk iteration: 2/10
01:13:35,790 root INFO Walk iteration: 3/10
01:13:35,791 root INFO Walk iteration: 4/10
01:13:35,792 root INFO Walk iteration: 5/10
01:13:35,792 root INFO Walk iteration: 6/10
01:13:35,793 root INFO Walk iteration: 7/10
01:13:35,793 root INFO Walk iteration: 8/10
01:13:35,794 root INFO Walk iteration: 9/10
01:13:35,794 root INFO Walk iteration: 10/10
01:13:35,795 root INFO Learning embeddings at time 1745298815.795462
01:13:35,795 gensim.models.word2vec INFO collecting all words and their counts
01:13:35,795 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:13:35,795 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:13:35,795 gensim.models.word2vec INFO Creating a fresh vocabulary
01:13:35,796 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:13:35.796048', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:13:35,796 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:13:35.796079', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:13:35,796 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:13:35,796 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:13:35,796 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:13:35.796188', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:13:35,796 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:13:35,796 gensim.models.word2vec INFO resetting layer weights
01:13:35,796 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:13:35.796465', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:13:35,796 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:13:35.796499', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:13:35,800 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 205417 effective words/s
01:13:35,803 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 211037 effective words/s
01:13:35,807 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 206824 effective words/s
01:13:35,807 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173747 effective words/s', 'datetime': '2025-04-22T01:13:35.807230', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:13:35,807 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:13:35.807262', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:13:35,807 root INFO Completed. Ending time is 1745298815.8072891 Elapsed time is -0.018564224243164062
01:13:39,385 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:13:39,387 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:13:39,407 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:13:39,408 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:13:39,409 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:13:39,425 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:13:39,426 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:13:39,428 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:13:39,432 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:13:39,477 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:13:39,479 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:13:39,480 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:13:39,482 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:13:39,483 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:13:39,486 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:13:39,486 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:13:39,701 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:13:39,710 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:13:39,713 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:13:39,718 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:13:39,720 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:13:39,785 graphrag.cli.index INFO All workflows completed successfully.
01:27:47,428 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:27:48,110 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:27:48,761 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:27:48,767 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:27:48,768 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "Ai_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:27:48,770 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_output
01:27:48,770 graphrag.index.input.factory INFO loading input from root_dir=Ai_safety_input
01:27:48,770 graphrag.index.input.factory INFO using file storage for input
01:27:48,771 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/Ai_safety_input for files matching .*\.txt$
01:27:48,772 graphrag.index.input.text INFO found text files from Ai_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:27:48,781 graphrag.index.input.text INFO Found 9 files, loading 9
01:27:48,782 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:27:48,790 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:27:48,822 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:27:48,823 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:27:48,836 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:27:48,897 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:27:48,898 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:27:48,902 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:27:48,902 root INFO Starting at time 1745299668.902082
01:27:48,902 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:27:48,902 root INFO Completed 1 / 24 vertices
01:27:48,902 root INFO Completed 3 / 24 vertices
01:27:48,902 root INFO Completed 5 / 24 vertices
01:27:48,902 root INFO Completed 7 / 24 vertices
01:27:48,902 root INFO Completed 9 / 24 vertices
01:27:48,902 root INFO Completed 11 / 24 vertices
01:27:48,902 root INFO Completed 13 / 24 vertices
01:27:48,902 root INFO Completed 15 / 24 vertices
01:27:48,902 root INFO Completed 17 / 24 vertices
01:27:48,902 root INFO Completed 19 / 24 vertices
01:27:48,902 root INFO Completed 21 / 24 vertices
01:27:48,902 root INFO Completed 23 / 24 vertices
01:27:48,902 root INFO Completed preprocessing of transition probabilities for vertices
01:27:48,902 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:27:48,902 root INFO Completed 1 / 25 edges
01:27:48,902 root INFO Completed 3 / 25 edges
01:27:48,902 root INFO Completed 5 / 25 edges
01:27:48,902 root INFO Completed 7 / 25 edges
01:27:48,902 root INFO Completed 9 / 25 edges
01:27:48,902 root INFO Completed 11 / 25 edges
01:27:48,902 root INFO Completed 13 / 25 edges
01:27:48,902 root INFO Completed 15 / 25 edges
01:27:48,902 root INFO Completed 17 / 25 edges
01:27:48,902 root INFO Completed 19 / 25 edges
01:27:48,902 root INFO Completed 21 / 25 edges
01:27:48,902 root INFO Completed 23 / 25 edges
01:27:48,902 root INFO Completed 25 / 25 edges
01:27:48,902 root INFO Completed preprocessing of transition probabilities for edges
01:27:48,902 root INFO Simulating walks on graph at time 1745299668.9028878
01:27:48,902 root INFO Walk iteration: 1/10
01:27:48,903 root INFO Walk iteration: 2/10
01:27:48,904 root INFO Walk iteration: 3/10
01:27:48,904 root INFO Walk iteration: 4/10
01:27:48,905 root INFO Walk iteration: 5/10
01:27:48,905 root INFO Walk iteration: 6/10
01:27:48,906 root INFO Walk iteration: 7/10
01:27:48,907 root INFO Walk iteration: 8/10
01:27:48,907 root INFO Walk iteration: 9/10
01:27:48,908 root INFO Walk iteration: 10/10
01:27:48,908 root INFO Learning embeddings at time 1745299668.9088042
01:27:48,909 gensim.models.word2vec INFO collecting all words and their counts
01:27:48,909 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:27:48,909 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:27:48,909 gensim.models.word2vec INFO Creating a fresh vocabulary
01:27:48,909 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:27:48.909687', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:27:48,909 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:27:48.909718', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:27:48,909 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:27:48,909 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:27:48,909 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:27:48.909831', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:27:48,909 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:27:48,909 gensim.models.word2vec INFO resetting layer weights
01:27:48,910 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:27:48.910119', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:27:48,910 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:27:48.910147', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:27:48,913 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 195682 effective words/s
01:27:48,917 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 214207 effective words/s
01:27:48,920 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 209628 effective words/s
01:27:48,920 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 174079 effective words/s', 'datetime': '2025-04-22T01:27:48.920857', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:27:48,920 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:27:48.920883', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:27:48,920 root INFO Completed. Ending time is 1745299668.920907 Elapsed time is -0.018825054168701172
01:27:52,512 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:27:52,514 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:27:52,533 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:27:52,535 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:27:52,536 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:27:52,552 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:27:52,553 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:27:52,555 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:27:52,560 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:27:52,605 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:27:52,607 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:27:52,608 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:27:52,610 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:27:52,611 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:27:52,614 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:27:52,614 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:27:52,852 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:27:52,880 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:27:52,883 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:27:52,888 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:27:52,891 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:27:52,954 graphrag.cli.index INFO All workflows completed successfully.
01:36:06,90 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:36:06,736 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:36:06,999 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:36:07,1 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:36:07,2 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:36:07,3 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:36:07,3 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:36:07,3 graphrag.index.input.factory INFO using file storage for input
01:36:07,3 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:36:07,3 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:36:07,10 graphrag.index.input.text INFO Found 9 files, loading 9
01:36:07,12 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:36:07,18 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:36:07,49 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:36:07,51 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:36:07,63 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:36:07,126 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:36:07,128 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:36:07,131 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:36:07,131 root INFO Starting at time 1745300167.1314769
01:36:07,131 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:36:07,131 root INFO Completed 1 / 24 vertices
01:36:07,131 root INFO Completed 3 / 24 vertices
01:36:07,131 root INFO Completed 5 / 24 vertices
01:36:07,131 root INFO Completed 7 / 24 vertices
01:36:07,131 root INFO Completed 9 / 24 vertices
01:36:07,131 root INFO Completed 11 / 24 vertices
01:36:07,131 root INFO Completed 13 / 24 vertices
01:36:07,131 root INFO Completed 15 / 24 vertices
01:36:07,131 root INFO Completed 17 / 24 vertices
01:36:07,131 root INFO Completed 19 / 24 vertices
01:36:07,131 root INFO Completed 21 / 24 vertices
01:36:07,131 root INFO Completed 23 / 24 vertices
01:36:07,131 root INFO Completed preprocessing of transition probabilities for vertices
01:36:07,131 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:36:07,131 root INFO Completed 1 / 25 edges
01:36:07,131 root INFO Completed 3 / 25 edges
01:36:07,131 root INFO Completed 5 / 25 edges
01:36:07,131 root INFO Completed 7 / 25 edges
01:36:07,131 root INFO Completed 9 / 25 edges
01:36:07,132 root INFO Completed 11 / 25 edges
01:36:07,132 root INFO Completed 13 / 25 edges
01:36:07,132 root INFO Completed 15 / 25 edges
01:36:07,132 root INFO Completed 17 / 25 edges
01:36:07,132 root INFO Completed 19 / 25 edges
01:36:07,132 root INFO Completed 21 / 25 edges
01:36:07,132 root INFO Completed 23 / 25 edges
01:36:07,132 root INFO Completed 25 / 25 edges
01:36:07,132 root INFO Completed preprocessing of transition probabilities for edges
01:36:07,132 root INFO Simulating walks on graph at time 1745300167.1322932
01:36:07,132 root INFO Walk iteration: 1/10
01:36:07,133 root INFO Walk iteration: 2/10
01:36:07,133 root INFO Walk iteration: 3/10
01:36:07,134 root INFO Walk iteration: 4/10
01:36:07,134 root INFO Walk iteration: 5/10
01:36:07,135 root INFO Walk iteration: 6/10
01:36:07,135 root INFO Walk iteration: 7/10
01:36:07,136 root INFO Walk iteration: 8/10
01:36:07,137 root INFO Walk iteration: 9/10
01:36:07,137 root INFO Walk iteration: 10/10
01:36:07,138 root INFO Learning embeddings at time 1745300167.138359
01:36:07,138 gensim.models.word2vec INFO collecting all words and their counts
01:36:07,138 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:36:07,138 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:36:07,138 gensim.models.word2vec INFO Creating a fresh vocabulary
01:36:07,138 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:36:07.138957', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:36:07,138 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:36:07.138988', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:36:07,139 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:36:07,139 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:36:07,139 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:36:07.139099', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:36:07,139 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:36:07,139 gensim.models.word2vec INFO resetting layer weights
01:36:07,139 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:36:07.139383', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:36:07,139 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:36:07.139410', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:36:07,143 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 201606 effective words/s
01:36:07,146 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 214238 effective words/s
01:36:07,150 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 206672 effective words/s
01:36:07,150 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 173587 effective words/s', 'datetime': '2025-04-22T01:36:07.150151', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:36:07,150 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:36:07.150176', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:36:07,150 root INFO Completed. Ending time is 1745300167.150201 Elapsed time is -0.01872420310974121
01:36:10,761 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:36:10,763 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:36:10,783 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:36:10,784 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:36:10,786 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:36:10,803 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:36:10,804 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:36:10,806 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:36:10,811 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:36:10,858 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:36:10,859 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:36:10,861 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:36:10,862 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:36:10,863 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:36:10,866 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:36:10,866 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:36:11,103 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:36:11,132 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:36:11,134 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:36:11,157 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:36:11,160 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:36:11,211 graphrag.cli.index INFO All workflows completed successfully.
01:44:12,170 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:44:12,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:44:13,361 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:44:13,367 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:44:13,368 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:44:13,370 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:44:13,370 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:44:13,370 graphrag.index.input.factory INFO using file storage for input
01:44:13,371 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:44:13,372 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:44:13,381 graphrag.index.input.text INFO Found 9 files, loading 9
01:44:13,383 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:44:13,391 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:44:13,423 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:44:13,425 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:44:13,437 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:44:13,498 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:44:13,499 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:44:13,502 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:44:13,502 root INFO Starting at time 1745300653.502708
01:44:13,502 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:44:13,502 root INFO Completed 1 / 24 vertices
01:44:13,502 root INFO Completed 3 / 24 vertices
01:44:13,502 root INFO Completed 5 / 24 vertices
01:44:13,502 root INFO Completed 7 / 24 vertices
01:44:13,502 root INFO Completed 9 / 24 vertices
01:44:13,502 root INFO Completed 11 / 24 vertices
01:44:13,502 root INFO Completed 13 / 24 vertices
01:44:13,502 root INFO Completed 15 / 24 vertices
01:44:13,502 root INFO Completed 17 / 24 vertices
01:44:13,502 root INFO Completed 19 / 24 vertices
01:44:13,502 root INFO Completed 21 / 24 vertices
01:44:13,502 root INFO Completed 23 / 24 vertices
01:44:13,503 root INFO Completed preprocessing of transition probabilities for vertices
01:44:13,503 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:44:13,503 root INFO Completed 1 / 25 edges
01:44:13,503 root INFO Completed 3 / 25 edges
01:44:13,503 root INFO Completed 5 / 25 edges
01:44:13,503 root INFO Completed 7 / 25 edges
01:44:13,503 root INFO Completed 9 / 25 edges
01:44:13,503 root INFO Completed 11 / 25 edges
01:44:13,503 root INFO Completed 13 / 25 edges
01:44:13,503 root INFO Completed 15 / 25 edges
01:44:13,503 root INFO Completed 17 / 25 edges
01:44:13,503 root INFO Completed 19 / 25 edges
01:44:13,503 root INFO Completed 21 / 25 edges
01:44:13,503 root INFO Completed 23 / 25 edges
01:44:13,503 root INFO Completed 25 / 25 edges
01:44:13,503 root INFO Completed preprocessing of transition probabilities for edges
01:44:13,503 root INFO Simulating walks on graph at time 1745300653.5035431
01:44:13,503 root INFO Walk iteration: 1/10
01:44:13,504 root INFO Walk iteration: 2/10
01:44:13,504 root INFO Walk iteration: 3/10
01:44:13,505 root INFO Walk iteration: 4/10
01:44:13,506 root INFO Walk iteration: 5/10
01:44:13,506 root INFO Walk iteration: 6/10
01:44:13,507 root INFO Walk iteration: 7/10
01:44:13,507 root INFO Walk iteration: 8/10
01:44:13,508 root INFO Walk iteration: 9/10
01:44:13,509 root INFO Walk iteration: 10/10
01:44:13,509 root INFO Learning embeddings at time 1745300653.5096729
01:44:13,509 gensim.models.word2vec INFO collecting all words and their counts
01:44:13,510 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:44:13,510 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:44:13,510 gensim.models.word2vec INFO Creating a fresh vocabulary
01:44:13,510 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:44:13.510270', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:44:13,510 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:44:13.510301', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:44:13,510 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:44:13,510 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:44:13,510 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:44:13.510412', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:44:13,510 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:44:13,510 gensim.models.word2vec INFO resetting layer weights
01:44:13,510 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:44:13.510708', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:44:13,510 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:44:13.510735', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:44:13,514 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 194132 effective words/s
01:44:13,517 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 208678 effective words/s
01:44:13,521 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 200704 effective words/s
01:44:13,521 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 171118 effective words/s', 'datetime': '2025-04-22T01:44:13.521631', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:44:13,521 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:44:13.521662', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:44:13,521 root INFO Completed. Ending time is 1745300653.5216892 Elapsed time is -0.018981218338012695
01:44:17,131 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:44:17,133 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:44:17,153 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:44:17,154 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:44:17,155 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:44:17,171 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:44:17,173 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:44:17,174 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:44:17,180 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:44:17,227 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:44:17,228 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:44:17,230 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:44:17,231 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:44:17,232 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:44:17,235 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:44:17,235 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:44:17,472 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:44:17,501 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:44:17,504 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:44:17,511 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:44:17,513 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:44:17,579 graphrag.cli.index INFO All workflows completed successfully.
01:50:20,762 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:50:21,361 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:50:22,156 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:50:22,162 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:50:22,163 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:50:22,165 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:50:22,165 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:50:22,165 graphrag.index.input.factory INFO using file storage for input
01:50:22,166 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:50:22,168 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:50:22,176 graphrag.index.input.text INFO Found 9 files, loading 9
01:50:22,177 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:50:22,184 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:50:22,213 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:50:22,215 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:50:22,228 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:50:22,289 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:50:22,291 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:50:22,294 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:50:22,294 root INFO Starting at time 1745301022.294813
01:50:22,294 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:50:22,294 root INFO Completed 1 / 24 vertices
01:50:22,294 root INFO Completed 3 / 24 vertices
01:50:22,294 root INFO Completed 5 / 24 vertices
01:50:22,294 root INFO Completed 7 / 24 vertices
01:50:22,294 root INFO Completed 9 / 24 vertices
01:50:22,294 root INFO Completed 11 / 24 vertices
01:50:22,294 root INFO Completed 13 / 24 vertices
01:50:22,294 root INFO Completed 15 / 24 vertices
01:50:22,295 root INFO Completed 17 / 24 vertices
01:50:22,295 root INFO Completed 19 / 24 vertices
01:50:22,295 root INFO Completed 21 / 24 vertices
01:50:22,295 root INFO Completed 23 / 24 vertices
01:50:22,295 root INFO Completed preprocessing of transition probabilities for vertices
01:50:22,295 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:50:22,295 root INFO Completed 1 / 25 edges
01:50:22,295 root INFO Completed 3 / 25 edges
01:50:22,295 root INFO Completed 5 / 25 edges
01:50:22,295 root INFO Completed 7 / 25 edges
01:50:22,295 root INFO Completed 9 / 25 edges
01:50:22,295 root INFO Completed 11 / 25 edges
01:50:22,295 root INFO Completed 13 / 25 edges
01:50:22,295 root INFO Completed 15 / 25 edges
01:50:22,295 root INFO Completed 17 / 25 edges
01:50:22,295 root INFO Completed 19 / 25 edges
01:50:22,295 root INFO Completed 21 / 25 edges
01:50:22,295 root INFO Completed 23 / 25 edges
01:50:22,295 root INFO Completed 25 / 25 edges
01:50:22,295 root INFO Completed preprocessing of transition probabilities for edges
01:50:22,295 root INFO Simulating walks on graph at time 1745301022.295594
01:50:22,295 root INFO Walk iteration: 1/10
01:50:22,296 root INFO Walk iteration: 2/10
01:50:22,296 root INFO Walk iteration: 3/10
01:50:22,297 root INFO Walk iteration: 4/10
01:50:22,298 root INFO Walk iteration: 5/10
01:50:22,298 root INFO Walk iteration: 6/10
01:50:22,299 root INFO Walk iteration: 7/10
01:50:22,299 root INFO Walk iteration: 8/10
01:50:22,300 root INFO Walk iteration: 9/10
01:50:22,301 root INFO Walk iteration: 10/10
01:50:22,301 root INFO Learning embeddings at time 1745301022.301638
01:50:22,301 gensim.models.word2vec INFO collecting all words and their counts
01:50:22,301 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:50:22,302 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:50:22,302 gensim.models.word2vec INFO Creating a fresh vocabulary
01:50:22,302 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:50:22.302240', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:50:22,302 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:50:22.302271', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:50:22,302 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:50:22,302 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:50:22,302 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:50:22.302380', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:50:22,302 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:50:22,302 gensim.models.word2vec INFO resetting layer weights
01:50:22,302 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:50:22.302676', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:50:22,302 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:50:22.302705', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:50:22,306 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199937 effective words/s
01:50:22,310 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 210033 effective words/s
01:50:22,313 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 204658 effective words/s
01:50:22,313 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170710 effective words/s', 'datetime': '2025-04-22T01:50:22.313626', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:50:22,313 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:50:22.313653', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:50:22,313 root INFO Completed. Ending time is 1745301022.313676 Elapsed time is -0.018863201141357422
01:50:26,46 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:50:26,48 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:50:26,68 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:50:26,70 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:50:26,71 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:50:26,86 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:50:26,88 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:50:26,89 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:50:26,95 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:50:26,142 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:50:26,143 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:50:26,145 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:50:26,146 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:50:26,148 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:50:26,151 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:50:26,151 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:50:26,388 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:50:26,417 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:50:26,421 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:50:26,428 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:50:26,431 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:50:26,497 graphrag.cli.index INFO All workflows completed successfully.
01:55:29,731 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:55:30,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:55:31,100 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:55:31,105 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:55:31,106 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:55:31,107 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:55:31,108 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:55:31,108 graphrag.index.input.factory INFO using file storage for input
01:55:31,108 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:55:31,109 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:55:31,117 graphrag.index.input.text INFO Found 9 files, loading 9
01:55:31,118 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:55:31,125 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:31,154 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:31,155 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:31,168 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:31,229 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:31,231 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:31,234 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:55:31,234 root INFO Starting at time 1745301331.2348711
01:55:31,234 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:55:31,234 root INFO Completed 1 / 24 vertices
01:55:31,234 root INFO Completed 3 / 24 vertices
01:55:31,234 root INFO Completed 5 / 24 vertices
01:55:31,234 root INFO Completed 7 / 24 vertices
01:55:31,235 root INFO Completed 9 / 24 vertices
01:55:31,235 root INFO Completed 11 / 24 vertices
01:55:31,235 root INFO Completed 13 / 24 vertices
01:55:31,235 root INFO Completed 15 / 24 vertices
01:55:31,235 root INFO Completed 17 / 24 vertices
01:55:31,235 root INFO Completed 19 / 24 vertices
01:55:31,235 root INFO Completed 21 / 24 vertices
01:55:31,235 root INFO Completed 23 / 24 vertices
01:55:31,235 root INFO Completed preprocessing of transition probabilities for vertices
01:55:31,235 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:55:31,235 root INFO Completed 1 / 25 edges
01:55:31,235 root INFO Completed 3 / 25 edges
01:55:31,235 root INFO Completed 5 / 25 edges
01:55:31,235 root INFO Completed 7 / 25 edges
01:55:31,235 root INFO Completed 9 / 25 edges
01:55:31,235 root INFO Completed 11 / 25 edges
01:55:31,235 root INFO Completed 13 / 25 edges
01:55:31,235 root INFO Completed 15 / 25 edges
01:55:31,235 root INFO Completed 17 / 25 edges
01:55:31,235 root INFO Completed 19 / 25 edges
01:55:31,235 root INFO Completed 21 / 25 edges
01:55:31,235 root INFO Completed 23 / 25 edges
01:55:31,235 root INFO Completed 25 / 25 edges
01:55:31,235 root INFO Completed preprocessing of transition probabilities for edges
01:55:31,235 root INFO Simulating walks on graph at time 1745301331.2356951
01:55:31,235 root INFO Walk iteration: 1/10
01:55:31,236 root INFO Walk iteration: 2/10
01:55:31,237 root INFO Walk iteration: 3/10
01:55:31,237 root INFO Walk iteration: 4/10
01:55:31,238 root INFO Walk iteration: 5/10
01:55:31,238 root INFO Walk iteration: 6/10
01:55:31,239 root INFO Walk iteration: 7/10
01:55:31,240 root INFO Walk iteration: 8/10
01:55:31,240 root INFO Walk iteration: 9/10
01:55:31,241 root INFO Walk iteration: 10/10
01:55:31,241 root INFO Learning embeddings at time 1745301331.241824
01:55:31,242 gensim.models.word2vec INFO collecting all words and their counts
01:55:31,242 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:55:31,242 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:55:31,242 gensim.models.word2vec INFO Creating a fresh vocabulary
01:55:31,242 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:55:31.242437', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:31,242 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:55:31.242470', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:31,242 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:55:31,242 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:55:31,242 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:55:31.242582', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:31,242 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:55:31,242 gensim.models.word2vec INFO resetting layer weights
01:55:31,242 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:55:31.242884', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:55:31,242 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:55:31.242913', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:55:31,246 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 191794 effective words/s
01:55:31,250 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 202822 effective words/s
01:55:31,254 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 198844 effective words/s
01:55:31,254 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 166457 effective words/s', 'datetime': '2025-04-22T01:55:31.254114', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:55:31,254 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:55:31.254145', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:55:31,254 root INFO Completed. Ending time is 1745301331.2541718 Elapsed time is -0.01930069923400879
01:55:34,922 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:34,924 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:34,944 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:34,945 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:34,946 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:34,962 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:34,963 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:34,964 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:55:34,970 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:55:35,16 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:35,17 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:35,19 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:35,20 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:35,21 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:55:35,24 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:55:35,24 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:55:35,258 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:55:35,301 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:55:35,304 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:55:35,310 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:55:35,316 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:55:35,367 graphrag.cli.index INFO All workflows completed successfully.
01:55:50,128 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
01:55:50,964 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
01:55:51,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
01:55:51,499 graphrag.cli.index INFO Starting pipeline run. dry_run=False
01:55:51,501 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
01:55:51,502 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
01:55:51,502 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
01:55:51,502 graphrag.index.input.factory INFO using file storage for input
01:55:51,503 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
01:55:51,504 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
01:55:51,513 graphrag.index.input.text INFO Found 9 files, loading 9
01:55:51,514 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
01:55:51,520 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:51,550 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:51,552 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:51,565 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:51,627 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:51,629 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:51,632 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
01:55:51,632 root INFO Starting at time 1745301351.632448
01:55:51,632 root INFO Beginning preprocessing of transition probabilities for 24 vertices
01:55:51,632 root INFO Completed 1 / 24 vertices
01:55:51,632 root INFO Completed 3 / 24 vertices
01:55:51,632 root INFO Completed 5 / 24 vertices
01:55:51,632 root INFO Completed 7 / 24 vertices
01:55:51,632 root INFO Completed 9 / 24 vertices
01:55:51,632 root INFO Completed 11 / 24 vertices
01:55:51,632 root INFO Completed 13 / 24 vertices
01:55:51,632 root INFO Completed 15 / 24 vertices
01:55:51,632 root INFO Completed 17 / 24 vertices
01:55:51,632 root INFO Completed 19 / 24 vertices
01:55:51,632 root INFO Completed 21 / 24 vertices
01:55:51,632 root INFO Completed 23 / 24 vertices
01:55:51,632 root INFO Completed preprocessing of transition probabilities for vertices
01:55:51,632 root INFO Beginning preprocessing of transition probabilities for 25 edges
01:55:51,632 root INFO Completed 1 / 25 edges
01:55:51,632 root INFO Completed 3 / 25 edges
01:55:51,632 root INFO Completed 5 / 25 edges
01:55:51,632 root INFO Completed 7 / 25 edges
01:55:51,632 root INFO Completed 9 / 25 edges
01:55:51,632 root INFO Completed 11 / 25 edges
01:55:51,633 root INFO Completed 13 / 25 edges
01:55:51,633 root INFO Completed 15 / 25 edges
01:55:51,633 root INFO Completed 17 / 25 edges
01:55:51,633 root INFO Completed 19 / 25 edges
01:55:51,633 root INFO Completed 21 / 25 edges
01:55:51,633 root INFO Completed 23 / 25 edges
01:55:51,633 root INFO Completed 25 / 25 edges
01:55:51,633 root INFO Completed preprocessing of transition probabilities for edges
01:55:51,633 root INFO Simulating walks on graph at time 1745301351.633271
01:55:51,633 root INFO Walk iteration: 1/10
01:55:51,633 root INFO Walk iteration: 2/10
01:55:51,634 root INFO Walk iteration: 3/10
01:55:51,635 root INFO Walk iteration: 4/10
01:55:51,635 root INFO Walk iteration: 5/10
01:55:51,636 root INFO Walk iteration: 6/10
01:55:51,636 root INFO Walk iteration: 7/10
01:55:51,637 root INFO Walk iteration: 8/10
01:55:51,638 root INFO Walk iteration: 9/10
01:55:51,638 root INFO Walk iteration: 10/10
01:55:51,639 root INFO Learning embeddings at time 1745301351.639296
01:55:51,639 gensim.models.word2vec INFO collecting all words and their counts
01:55:51,639 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
01:55:51,639 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
01:55:51,639 gensim.models.word2vec INFO Creating a fresh vocabulary
01:55:51,639 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T01:55:51.639908', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:51,639 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T01:55:51.639939', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:51,640 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
01:55:51,640 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
01:55:51,640 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T01:55:51.640052', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
01:55:51,640 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
01:55:51,640 gensim.models.word2vec INFO resetting layer weights
01:55:51,640 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T01:55:51.640355', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
01:55:51,640 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T01:55:51.640383', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:55:51,644 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 189572 effective words/s
01:55:51,647 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 208654 effective words/s
01:55:51,651 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 200432 effective words/s
01:55:51,651 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 169273 effective words/s', 'datetime': '2025-04-22T01:55:51.651397', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
01:55:51,651 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T01:55:51.651424', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
01:55:51,651 root INFO Completed. Ending time is 1745301351.651447 Elapsed time is -0.018999099731445312
01:55:55,340 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:55,342 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:55,362 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:55,363 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:55,364 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:55,380 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:55,381 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:55,383 graphrag.utils.storage INFO reading table from storage: communities.parquet
01:55:55,388 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
01:55:55,433 graphrag.utils.storage INFO reading table from storage: documents.parquet
01:55:55,435 graphrag.utils.storage INFO reading table from storage: relationships.parquet
01:55:55,436 graphrag.utils.storage INFO reading table from storage: text_units.parquet
01:55:55,438 graphrag.utils.storage INFO reading table from storage: entities.parquet
01:55:55,439 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
01:55:55,442 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
01:55:55,442 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
01:55:55,657 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:55:55,667 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
01:55:55,670 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:55:55,675 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
01:55:55,678 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
01:55:55,743 graphrag.cli.index INFO All workflows completed successfully.
02:01:21,650 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
02:01:22,494 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
02:01:23,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
02:01:23,32 graphrag.cli.index INFO Starting pipeline run. dry_run=False
02:01:23,33 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
02:01:23,34 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
02:01:23,35 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
02:01:23,35 graphrag.index.input.factory INFO using file storage for input
02:01:23,35 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
02:01:23,37 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
02:01:23,45 graphrag.index.input.text INFO Found 9 files, loading 9
02:01:23,46 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
02:01:23,52 graphrag.utils.storage INFO reading table from storage: documents.parquet
02:01:23,80 graphrag.utils.storage INFO reading table from storage: documents.parquet
02:01:23,82 graphrag.utils.storage INFO reading table from storage: text_units.parquet
02:01:23,95 graphrag.utils.storage INFO reading table from storage: text_units.parquet
02:01:23,166 graphrag.utils.storage INFO reading table from storage: entities.parquet
02:01:23,168 graphrag.utils.storage INFO reading table from storage: relationships.parquet
02:01:23,172 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
02:01:23,172 root INFO Starting at time 1745301683.172093
02:01:23,172 root INFO Beginning preprocessing of transition probabilities for 24 vertices
02:01:23,172 root INFO Completed 1 / 24 vertices
02:01:23,172 root INFO Completed 3 / 24 vertices
02:01:23,172 root INFO Completed 5 / 24 vertices
02:01:23,172 root INFO Completed 7 / 24 vertices
02:01:23,172 root INFO Completed 9 / 24 vertices
02:01:23,172 root INFO Completed 11 / 24 vertices
02:01:23,172 root INFO Completed 13 / 24 vertices
02:01:23,172 root INFO Completed 15 / 24 vertices
02:01:23,172 root INFO Completed 17 / 24 vertices
02:01:23,172 root INFO Completed 19 / 24 vertices
02:01:23,172 root INFO Completed 21 / 24 vertices
02:01:23,172 root INFO Completed 23 / 24 vertices
02:01:23,172 root INFO Completed preprocessing of transition probabilities for vertices
02:01:23,172 root INFO Beginning preprocessing of transition probabilities for 25 edges
02:01:23,172 root INFO Completed 1 / 25 edges
02:01:23,172 root INFO Completed 3 / 25 edges
02:01:23,172 root INFO Completed 5 / 25 edges
02:01:23,172 root INFO Completed 7 / 25 edges
02:01:23,172 root INFO Completed 9 / 25 edges
02:01:23,172 root INFO Completed 11 / 25 edges
02:01:23,172 root INFO Completed 13 / 25 edges
02:01:23,172 root INFO Completed 15 / 25 edges
02:01:23,172 root INFO Completed 17 / 25 edges
02:01:23,172 root INFO Completed 19 / 25 edges
02:01:23,172 root INFO Completed 21 / 25 edges
02:01:23,172 root INFO Completed 23 / 25 edges
02:01:23,172 root INFO Completed 25 / 25 edges
02:01:23,172 root INFO Completed preprocessing of transition probabilities for edges
02:01:23,172 root INFO Simulating walks on graph at time 1745301683.172897
02:01:23,173 root INFO Walk iteration: 1/10
02:01:23,173 root INFO Walk iteration: 2/10
02:01:23,174 root INFO Walk iteration: 3/10
02:01:23,175 root INFO Walk iteration: 4/10
02:01:23,175 root INFO Walk iteration: 5/10
02:01:23,176 root INFO Walk iteration: 6/10
02:01:23,176 root INFO Walk iteration: 7/10
02:01:23,178 root INFO Walk iteration: 8/10
02:01:23,179 root INFO Walk iteration: 9/10
02:01:23,179 root INFO Walk iteration: 10/10
02:01:23,180 root INFO Learning embeddings at time 1745301683.180235
02:01:23,180 gensim.models.word2vec INFO collecting all words and their counts
02:01:23,180 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
02:01:23,180 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
02:01:23,180 gensim.models.word2vec INFO Creating a fresh vocabulary
02:01:23,180 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T02:01:23.180860', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
02:01:23,180 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T02:01:23.180894', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
02:01:23,180 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
02:01:23,180 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
02:01:23,181 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T02:01:23.181019', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
02:01:23,181 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
02:01:23,181 gensim.models.word2vec INFO resetting layer weights
02:01:23,181 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T02:01:23.181324', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
02:01:23,181 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T02:01:23.181352', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
02:01:23,185 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 192197 effective words/s
02:01:23,189 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 184912 effective words/s
02:01:23,192 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 192236 effective words/s
02:01:23,192 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 160834 effective words/s', 'datetime': '2025-04-22T02:01:23.192944', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
02:01:23,192 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T02:01:23.192978', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
02:01:23,193 root INFO Completed. Ending time is 1745301683.1930182 Elapsed time is -0.020925283432006836
02:01:26,849 graphrag.utils.storage INFO reading table from storage: entities.parquet
02:01:26,851 graphrag.utils.storage INFO reading table from storage: relationships.parquet
02:01:26,871 graphrag.utils.storage INFO reading table from storage: text_units.parquet
02:01:26,872 graphrag.utils.storage INFO reading table from storage: entities.parquet
02:01:26,874 graphrag.utils.storage INFO reading table from storage: relationships.parquet
02:01:26,889 graphrag.utils.storage INFO reading table from storage: relationships.parquet
02:01:26,891 graphrag.utils.storage INFO reading table from storage: entities.parquet
02:01:26,892 graphrag.utils.storage INFO reading table from storage: communities.parquet
02:01:26,897 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
02:01:26,944 graphrag.utils.storage INFO reading table from storage: documents.parquet
02:01:26,945 graphrag.utils.storage INFO reading table from storage: relationships.parquet
02:01:26,947 graphrag.utils.storage INFO reading table from storage: text_units.parquet
02:01:26,948 graphrag.utils.storage INFO reading table from storage: entities.parquet
02:01:26,950 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
02:01:26,952 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
02:01:26,952 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
02:01:27,196 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
02:01:27,229 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
02:01:27,233 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
02:01:27,239 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
02:01:27,243 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
02:01:27,309 graphrag.cli.index INFO All workflows completed successfully.
03:40:46,216 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
03:40:47,184 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
03:40:48,242 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
03:40:48,250 graphrag.cli.index INFO Starting pipeline run. dry_run=False
03:40:48,251 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
03:40:48,252 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
03:40:48,252 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
03:40:48,252 graphrag.index.input.factory INFO using file storage for input
03:40:48,253 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
03:40:48,254 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
03:40:48,262 graphrag.index.input.text INFO Found 9 files, loading 9
03:40:48,265 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
03:40:48,274 graphrag.utils.storage INFO reading table from storage: documents.parquet
03:40:48,308 graphrag.utils.storage INFO reading table from storage: documents.parquet
03:40:48,309 graphrag.utils.storage INFO reading table from storage: text_units.parquet
03:40:48,322 graphrag.utils.storage INFO reading table from storage: text_units.parquet
03:40:48,383 graphrag.utils.storage INFO reading table from storage: entities.parquet
03:40:48,384 graphrag.utils.storage INFO reading table from storage: relationships.parquet
03:40:48,387 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
03:40:48,387 root INFO Starting at time 1745307648.3879292
03:40:48,387 root INFO Beginning preprocessing of transition probabilities for 24 vertices
03:40:48,387 root INFO Completed 1 / 24 vertices
03:40:48,388 root INFO Completed 3 / 24 vertices
03:40:48,388 root INFO Completed 5 / 24 vertices
03:40:48,388 root INFO Completed 7 / 24 vertices
03:40:48,388 root INFO Completed 9 / 24 vertices
03:40:48,388 root INFO Completed 11 / 24 vertices
03:40:48,388 root INFO Completed 13 / 24 vertices
03:40:48,388 root INFO Completed 15 / 24 vertices
03:40:48,388 root INFO Completed 17 / 24 vertices
03:40:48,388 root INFO Completed 19 / 24 vertices
03:40:48,388 root INFO Completed 21 / 24 vertices
03:40:48,388 root INFO Completed 23 / 24 vertices
03:40:48,388 root INFO Completed preprocessing of transition probabilities for vertices
03:40:48,388 root INFO Beginning preprocessing of transition probabilities for 25 edges
03:40:48,388 root INFO Completed 1 / 25 edges
03:40:48,388 root INFO Completed 3 / 25 edges
03:40:48,388 root INFO Completed 5 / 25 edges
03:40:48,388 root INFO Completed 7 / 25 edges
03:40:48,388 root INFO Completed 9 / 25 edges
03:40:48,388 root INFO Completed 11 / 25 edges
03:40:48,388 root INFO Completed 13 / 25 edges
03:40:48,388 root INFO Completed 15 / 25 edges
03:40:48,388 root INFO Completed 17 / 25 edges
03:40:48,388 root INFO Completed 19 / 25 edges
03:40:48,388 root INFO Completed 21 / 25 edges
03:40:48,388 root INFO Completed 23 / 25 edges
03:40:48,388 root INFO Completed 25 / 25 edges
03:40:48,388 root INFO Completed preprocessing of transition probabilities for edges
03:40:48,388 root INFO Simulating walks on graph at time 1745307648.388729
03:40:48,388 root INFO Walk iteration: 1/10
03:40:48,389 root INFO Walk iteration: 2/10
03:40:48,390 root INFO Walk iteration: 3/10
03:40:48,390 root INFO Walk iteration: 4/10
03:40:48,391 root INFO Walk iteration: 5/10
03:40:48,391 root INFO Walk iteration: 6/10
03:40:48,392 root INFO Walk iteration: 7/10
03:40:48,392 root INFO Walk iteration: 8/10
03:40:48,393 root INFO Walk iteration: 9/10
03:40:48,394 root INFO Walk iteration: 10/10
03:40:48,394 root INFO Learning embeddings at time 1745307648.394776
03:40:48,395 gensim.models.word2vec INFO collecting all words and their counts
03:40:48,395 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
03:40:48,395 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
03:40:48,395 gensim.models.word2vec INFO Creating a fresh vocabulary
03:40:48,395 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-22T03:40:48.395660', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
03:40:48,395 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-22T03:40:48.395691', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
03:40:48,395 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
03:40:48,395 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
03:40:48,395 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-22T03:40:48.395805', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
03:40:48,395 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
03:40:48,395 gensim.models.word2vec INFO resetting layer weights
03:40:48,396 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-22T03:40:48.396092', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
03:40:48,396 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-22T03:40:48.396119', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
03:40:48,399 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 198833 effective words/s
03:40:48,403 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 209957 effective words/s
03:40:48,406 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205660 effective words/s
03:40:48,406 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172298 effective words/s', 'datetime': '2025-04-22T03:40:48.406939', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
03:40:48,406 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-22T03:40:48.406969', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
03:40:48,407 root INFO Completed. Ending time is 1745307648.406995 Elapsed time is -0.01906585693359375
03:40:52,28 graphrag.utils.storage INFO reading table from storage: entities.parquet
03:40:52,30 graphrag.utils.storage INFO reading table from storage: relationships.parquet
03:40:52,50 graphrag.utils.storage INFO reading table from storage: text_units.parquet
03:40:52,51 graphrag.utils.storage INFO reading table from storage: entities.parquet
03:40:52,53 graphrag.utils.storage INFO reading table from storage: relationships.parquet
03:40:52,69 graphrag.utils.storage INFO reading table from storage: relationships.parquet
03:40:52,71 graphrag.utils.storage INFO reading table from storage: entities.parquet
03:40:52,72 graphrag.utils.storage INFO reading table from storage: communities.parquet
03:40:52,78 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
03:40:52,124 graphrag.utils.storage INFO reading table from storage: documents.parquet
03:40:52,126 graphrag.utils.storage INFO reading table from storage: relationships.parquet
03:40:52,127 graphrag.utils.storage INFO reading table from storage: text_units.parquet
03:40:52,128 graphrag.utils.storage INFO reading table from storage: entities.parquet
03:40:52,130 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
03:40:52,133 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
03:40:52,133 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
03:40:52,367 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
03:40:52,394 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
03:40:52,397 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
03:40:52,420 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
03:40:52,427 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
03:40:52,477 graphrag.cli.index INFO All workflows completed successfully.
