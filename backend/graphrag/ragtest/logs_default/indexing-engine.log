11:22:20,689 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:22:21,736 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:22,553 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:22:22,558 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:22:22,558 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:22:22,559 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:22:22,560 graphrag.index.input.factory INFO loading input from root_dir=input
11:22:22,560 graphrag.index.input.factory INFO using file storage for input
11:22:22,560 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:22:22,562 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:22:22,570 graphrag.index.input.text INFO Found 9 files, loading 9
11:22:22,570 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:22:22,576 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:22:22,607 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:22:22,609 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:22:22,623 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:22:25,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:30,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:35,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:38,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:39,145 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:40,272 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:40,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:42,113 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:42,728 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:46,218 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:47,649 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:48,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:51,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:51,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:52,251 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:52,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:53,581 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:22:59,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:03,617 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:04,48 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:08,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:09,249 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:12,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:12,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:16,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,647 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:17,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,157 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,330 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:18,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:24,811 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:37,481 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:40,900 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:41,711 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:42,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:42,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:43,41 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:43,346 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,270 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:44,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:45,52 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:23:45,84 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:45,86 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:45,91 root INFO Starting preprocessing of transition probabilities on graph with 62 nodes and 81 edges
11:23:45,91 root INFO Starting at time 1744817025.091522
11:23:45,91 root INFO Beginning preprocessing of transition probabilities for 62 vertices
11:23:45,91 root INFO Completed 1 / 62 vertices
11:23:45,91 root INFO Completed 7 / 62 vertices
11:23:45,91 root INFO Completed 13 / 62 vertices
11:23:45,91 root INFO Completed 19 / 62 vertices
11:23:45,91 root INFO Completed 25 / 62 vertices
11:23:45,91 root INFO Completed 31 / 62 vertices
11:23:45,91 root INFO Completed 37 / 62 vertices
11:23:45,91 root INFO Completed 43 / 62 vertices
11:23:45,91 root INFO Completed 49 / 62 vertices
11:23:45,92 root INFO Completed 55 / 62 vertices
11:23:45,92 root INFO Completed 61 / 62 vertices
11:23:45,92 root INFO Completed preprocessing of transition probabilities for vertices
11:23:45,92 root INFO Beginning preprocessing of transition probabilities for 81 edges
11:23:45,92 root INFO Completed 1 / 81 edges
11:23:45,92 root INFO Completed 9 / 81 edges
11:23:45,92 root INFO Completed 17 / 81 edges
11:23:45,93 root INFO Completed 25 / 81 edges
11:23:45,93 root INFO Completed 33 / 81 edges
11:23:45,94 root INFO Completed 41 / 81 edges
11:23:45,94 root INFO Completed 49 / 81 edges
11:23:45,94 root INFO Completed 57 / 81 edges
11:23:45,94 root INFO Completed 65 / 81 edges
11:23:45,94 root INFO Completed 73 / 81 edges
11:23:45,95 root INFO Completed 81 / 81 edges
11:23:45,95 root INFO Completed preprocessing of transition probabilities for edges
11:23:45,95 root INFO Simulating walks on graph at time 1744817025.095087
11:23:45,95 root INFO Walk iteration: 1/10
11:23:45,98 root INFO Walk iteration: 2/10
11:23:45,101 root INFO Walk iteration: 3/10
11:23:45,103 root INFO Walk iteration: 4/10
11:23:45,106 root INFO Walk iteration: 5/10
11:23:45,108 root INFO Walk iteration: 6/10
11:23:45,111 root INFO Walk iteration: 7/10
11:23:45,114 root INFO Walk iteration: 8/10
11:23:45,116 root INFO Walk iteration: 9/10
11:23:45,118 root INFO Walk iteration: 10/10
11:23:45,121 root INFO Learning embeddings at time 1744817025.121253
11:23:45,121 gensim.models.word2vec INFO collecting all words and their counts
11:23:45,121 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:23:45,122 gensim.models.word2vec INFO collected 62 word types from a corpus of 11200 raw words and 620 sentences
11:23:45,122 gensim.models.word2vec INFO Creating a fresh vocabulary
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 62 unique words (100.00% of original 62, drops 0)', 'datetime': '2025-04-16T11:23:45.122709', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 11200 word corpus (100.00% of original 11200, drops 0)', 'datetime': '2025-04-16T11:23:45.122745', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,122 gensim.models.word2vec INFO deleting the raw counts dictionary of 62 items
11:23:45,122 gensim.models.word2vec INFO sample=0.001 downsamples 62 most-common words
11:23:45,122 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3126.1365729291606 word corpus (27.9%% of prior 11200)', 'datetime': '2025-04-16T11:23:45.122963', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:23:45,123 gensim.models.word2vec INFO estimated required memory for 62 words and 1536 dimensions: 792856 bytes
11:23:45,123 gensim.models.word2vec INFO resetting layer weights
11:23:45,123 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:23:45.123581', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:23:45,123 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 62 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:23:45.123617', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:23:45,143 gensim.models.word2vec INFO EPOCH 0: training on 11200 raw words (3160 effective words) took 0.0s, 166779 effective words/s
11:23:45,161 gensim.models.word2vec INFO EPOCH 1: training on 11200 raw words (3098 effective words) took 0.0s, 179365 effective words/s
11:23:45,179 gensim.models.word2vec INFO EPOCH 2: training on 11200 raw words (3126 effective words) took 0.0s, 180223 effective words/s
11:23:45,179 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 33600 raw words (9384 effective words) took 0.1s, 168364 effective words/s', 'datetime': '2025-04-16T11:23:45.179368', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:23:45,179 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=62, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:23:45.179395', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:23:45,179 root INFO Completed. Ending time is 1744817025.179429 Elapsed time is -0.08790707588195801
11:23:48,887 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,889 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,917 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:23:48,918 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,919 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,935 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:23:48,937 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:23:48,938 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:23:48,943 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 36
11:23:48,977 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 62
11:24:12,24 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:17,959 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:29,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:31,7 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:32,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:50,727 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:51,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:52,675 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:55,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:55,926 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:56,710 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:24:56,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:02,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:08,337 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:11,689 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:14,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:25:14,727 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:25:14,730 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:25:14,732 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:25:14,734 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:25:14,735 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:25:14,739 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:25:14,739 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:25:14,764 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:25:15,612 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:15,930 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:25:15,933 graphrag.index.operations.embed_text.strategies.openai INFO embedding 65 inputs via 65 snippets using 5 batches. max_batch_size=16, max_tokens=8191
11:25:16,431 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,434 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,574 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,770 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:16,981 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:25:16,990 graphrag.index.operations.embed_text.strategies.openai INFO embedding 16 inputs via 16 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:25:17,454 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:25:17,642 graphrag.cli.index INFO All workflows completed successfully.
11:41:29,515 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:41:41,570 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:44:27,259 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:44:28,462 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:28,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:44:28,980 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:44:28,981 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:44:28,982 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:44:28,983 graphrag.index.input.factory INFO loading input from root_dir=input
11:44:28,983 graphrag.index.input.factory INFO using file storage for input
11:44:28,983 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:44:28,984 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:44:28,993 graphrag.index.input.text INFO Found 9 files, loading 9
11:44:28,997 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:44:29,4 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:44:29,35 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:44:29,36 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:44:29,49 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:44:31,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:31,621 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:31,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:32,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,173 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:33,177 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:34,500 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:34,501 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:38,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:44:58,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:08,400 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:15,568 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:24,63 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:25,703 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:25,758 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:25,760 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:25,764 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
11:45:25,764 root INFO Starting at time 1744818325.764467
11:45:25,764 root INFO Beginning preprocessing of transition probabilities for 39 vertices
11:45:25,764 root INFO Completed 1 / 39 vertices
11:45:25,764 root INFO Completed 4 / 39 vertices
11:45:25,764 root INFO Completed 7 / 39 vertices
11:45:25,764 root INFO Completed 10 / 39 vertices
11:45:25,764 root INFO Completed 13 / 39 vertices
11:45:25,764 root INFO Completed 16 / 39 vertices
11:45:25,764 root INFO Completed 19 / 39 vertices
11:45:25,764 root INFO Completed 22 / 39 vertices
11:45:25,764 root INFO Completed 25 / 39 vertices
11:45:25,764 root INFO Completed 28 / 39 vertices
11:45:25,764 root INFO Completed 31 / 39 vertices
11:45:25,764 root INFO Completed 34 / 39 vertices
11:45:25,764 root INFO Completed 37 / 39 vertices
11:45:25,764 root INFO Completed preprocessing of transition probabilities for vertices
11:45:25,764 root INFO Beginning preprocessing of transition probabilities for 46 edges
11:45:25,764 root INFO Completed 1 / 46 edges
11:45:25,765 root INFO Completed 5 / 46 edges
11:45:25,765 root INFO Completed 9 / 46 edges
11:45:25,765 root INFO Completed 13 / 46 edges
11:45:25,765 root INFO Completed 17 / 46 edges
11:45:25,765 root INFO Completed 21 / 46 edges
11:45:25,765 root INFO Completed 25 / 46 edges
11:45:25,765 root INFO Completed 29 / 46 edges
11:45:25,765 root INFO Completed 33 / 46 edges
11:45:25,766 root INFO Completed 37 / 46 edges
11:45:25,766 root INFO Completed 41 / 46 edges
11:45:25,766 root INFO Completed 45 / 46 edges
11:45:25,766 root INFO Completed preprocessing of transition probabilities for edges
11:45:25,766 root INFO Simulating walks on graph at time 1744818325.766187
11:45:25,766 root INFO Walk iteration: 1/10
11:45:25,767 root INFO Walk iteration: 2/10
11:45:25,769 root INFO Walk iteration: 3/10
11:45:25,770 root INFO Walk iteration: 4/10
11:45:25,771 root INFO Walk iteration: 5/10
11:45:25,773 root INFO Walk iteration: 6/10
11:45:25,774 root INFO Walk iteration: 7/10
11:45:25,776 root INFO Walk iteration: 8/10
11:45:25,777 root INFO Walk iteration: 9/10
11:45:25,778 root INFO Walk iteration: 10/10
11:45:25,780 root INFO Learning embeddings at time 1744818325.7802858
11:45:25,780 gensim.models.word2vec INFO collecting all words and their counts
11:45:25,780 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:45:25,781 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
11:45:25,781 gensim.models.word2vec INFO Creating a fresh vocabulary
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T11:45:25.781201', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T11:45:25.781234', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
11:45:25,781 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T11:45:25.781390', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:45:25,781 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
11:45:25,781 gensim.models.word2vec INFO resetting layer weights
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:45:25.781826', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:45:25,781 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:45:25.781856', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:45:25,791 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 162105 effective words/s
11:45:25,801 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 172084 effective words/s
11:45:25,810 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 169905 effective words/s
11:45:25,810 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 156614 effective words/s', 'datetime': '2025-04-16T11:45:25.810624', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:45:25,810 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:45:25.810654', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:45:25,810 root INFO Completed. Ending time is 1744818325.810685 Elapsed time is -0.046217918395996094
11:45:29,574 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,576 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,596 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:45:29,597 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,599 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,615 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:45:29,616 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:45:29,618 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:45:29,623 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
11:45:45,468 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:45:55,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:00,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:03,697 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:05,847 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:08,509 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:46:08,537 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:46:08,540 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:46:08,542 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:46:08,544 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:46:08,546 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:46:08,550 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:46:08,550 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:46:08,774 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:46:08,788 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:46:08,791 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:46:09,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:09,560 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:46:09,566 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
11:46:10,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:46:10,906 graphrag.cli.index INFO All workflows completed successfully.
11:51:01,572 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
11:51:02,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:51:02,916 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:51:02,922 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:51:02,924 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
11:51:02,925 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
11:51:02,925 graphrag.index.input.factory INFO loading input from root_dir=input
11:51:02,925 graphrag.index.input.factory INFO using file storage for input
11:51:02,926 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
11:51:02,927 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
11:51:02,935 graphrag.index.input.text INFO Found 9 files, loading 9
11:51:02,937 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
11:51:02,943 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:02,974 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:02,976 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:02,989 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:03,62 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:03,64 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:03,67 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
11:51:03,67 root INFO Starting at time 1744818663.067168
11:51:03,67 root INFO Beginning preprocessing of transition probabilities for 39 vertices
11:51:03,67 root INFO Completed 1 / 39 vertices
11:51:03,67 root INFO Completed 4 / 39 vertices
11:51:03,67 root INFO Completed 7 / 39 vertices
11:51:03,67 root INFO Completed 10 / 39 vertices
11:51:03,67 root INFO Completed 13 / 39 vertices
11:51:03,67 root INFO Completed 16 / 39 vertices
11:51:03,67 root INFO Completed 19 / 39 vertices
11:51:03,67 root INFO Completed 22 / 39 vertices
11:51:03,67 root INFO Completed 25 / 39 vertices
11:51:03,67 root INFO Completed 28 / 39 vertices
11:51:03,67 root INFO Completed 31 / 39 vertices
11:51:03,67 root INFO Completed 34 / 39 vertices
11:51:03,67 root INFO Completed 37 / 39 vertices
11:51:03,67 root INFO Completed preprocessing of transition probabilities for vertices
11:51:03,67 root INFO Beginning preprocessing of transition probabilities for 46 edges
11:51:03,67 root INFO Completed 1 / 46 edges
11:51:03,67 root INFO Completed 5 / 46 edges
11:51:03,67 root INFO Completed 9 / 46 edges
11:51:03,67 root INFO Completed 13 / 46 edges
11:51:03,67 root INFO Completed 17 / 46 edges
11:51:03,68 root INFO Completed 21 / 46 edges
11:51:03,68 root INFO Completed 25 / 46 edges
11:51:03,68 root INFO Completed 29 / 46 edges
11:51:03,68 root INFO Completed 33 / 46 edges
11:51:03,68 root INFO Completed 37 / 46 edges
11:51:03,68 root INFO Completed 41 / 46 edges
11:51:03,68 root INFO Completed 45 / 46 edges
11:51:03,68 root INFO Completed preprocessing of transition probabilities for edges
11:51:03,68 root INFO Simulating walks on graph at time 1744818663.068479
11:51:03,68 root INFO Walk iteration: 1/10
11:51:03,69 root INFO Walk iteration: 2/10
11:51:03,70 root INFO Walk iteration: 3/10
11:51:03,72 root INFO Walk iteration: 4/10
11:51:03,73 root INFO Walk iteration: 5/10
11:51:03,74 root INFO Walk iteration: 6/10
11:51:03,75 root INFO Walk iteration: 7/10
11:51:03,76 root INFO Walk iteration: 8/10
11:51:03,77 root INFO Walk iteration: 9/10
11:51:03,78 root INFO Walk iteration: 10/10
11:51:03,80 root INFO Learning embeddings at time 1744818663.080079
11:51:03,80 gensim.models.word2vec INFO collecting all words and their counts
11:51:03,80 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
11:51:03,80 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
11:51:03,80 gensim.models.word2vec INFO Creating a fresh vocabulary
11:51:03,80 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T11:51:03.080901', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,80 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T11:51:03.080932', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,81 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
11:51:03,81 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T11:51:03.081070', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
11:51:03,81 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
11:51:03,81 gensim.models.word2vec INFO resetting layer weights
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T11:51:03.081465', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
11:51:03,81 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T11:51:03.081492', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:51:03,90 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 169659 effective words/s
11:51:03,106 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 135531 effective words/s
11:51:03,115 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 175435 effective words/s
11:51:03,115 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 131113 effective words/s', 'datetime': '2025-04-16T11:51:03.115846', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
11:51:03,115 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T11:51:03.115885', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
11:51:03,115 root INFO Completed. Ending time is 1744818663.115919 Elapsed time is -0.048751115798950195
11:51:06,724 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,726 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,746 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:06,747 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,749 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,765 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:06,766 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:06,768 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:51:06,772 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
11:51:42,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:51:42,518 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:51:42,521 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:51:42,524 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:51:42,526 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:51:42,528 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:51:42,532 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:51:42,532 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:51:42,744 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
11:51:42,765 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:51:42,768 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:51:43,154 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:51:43,182 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:51:43,194 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
11:51:43,252 graphrag.cli.index INFO All workflows completed successfully.
13:01:31,445 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:01:32,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:01:33,332 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:01:33,336 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:01:33,337 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:01:33,338 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
13:01:33,338 graphrag.index.input.factory INFO loading input from root_dir=input
13:01:33,338 graphrag.index.input.factory INFO using file storage for input
13:01:33,339 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
13:01:33,341 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
13:01:33,350 graphrag.index.input.text INFO Found 9 files, loading 9
13:01:33,351 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:01:33,358 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:33,387 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:33,388 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:33,401 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:33,474 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:33,476 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:33,479 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
13:01:33,479 root INFO Starting at time 1744822893.479897
13:01:33,479 root INFO Beginning preprocessing of transition probabilities for 39 vertices
13:01:33,479 root INFO Completed 1 / 39 vertices
13:01:33,479 root INFO Completed 4 / 39 vertices
13:01:33,480 root INFO Completed 7 / 39 vertices
13:01:33,480 root INFO Completed 10 / 39 vertices
13:01:33,480 root INFO Completed 13 / 39 vertices
13:01:33,480 root INFO Completed 16 / 39 vertices
13:01:33,480 root INFO Completed 19 / 39 vertices
13:01:33,480 root INFO Completed 22 / 39 vertices
13:01:33,480 root INFO Completed 25 / 39 vertices
13:01:33,480 root INFO Completed 28 / 39 vertices
13:01:33,480 root INFO Completed 31 / 39 vertices
13:01:33,480 root INFO Completed 34 / 39 vertices
13:01:33,480 root INFO Completed 37 / 39 vertices
13:01:33,480 root INFO Completed preprocessing of transition probabilities for vertices
13:01:33,480 root INFO Beginning preprocessing of transition probabilities for 46 edges
13:01:33,480 root INFO Completed 1 / 46 edges
13:01:33,480 root INFO Completed 5 / 46 edges
13:01:33,480 root INFO Completed 9 / 46 edges
13:01:33,480 root INFO Completed 13 / 46 edges
13:01:33,480 root INFO Completed 17 / 46 edges
13:01:33,480 root INFO Completed 21 / 46 edges
13:01:33,480 root INFO Completed 25 / 46 edges
13:01:33,481 root INFO Completed 29 / 46 edges
13:01:33,481 root INFO Completed 33 / 46 edges
13:01:33,481 root INFO Completed 37 / 46 edges
13:01:33,481 root INFO Completed 41 / 46 edges
13:01:33,481 root INFO Completed 45 / 46 edges
13:01:33,481 root INFO Completed preprocessing of transition probabilities for edges
13:01:33,481 root INFO Simulating walks on graph at time 1744822893.481245
13:01:33,481 root INFO Walk iteration: 1/10
13:01:33,482 root INFO Walk iteration: 2/10
13:01:33,483 root INFO Walk iteration: 3/10
13:01:33,485 root INFO Walk iteration: 4/10
13:01:33,486 root INFO Walk iteration: 5/10
13:01:33,487 root INFO Walk iteration: 6/10
13:01:33,488 root INFO Walk iteration: 7/10
13:01:33,489 root INFO Walk iteration: 8/10
13:01:33,491 root INFO Walk iteration: 9/10
13:01:33,492 root INFO Walk iteration: 10/10
13:01:33,493 root INFO Learning embeddings at time 1744822893.493786
13:01:33,494 gensim.models.word2vec INFO collecting all words and their counts
13:01:33,494 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:01:33,494 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
13:01:33,494 gensim.models.word2vec INFO Creating a fresh vocabulary
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T13:01:33.494795', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T13:01:33.494830', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,494 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
13:01:33,494 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
13:01:33,494 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T13:01:33.494994', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:01:33,495 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
13:01:33,495 gensim.models.word2vec INFO resetting layer weights
13:01:33,495 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T13:01:33.495465', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:01:33,495 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T13:01:33.495502', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:01:33,505 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 168077 effective words/s
13:01:33,515 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 166029 effective words/s
13:01:33,524 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 177786 effective words/s
13:01:33,524 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 156743 effective words/s', 'datetime': '2025-04-16T13:01:33.524245', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:01:33,524 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T13:01:33.524279', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:01:33,524 root INFO Completed. Ending time is 1744822893.524309 Elapsed time is -0.04441189765930176
13:01:37,200 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,202 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,222 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:37,223 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,225 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,243 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,244 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,246 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:01:37,251 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
13:01:37,313 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:01:37,315 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:01:37,316 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:01:37,318 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:01:37,319 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:01:37,322 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:01:37,322 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:01:37,541 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
13:01:37,566 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:01:37,570 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:01:37,576 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:01:37,583 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:01:37,633 graphrag.cli.index INFO All workflows completed successfully.
13:41:47,75 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:41:47,994 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:41:48,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:41:48,549 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:41:48,551 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:41:48,552 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
13:41:48,552 graphrag.index.input.factory INFO loading input from root_dir=input
13:41:48,553 graphrag.index.input.factory INFO using file storage for input
13:41:48,553 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/input for files matching .*\.txt$
13:41:48,555 graphrag.index.input.text INFO found text files from input, found [('aljazeera.txt', {}), ('abc.txt', {}), ('nyu.txt', {}), ('health.txt', {}), ('cnbc.txt', {}), ('dbsalliance.txt', {}), ('npr(supreme_court).txt', {}), ('motleyrice.txt', {}), ('npr(tiktok_offline).txt', {})]
13:41:48,564 graphrag.index.input.text INFO Found 9 files, loading 9
13:41:48,565 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:41:48,571 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:48,601 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:48,603 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:48,616 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:48,688 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:48,690 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:48,693 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 46 edges
13:41:48,693 root INFO Starting at time 1744825308.693502
13:41:48,693 root INFO Beginning preprocessing of transition probabilities for 39 vertices
13:41:48,693 root INFO Completed 1 / 39 vertices
13:41:48,693 root INFO Completed 4 / 39 vertices
13:41:48,693 root INFO Completed 7 / 39 vertices
13:41:48,693 root INFO Completed 10 / 39 vertices
13:41:48,693 root INFO Completed 13 / 39 vertices
13:41:48,693 root INFO Completed 16 / 39 vertices
13:41:48,693 root INFO Completed 19 / 39 vertices
13:41:48,693 root INFO Completed 22 / 39 vertices
13:41:48,693 root INFO Completed 25 / 39 vertices
13:41:48,693 root INFO Completed 28 / 39 vertices
13:41:48,693 root INFO Completed 31 / 39 vertices
13:41:48,693 root INFO Completed 34 / 39 vertices
13:41:48,693 root INFO Completed 37 / 39 vertices
13:41:48,693 root INFO Completed preprocessing of transition probabilities for vertices
13:41:48,693 root INFO Beginning preprocessing of transition probabilities for 46 edges
13:41:48,693 root INFO Completed 1 / 46 edges
13:41:48,693 root INFO Completed 5 / 46 edges
13:41:48,694 root INFO Completed 9 / 46 edges
13:41:48,694 root INFO Completed 13 / 46 edges
13:41:48,694 root INFO Completed 17 / 46 edges
13:41:48,694 root INFO Completed 21 / 46 edges
13:41:48,694 root INFO Completed 25 / 46 edges
13:41:48,694 root INFO Completed 29 / 46 edges
13:41:48,694 root INFO Completed 33 / 46 edges
13:41:48,694 root INFO Completed 37 / 46 edges
13:41:48,694 root INFO Completed 41 / 46 edges
13:41:48,694 root INFO Completed 45 / 46 edges
13:41:48,694 root INFO Completed preprocessing of transition probabilities for edges
13:41:48,694 root INFO Simulating walks on graph at time 1744825308.69485
13:41:48,694 root INFO Walk iteration: 1/10
13:41:48,696 root INFO Walk iteration: 2/10
13:41:48,697 root INFO Walk iteration: 3/10
13:41:48,698 root INFO Walk iteration: 4/10
13:41:48,699 root INFO Walk iteration: 5/10
13:41:48,700 root INFO Walk iteration: 6/10
13:41:48,701 root INFO Walk iteration: 7/10
13:41:48,703 root INFO Walk iteration: 8/10
13:41:48,704 root INFO Walk iteration: 9/10
13:41:48,705 root INFO Walk iteration: 10/10
13:41:48,706 root INFO Learning embeddings at time 1744825308.706572
13:41:48,706 gensim.models.word2vec INFO collecting all words and their counts
13:41:48,706 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:41:48,707 gensim.models.word2vec INFO collected 39 word types from a corpus of 6960 raw words and 390 sentences
13:41:48,707 gensim.models.word2vec INFO Creating a fresh vocabulary
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T13:41:48.707443', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6960 word corpus (100.00% of original 6960, drops 0)', 'datetime': '2025-04-16T13:41:48.707474', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
13:41:48,707 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
13:41:48,707 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1485.0775517370942 word corpus (21.3%% of prior 6960)', 'datetime': '2025-04-16T13:41:48.707621', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:41:48,707 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
13:41:48,707 gensim.models.word2vec INFO resetting layer weights
13:41:48,708 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T13:41:48.708008', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:41:48,708 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T13:41:48.708035', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:41:48,717 gensim.models.word2vec INFO EPOCH 0: training on 6960 raw words (1483 effective words) took 0.0s, 178760 effective words/s
13:41:48,726 gensim.models.word2vec INFO EPOCH 1: training on 6960 raw words (1537 effective words) took 0.0s, 180281 effective words/s
13:41:48,735 gensim.models.word2vec INFO EPOCH 2: training on 6960 raw words (1482 effective words) took 0.0s, 178310 effective words/s
13:41:48,735 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 20880 raw words (4502 effective words) took 0.0s, 166187 effective words/s', 'datetime': '2025-04-16T13:41:48.735139', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:41:48,735 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T13:41:48.735171', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:41:48,735 root INFO Completed. Ending time is 1744825308.7352011 Elapsed time is -0.04169917106628418
13:41:52,566 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,568 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,588 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:52,589 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,590 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,606 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,608 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,609 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:41:52,615 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
13:41:52,676 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:41:52,677 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:41:52,679 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:41:52,680 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:41:52,682 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:41:52,684 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:41:52,684 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:41:52,909 graphrag.index.operations.embed_text.strategies.openai INFO embedding 12 inputs via 12 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:41:52,923 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:41:52,925 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 3 batches. max_batch_size=16, max_tokens=8191
13:41:52,945 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:41:52,948 graphrag.index.operations.embed_text.strategies.openai INFO embedding 6 inputs via 6 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:41:52,993 graphrag.cli.index INFO All workflows completed successfully.
14:00:29,438 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:00:30,385 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:31,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:00:31,17 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:00:31,18 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:00:31,18 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:00:31,19 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:00:31,19 graphrag.index.input.factory INFO using file storage for input
14:00:31,19 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:00:31,20 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:00:31,28 graphrag.index.input.text INFO Found 9 files, loading 9
14:00:31,29 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:00:31,36 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:00:31,68 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:00:31,70 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:00:31,84 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:00:32,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:38,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:41,934 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:43,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:44,211 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:53,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:54,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:59,183 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:00:59,496 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:00,184 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:01,760 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:03,675 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:07,350 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:11,549 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:12,681 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:13,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:17,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:19,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:26,573 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:29,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:33,60 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:33,789 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:35,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:40,146 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:01:40,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:40,176 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:40,181 root INFO Starting preprocessing of transition probabilities on graph with 39 nodes and 44 edges
14:01:40,181 root INFO Starting at time 1744826500.1812239
14:01:40,181 root INFO Beginning preprocessing of transition probabilities for 39 vertices
14:01:40,181 root INFO Completed 1 / 39 vertices
14:01:40,181 root INFO Completed 4 / 39 vertices
14:01:40,181 root INFO Completed 7 / 39 vertices
14:01:40,181 root INFO Completed 10 / 39 vertices
14:01:40,181 root INFO Completed 13 / 39 vertices
14:01:40,181 root INFO Completed 16 / 39 vertices
14:01:40,181 root INFO Completed 19 / 39 vertices
14:01:40,181 root INFO Completed 22 / 39 vertices
14:01:40,181 root INFO Completed 25 / 39 vertices
14:01:40,181 root INFO Completed 28 / 39 vertices
14:01:40,181 root INFO Completed 31 / 39 vertices
14:01:40,181 root INFO Completed 34 / 39 vertices
14:01:40,181 root INFO Completed 37 / 39 vertices
14:01:40,181 root INFO Completed preprocessing of transition probabilities for vertices
14:01:40,181 root INFO Beginning preprocessing of transition probabilities for 44 edges
14:01:40,181 root INFO Completed 1 / 44 edges
14:01:40,181 root INFO Completed 5 / 44 edges
14:01:40,182 root INFO Completed 9 / 44 edges
14:01:40,182 root INFO Completed 13 / 44 edges
14:01:40,182 root INFO Completed 17 / 44 edges
14:01:40,182 root INFO Completed 21 / 44 edges
14:01:40,182 root INFO Completed 25 / 44 edges
14:01:40,182 root INFO Completed 29 / 44 edges
14:01:40,182 root INFO Completed 33 / 44 edges
14:01:40,182 root INFO Completed 37 / 44 edges
14:01:40,183 root INFO Completed 41 / 44 edges
14:01:40,183 root INFO Completed preprocessing of transition probabilities for edges
14:01:40,183 root INFO Simulating walks on graph at time 1744826500.183128
14:01:40,183 root INFO Walk iteration: 1/10
14:01:40,184 root INFO Walk iteration: 2/10
14:01:40,186 root INFO Walk iteration: 3/10
14:01:40,187 root INFO Walk iteration: 4/10
14:01:40,189 root INFO Walk iteration: 5/10
14:01:40,190 root INFO Walk iteration: 6/10
14:01:40,192 root INFO Walk iteration: 7/10
14:01:40,193 root INFO Walk iteration: 8/10
14:01:40,194 root INFO Walk iteration: 9/10
14:01:40,196 root INFO Walk iteration: 10/10
14:01:40,197 root INFO Learning embeddings at time 1744826500.197429
14:01:40,197 gensim.models.word2vec INFO collecting all words and their counts
14:01:40,197 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:01:40,198 gensim.models.word2vec INFO collected 39 word types from a corpus of 6600 raw words and 390 sentences
14:01:40,198 gensim.models.word2vec INFO Creating a fresh vocabulary
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 39 unique words (100.00% of original 39, drops 0)', 'datetime': '2025-04-16T14:01:40.198429', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 6600 word corpus (100.00% of original 6600, drops 0)', 'datetime': '2025-04-16T14:01:40.198468', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.models.word2vec INFO deleting the raw counts dictionary of 39 items
14:01:40,198 gensim.models.word2vec INFO sample=0.001 downsamples 39 most-common words
14:01:40,198 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1409.778285885143 word corpus (21.4%% of prior 6600)', 'datetime': '2025-04-16T14:01:40.198644', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:01:40,198 gensim.models.word2vec INFO estimated required memory for 39 words and 1536 dimensions: 498732 bytes
14:01:40,198 gensim.models.word2vec INFO resetting layer weights
14:01:40,199 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:01:40.199179', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:01:40,199 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 39 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:01:40.199238', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:01:40,209 gensim.models.word2vec INFO EPOCH 0: training on 6600 raw words (1428 effective words) took 0.0s, 157081 effective words/s
14:01:40,218 gensim.models.word2vec INFO EPOCH 1: training on 6600 raw words (1398 effective words) took 0.0s, 166176 effective words/s
14:01:40,226 gensim.models.word2vec INFO EPOCH 2: training on 6600 raw words (1372 effective words) took 0.0s, 173791 effective words/s
14:01:40,226 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 19800 raw words (4198 effective words) took 0.0s, 153732 effective words/s', 'datetime': '2025-04-16T14:01:40.226573', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:01:40,226 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=39, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:01:40.226604', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:01:40,226 root INFO Completed. Ending time is 1744826500.226635 Elapsed time is -0.045411109924316406
14:01:44,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,98 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,118 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:01:44,120 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,121 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,137 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:01:44,138 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:01:44,140 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:01:44,145 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 39
14:02:10,128 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:11,220 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:11,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:13,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:26,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:02:31,171 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:11,808 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:03:12,897 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:13,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:03:13,416 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:03:13,417 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:03:13,418 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:03:13,418 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:03:13,418 graphrag.index.input.factory INFO using file storage for input
14:03:13,419 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:03:13,419 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:03:13,425 graphrag.index.input.text INFO Found 9 files, loading 9
14:03:13,426 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:03:13,431 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:13,456 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:13,458 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:13,470 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:13,531 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:13,533 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:13,536 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:03:13,536 root INFO Starting at time 1744826593.536353
14:03:13,536 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:03:13,536 root INFO Completed 1 / 24 vertices
14:03:13,536 root INFO Completed 3 / 24 vertices
14:03:13,536 root INFO Completed 5 / 24 vertices
14:03:13,536 root INFO Completed 7 / 24 vertices
14:03:13,536 root INFO Completed 9 / 24 vertices
14:03:13,536 root INFO Completed 11 / 24 vertices
14:03:13,536 root INFO Completed 13 / 24 vertices
14:03:13,536 root INFO Completed 15 / 24 vertices
14:03:13,536 root INFO Completed 17 / 24 vertices
14:03:13,536 root INFO Completed 19 / 24 vertices
14:03:13,536 root INFO Completed 21 / 24 vertices
14:03:13,536 root INFO Completed 23 / 24 vertices
14:03:13,536 root INFO Completed preprocessing of transition probabilities for vertices
14:03:13,536 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:03:13,536 root INFO Completed 1 / 25 edges
14:03:13,536 root INFO Completed 3 / 25 edges
14:03:13,536 root INFO Completed 5 / 25 edges
14:03:13,536 root INFO Completed 7 / 25 edges
14:03:13,536 root INFO Completed 9 / 25 edges
14:03:13,536 root INFO Completed 11 / 25 edges
14:03:13,536 root INFO Completed 13 / 25 edges
14:03:13,536 root INFO Completed 15 / 25 edges
14:03:13,536 root INFO Completed 17 / 25 edges
14:03:13,537 root INFO Completed 19 / 25 edges
14:03:13,537 root INFO Completed 21 / 25 edges
14:03:13,537 root INFO Completed 23 / 25 edges
14:03:13,537 root INFO Completed 25 / 25 edges
14:03:13,537 root INFO Completed preprocessing of transition probabilities for edges
14:03:13,537 root INFO Simulating walks on graph at time 1744826593.5371299
14:03:13,537 root INFO Walk iteration: 1/10
14:03:13,537 root INFO Walk iteration: 2/10
14:03:13,538 root INFO Walk iteration: 3/10
14:03:13,538 root INFO Walk iteration: 4/10
14:03:13,539 root INFO Walk iteration: 5/10
14:03:13,540 root INFO Walk iteration: 6/10
14:03:13,540 root INFO Walk iteration: 7/10
14:03:13,541 root INFO Walk iteration: 8/10
14:03:13,541 root INFO Walk iteration: 9/10
14:03:13,542 root INFO Walk iteration: 10/10
14:03:13,542 root INFO Learning embeddings at time 1744826593.5429351
14:03:13,543 gensim.models.word2vec INFO collecting all words and their counts
14:03:13,543 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:03:13,543 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:03:13,543 gensim.models.word2vec INFO Creating a fresh vocabulary
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:03:13.543516', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:03:13.543546', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:03:13,543 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:03:13.543651', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:03:13,543 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:03:13,543 gensim.models.word2vec INFO resetting layer weights
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:03:13.543942', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:03:13,543 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:03:13.543968', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:03:13,547 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199358 effective words/s
14:03:13,551 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 235317 effective words/s
14:03:13,554 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 231815 effective words/s
14:03:13,554 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170367 effective words/s', 'datetime': '2025-04-16T14:03:13.554911', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:03:13,554 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:03:13.554940', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:03:13,554 root INFO Completed. Ending time is 1744826593.554966 Elapsed time is -0.01861286163330078
14:03:17,242 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,244 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,264 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:17,265 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,267 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,282 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:03:17,283 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:03:17,284 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:03:17,289 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:03:41,508 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:47,305 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:53,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:03:55,697 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:04:01,739 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:04:01,764 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:04:01,767 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:04:01,769 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:04:01,771 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:04:01,773 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:04:01,776 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:04:01,776 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:04:02,7 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:04:02,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,863 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,864 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:02,865 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:03,73 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:04:03,81 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:04:03,787 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:03,926 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:04:03,933 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:04:04,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:04:04,468 graphrag.cli.index INFO All workflows completed successfully.
14:08:15,375 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:08:16,209 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:08:19,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:08:19,362 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:08:19,363 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:08:19,364 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:08:19,364 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:08:19,364 graphrag.index.input.factory INFO using file storage for input
14:08:19,364 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:08:19,365 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:08:19,373 graphrag.index.input.text INFO Found 9 files, loading 9
14:08:19,374 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:08:19,379 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:19,410 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:19,412 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:19,425 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:19,496 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:19,499 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:19,503 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:08:19,503 root INFO Starting at time 1744826899.503965
14:08:19,504 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:08:19,504 root INFO Completed 1 / 24 vertices
14:08:19,504 root INFO Completed 3 / 24 vertices
14:08:19,504 root INFO Completed 5 / 24 vertices
14:08:19,504 root INFO Completed 7 / 24 vertices
14:08:19,504 root INFO Completed 9 / 24 vertices
14:08:19,504 root INFO Completed 11 / 24 vertices
14:08:19,504 root INFO Completed 13 / 24 vertices
14:08:19,504 root INFO Completed 15 / 24 vertices
14:08:19,504 root INFO Completed 17 / 24 vertices
14:08:19,504 root INFO Completed 19 / 24 vertices
14:08:19,504 root INFO Completed 21 / 24 vertices
14:08:19,504 root INFO Completed 23 / 24 vertices
14:08:19,504 root INFO Completed preprocessing of transition probabilities for vertices
14:08:19,504 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:08:19,504 root INFO Completed 1 / 25 edges
14:08:19,504 root INFO Completed 3 / 25 edges
14:08:19,504 root INFO Completed 5 / 25 edges
14:08:19,504 root INFO Completed 7 / 25 edges
14:08:19,504 root INFO Completed 9 / 25 edges
14:08:19,504 root INFO Completed 11 / 25 edges
14:08:19,504 root INFO Completed 13 / 25 edges
14:08:19,504 root INFO Completed 15 / 25 edges
14:08:19,504 root INFO Completed 17 / 25 edges
14:08:19,504 root INFO Completed 19 / 25 edges
14:08:19,504 root INFO Completed 21 / 25 edges
14:08:19,504 root INFO Completed 23 / 25 edges
14:08:19,504 root INFO Completed 25 / 25 edges
14:08:19,504 root INFO Completed preprocessing of transition probabilities for edges
14:08:19,504 root INFO Simulating walks on graph at time 1744826899.504867
14:08:19,505 root INFO Walk iteration: 1/10
14:08:19,505 root INFO Walk iteration: 2/10
14:08:19,506 root INFO Walk iteration: 3/10
14:08:19,506 root INFO Walk iteration: 4/10
14:08:19,507 root INFO Walk iteration: 5/10
14:08:19,508 root INFO Walk iteration: 6/10
14:08:19,508 root INFO Walk iteration: 7/10
14:08:19,509 root INFO Walk iteration: 8/10
14:08:19,510 root INFO Walk iteration: 9/10
14:08:19,510 root INFO Walk iteration: 10/10
14:08:19,511 root INFO Learning embeddings at time 1744826899.511583
14:08:19,511 gensim.models.word2vec INFO collecting all words and their counts
14:08:19,512 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:08:19,512 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:08:19,512 gensim.models.word2vec INFO Creating a fresh vocabulary
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:08:19.512306', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:08:19.512342', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:08:19,512 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:08:19.512455', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:08:19,512 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:08:19,512 gensim.models.word2vec INFO resetting layer weights
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:08:19.512786', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:08:19,512 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:08:19.512819', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:08:19,517 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 176572 effective words/s
14:08:19,520 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 204596 effective words/s
14:08:19,524 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 195843 effective words/s
14:08:19,524 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 163705 effective words/s', 'datetime': '2025-04-16T14:08:19.524211', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:08:19,524 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:08:19.524244', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:08:19,524 root INFO Completed. Ending time is 1744826899.52427 Elapsed time is -0.020305156707763672
14:08:23,359 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,361 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,381 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:23,383 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,384 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,399 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,401 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,402 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:08:23,407 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:08:23,454 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:08:23,456 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:08:23,457 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:08:23,459 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:08:23,460 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:08:23,463 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:08:23,463 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:08:23,680 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:08:23,690 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:08:23,693 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:08:23,716 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:08:23,720 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:08:23,771 graphrag.cli.index INFO All workflows completed successfully.
14:12:22,793 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
14:12:23,509 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
14:12:23,745 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
14:12:23,748 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:12:23,749 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
14:12:23,749 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/output
14:12:23,749 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
14:12:23,749 graphrag.index.input.factory INFO using file storage for input
14:12:23,750 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
14:12:23,750 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
14:12:23,756 graphrag.index.input.text INFO Found 9 files, loading 9
14:12:23,757 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
14:12:23,762 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:23,790 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:23,792 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:23,805 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:23,865 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:23,867 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:23,870 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
14:12:23,870 root INFO Starting at time 1744827143.870765
14:12:23,870 root INFO Beginning preprocessing of transition probabilities for 24 vertices
14:12:23,870 root INFO Completed 1 / 24 vertices
14:12:23,870 root INFO Completed 3 / 24 vertices
14:12:23,870 root INFO Completed 5 / 24 vertices
14:12:23,870 root INFO Completed 7 / 24 vertices
14:12:23,870 root INFO Completed 9 / 24 vertices
14:12:23,870 root INFO Completed 11 / 24 vertices
14:12:23,870 root INFO Completed 13 / 24 vertices
14:12:23,870 root INFO Completed 15 / 24 vertices
14:12:23,870 root INFO Completed 17 / 24 vertices
14:12:23,871 root INFO Completed 19 / 24 vertices
14:12:23,871 root INFO Completed 21 / 24 vertices
14:12:23,871 root INFO Completed 23 / 24 vertices
14:12:23,871 root INFO Completed preprocessing of transition probabilities for vertices
14:12:23,871 root INFO Beginning preprocessing of transition probabilities for 25 edges
14:12:23,871 root INFO Completed 1 / 25 edges
14:12:23,871 root INFO Completed 3 / 25 edges
14:12:23,871 root INFO Completed 5 / 25 edges
14:12:23,871 root INFO Completed 7 / 25 edges
14:12:23,871 root INFO Completed 9 / 25 edges
14:12:23,871 root INFO Completed 11 / 25 edges
14:12:23,871 root INFO Completed 13 / 25 edges
14:12:23,871 root INFO Completed 15 / 25 edges
14:12:23,871 root INFO Completed 17 / 25 edges
14:12:23,871 root INFO Completed 19 / 25 edges
14:12:23,871 root INFO Completed 21 / 25 edges
14:12:23,871 root INFO Completed 23 / 25 edges
14:12:23,871 root INFO Completed 25 / 25 edges
14:12:23,871 root INFO Completed preprocessing of transition probabilities for edges
14:12:23,871 root INFO Simulating walks on graph at time 1744827143.871603
14:12:23,871 root INFO Walk iteration: 1/10
14:12:23,872 root INFO Walk iteration: 2/10
14:12:23,872 root INFO Walk iteration: 3/10
14:12:23,873 root INFO Walk iteration: 4/10
14:12:23,874 root INFO Walk iteration: 5/10
14:12:23,874 root INFO Walk iteration: 6/10
14:12:23,875 root INFO Walk iteration: 7/10
14:12:23,875 root INFO Walk iteration: 8/10
14:12:23,876 root INFO Walk iteration: 9/10
14:12:23,876 root INFO Walk iteration: 10/10
14:12:23,877 root INFO Learning embeddings at time 1744827143.877565
14:12:23,877 gensim.models.word2vec INFO collecting all words and their counts
14:12:23,877 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
14:12:23,878 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
14:12:23,878 gensim.models.word2vec INFO Creating a fresh vocabulary
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-16T14:12:23.878167', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-16T14:12:23.878197', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
14:12:23,878 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-16T14:12:23.878305', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
14:12:23,878 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
14:12:23,878 gensim.models.word2vec INFO resetting layer weights
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-16T14:12:23.878599', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
14:12:23,878 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-16T14:12:23.878626', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:12:23,882 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 199620 effective words/s
14:12:23,885 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 205771 effective words/s
14:12:23,889 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 234235 effective words/s
14:12:23,889 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 172138 effective words/s', 'datetime': '2025-04-16T14:12:23.889455', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
14:12:23,889 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-16T14:12:23.889483', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
14:12:23,889 root INFO Completed. Ending time is 1744827143.889507 Elapsed time is -0.018742084503173828
14:12:27,493 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,495 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,515 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:27,516 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,517 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,532 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,534 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,535 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:12:27,541 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
14:12:27,586 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:12:27,588 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:12:27,589 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:12:27,590 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:12:27,592 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:12:27,594 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:12:27,594 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:12:27,806 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
14:12:27,831 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:12:27,838 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:12:27,846 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:12:27,849 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
14:12:27,899 graphrag.cli.index INFO All workflows completed successfully.
13:24:21,157 graphrag.cli.index INFO Logging enabled at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default/indexing-engine.log
13:24:22,165 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
13:24:22,756 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
13:24:22,762 graphrag.cli.index INFO Starting pipeline run. dry_run=False
13:24:22,763 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0,
            "request_timeout": 180.0,
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "responses": null,
            "async_mode": "threaded"
        }
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/logs_default",
        "storage_account_blob_url": null
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache_default",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "AI_safety_input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "embed_graph": {
        "enabled": true,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "embed_text": {
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null,
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store"
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false
    },
    "extract_graph": {
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": null,
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "summarize_descriptions": {
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "community_reports": {
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null,
        "model_id": "default_chat_model"
    },
    "extract_claims": {
        "enabled": false,
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null,
        "model_id": "default_chat_model"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40,
        "remove_ego_nodes": false,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32,
        "dynamic_search_llm": "gpt-4o-mini",
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_concurrent_coroutines": 16,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "reduce_max_tokens": 2000,
        "reduce_temperature": 0,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": 4096
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "conversation_history_max_turns": 5,
        "temperature": 0,
        "top_p": 1,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/gauri/next-week-tonight/backend/graphrag/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null
}
13:24:22,765 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_output
13:24:22,765 graphrag.index.input.factory INFO loading input from root_dir=AI_safety_input
13:24:22,765 graphrag.index.input.factory INFO using file storage for input
13:24:22,766 graphrag.storage.file_pipeline_storage INFO search /Users/gauri/next-week-tonight/backend/graphrag/ragtest/AI_safety_input for files matching .*\.txt$
13:24:22,767 graphrag.index.input.text INFO found text files from AI_safety_input, found [('AI_safety_4752.txt', {}), ('AI_safety_6427.txt', {}), ('AI_safety_7673.txt', {}), ('AI_safety_2131.txt', {}), ('AI_safety_3886.txt', {}), ('AI_safety_perplexity_response.txt', {}), ('AI_safety_8710.txt', {}), ('AI_safety_2770.txt', {}), ('AI_safety_5906.txt', {})]
13:24:22,776 graphrag.index.input.text INFO Found 9 files, loading 9
13:24:22,777 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 9
13:24:22,784 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:22,813 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:22,815 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:22,827 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:22,890 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:22,892 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:22,895 root INFO Starting preprocessing of transition probabilities on graph with 24 nodes and 25 edges
13:24:22,895 root INFO Starting at time 1744910662.8956742
13:24:22,895 root INFO Beginning preprocessing of transition probabilities for 24 vertices
13:24:22,895 root INFO Completed 1 / 24 vertices
13:24:22,895 root INFO Completed 3 / 24 vertices
13:24:22,895 root INFO Completed 5 / 24 vertices
13:24:22,895 root INFO Completed 7 / 24 vertices
13:24:22,895 root INFO Completed 9 / 24 vertices
13:24:22,895 root INFO Completed 11 / 24 vertices
13:24:22,895 root INFO Completed 13 / 24 vertices
13:24:22,895 root INFO Completed 15 / 24 vertices
13:24:22,895 root INFO Completed 17 / 24 vertices
13:24:22,895 root INFO Completed 19 / 24 vertices
13:24:22,895 root INFO Completed 21 / 24 vertices
13:24:22,895 root INFO Completed 23 / 24 vertices
13:24:22,895 root INFO Completed preprocessing of transition probabilities for vertices
13:24:22,895 root INFO Beginning preprocessing of transition probabilities for 25 edges
13:24:22,896 root INFO Completed 1 / 25 edges
13:24:22,896 root INFO Completed 3 / 25 edges
13:24:22,896 root INFO Completed 5 / 25 edges
13:24:22,896 root INFO Completed 7 / 25 edges
13:24:22,896 root INFO Completed 9 / 25 edges
13:24:22,896 root INFO Completed 11 / 25 edges
13:24:22,896 root INFO Completed 13 / 25 edges
13:24:22,896 root INFO Completed 15 / 25 edges
13:24:22,896 root INFO Completed 17 / 25 edges
13:24:22,896 root INFO Completed 19 / 25 edges
13:24:22,896 root INFO Completed 21 / 25 edges
13:24:22,896 root INFO Completed 23 / 25 edges
13:24:22,896 root INFO Completed 25 / 25 edges
13:24:22,896 root INFO Completed preprocessing of transition probabilities for edges
13:24:22,896 root INFO Simulating walks on graph at time 1744910662.896491
13:24:22,896 root INFO Walk iteration: 1/10
13:24:22,897 root INFO Walk iteration: 2/10
13:24:22,897 root INFO Walk iteration: 3/10
13:24:22,898 root INFO Walk iteration: 4/10
13:24:22,898 root INFO Walk iteration: 5/10
13:24:22,899 root INFO Walk iteration: 6/10
13:24:22,900 root INFO Walk iteration: 7/10
13:24:22,900 root INFO Walk iteration: 8/10
13:24:22,901 root INFO Walk iteration: 9/10
13:24:22,901 root INFO Walk iteration: 10/10
13:24:22,902 root INFO Learning embeddings at time 1744910662.902466
13:24:22,902 gensim.models.word2vec INFO collecting all words and their counts
13:24:22,902 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
13:24:22,902 gensim.models.word2vec INFO collected 24 word types from a corpus of 3760 raw words and 240 sentences
13:24:22,902 gensim.models.word2vec INFO Creating a fresh vocabulary
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 24 unique words (100.00% of original 24, drops 0)', 'datetime': '2025-04-17T13:24:22.903060', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 3760 word corpus (100.00% of original 3760, drops 0)', 'datetime': '2025-04-17T13:24:22.903089', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.models.word2vec INFO deleting the raw counts dictionary of 24 items
13:24:22,903 gensim.models.word2vec INFO sample=0.001 downsamples 24 most-common words
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 609.7357859042421 word corpus (16.2%% of prior 3760)', 'datetime': '2025-04-17T13:24:22.903198', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}
13:24:22,903 gensim.models.word2vec INFO estimated required memory for 24 words and 1536 dimensions: 306912 bytes
13:24:22,903 gensim.models.word2vec INFO resetting layer weights
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-17T13:24:22.903484', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'build_vocab'}
13:24:22,903 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 24 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2025-04-17T13:24:22.903510', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:24:22,907 gensim.models.word2vec INFO EPOCH 0: training on 3760 raw words (639 effective words) took 0.0s, 186997 effective words/s
13:24:22,910 gensim.models.word2vec INFO EPOCH 1: training on 3760 raw words (605 effective words) took 0.0s, 205540 effective words/s
13:24:22,914 gensim.models.word2vec INFO EPOCH 2: training on 3760 raw words (618 effective words) took 0.0s, 205797 effective words/s
13:24:22,914 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 11280 raw words (1862 effective words) took 0.0s, 170164 effective words/s', 'datetime': '2025-04-17T13:24:22.914464', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'train'}
13:24:22,914 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=24, vector_size=1536, alpha=0.025>', 'datetime': '2025-04-17T13:24:22.914492', 'gensim': '4.3.3', 'python': '3.10.13 (main, Jan 26 2024, 18:29:17) [Clang 15.0.0 (clang-1500.1.0.2.5)]', 'platform': 'macOS-15.3.1-arm64-arm-64bit', 'event': 'created'}
13:24:22,914 root INFO Completed. Ending time is 1744910662.9145138 Elapsed time is -0.018839597702026367
13:24:26,536 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,539 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,558 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:26,560 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,561 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,576 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,578 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,579 graphrag.utils.storage INFO reading table from storage: communities.parquet
13:24:26,584 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 24
13:24:26,630 graphrag.utils.storage INFO reading table from storage: documents.parquet
13:24:26,631 graphrag.utils.storage INFO reading table from storage: relationships.parquet
13:24:26,633 graphrag.utils.storage INFO reading table from storage: text_units.parquet
13:24:26,634 graphrag.utils.storage INFO reading table from storage: entities.parquet
13:24:26,636 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
13:24:26,638 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
13:24:26,638 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
13:24:26,861 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:24:26,872 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
13:24:26,874 graphrag.index.operations.embed_text.strategies.openai INFO embedding 51 inputs via 51 snippets using 4 batches. max_batch_size=16, max_tokens=8191
13:24:26,897 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
13:24:26,903 graphrag.index.operations.embed_text.strategies.openai INFO embedding 10 inputs via 10 snippets using 1 batches. max_batch_size=16, max_tokens=8191
13:24:26,954 graphrag.cli.index INFO All workflows completed successfully.
